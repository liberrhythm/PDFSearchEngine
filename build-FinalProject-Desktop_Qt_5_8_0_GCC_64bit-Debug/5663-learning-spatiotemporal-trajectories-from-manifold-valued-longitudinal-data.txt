Learning spatiotemporal trajectories from
manifold-valued longitudinal data

Jean-Baptiste Schiratti2,1 , Stéphanie Allassonnière2 , Olivier Colliot1 , Stanley Durrleman1
1
ARAMIS Lab, INRIA Paris, Inserm U1127, CNRS UMR 7225, Sorbonne Universités,
UPMC Univ Paris 06 UMR S 1127, Institut du Cerveau et de la Moelle épinière,
ICM, F-75013, Paris, France
2
CMAP, Ecole Polytechnique, Palaiseau, France
jean-baptiste.schiratti@cmap.polytechnique.fr,
stephanie.allassonniere@polytechnique.edu,
olivier.colliot@upmc.fr,stanley.durrleman@inria.fr

Abstract
We propose a Bayesian mixed-effects model to learn typical scenarios of changes
from longitudinal manifold-valued data, namely repeated measurements of the
same objects or individuals at several points in time. The model allows to estimate
a group-average trajectory in the space of measurements. Random variations of
this trajectory result from spatiotemporal transformations, which allow changes in
the direction of the trajectory and in the pace at which trajectories are followed.
The use of the tools of Riemannian geometry allows to derive a generic algorithm
for any kind of data with smooth constraints, which lie therefore on a Riemannian
manifold. Stochastic approximations of the Expectation-Maximization algorithm
is used to estimate the model parameters in this highly non-linear setting. The
method is used to estimate a data-driven model of the progressive impairments of
cognitive functions during the onset of Alzheimer’s disease. Experimental results
show that the model correctly put into correspondence the age at which each individual was diagnosed with the disease, thus validating the fact that it effectively
estimated a normative scenario of disease progression. Random effects provide
unique insights into the variations in the ordering and timing of the succession of
cognitive impairments across different individuals.

1

Introduction

Age-related brain diseases, such as Parkinson’s or Alzheimer’s disease (AD) are complex diseases
with multiple effects on the metabolism, structure and function of the brain. Models of disease progression showing the sequence and timing of these effects during the course of the disease remain
largely hypothetical [3, 13]. Large databases have been collected recently in the hope to give experimental evidence of the patterns of disease progression based on the estimation of data-driven
models. These databases are longitudinal, in the sense that they contain repeated measurements of
several subjects at multiple time-points, but which do not necessarily correspond across subjects.
Learning models of disease progression from such databases raises great methodological challenges.
The main difficulty lies in the fact that the age of a given individual gives no information about the
stage of disease progression of this individual. The onset of clinical symptoms of AD may vary from
forty and eighty years of age, and the duration of the disease from few years to decades. Moreover,
the onset of the disease does not correspond with the onset of the symptoms: according to recent
studies, symptoms are likely to be preceded by a silent phase of the disease, for which little is
known. As a consequence, statistical models based on the regression of measurements with age are
inadequate to model disease progression.
1

The set of the measurements of a given individual at a specific time-point belongs to a highdimensional space. Building a model of disease progression amounts to estimating continuous
subject-specific trajectories in this space and average those trajectories among a group of individuals. Trajectories need to be registered in space, to account for the fact that individuals follow
different trajectories, and in time, to account for the fact that individuals, even if they follow the
same trajectory, may be at a different position on this trajectory at the same age.
The framework of mixed-effects models seems to be well suited to deal with this hierarchical problem. Mixed-effects models for longitudinal measurements were introduced in the seminal paper of
Laird and Ware [15] and have been widely developed since then (see [6], [16] for instance). However, this kind of models suffers from two main drawbacks regarding our problem. These models
are built on the estimation of the distribution of the measurements at a given time point. In many
situations, this reference time is given by the experimental set up: date at which treatment begins,
date of seeding in studies of plant growth, etc. In studies of ageing, using these models would require to register the data of each individual to a common stage of disease progression before being
compared. Unfortunately, this stage is unknown and such a temporal registration is actually what
we wish to estimate. Another limitation of usual mixed-effects models is that they are defined for
data lying in Euclidean spaces. However, measurements with smooth constraints usually cannot be
summed up or scaled, such as normalized scores of neurospychological tests, positive definite symmetric matrices, shapes encoded as images or meshes. These data are naturally modeled as points on
Riemannian manifolds. Although the development of statistical models for manifold-valued data is
a blooming topic, the construction of statistical models for longitudinal data on a manifold remains
an open problem.
The concept of “time-warp” was introduced in [8] to allow for temporal registration of trajectories
of shape changes. Nevertheless, the combination of the time-warps with the intrinsic variability of
shapes across individuals is done at the expense of a simplifying approximation: the variance of
shapes does not depend on time whereas it should adapt with the average scenario of shape changes.
Moreover, the estimation of the parameters of the statistical model is made by minimizing a sum of
squares which results from an uncontrolled likelihood approximation. In [18], time-warps are used
to define a metric between curves that are invariant under time reparameterization. This invariance,
by definition, prevents the estimation of correspondences across trajectories, and therefore the estimation of distribution of trajectories in the spatiotemporal domain. In [17], the authors proposed a
model for longitudinal image data but the model is not built on the inference of a statistical model
and does not include a time reparametrization of the estimated trajectories.
In this paper, we propose a generic statistical framework for the definition and estimation of mixedeffects models for longitudinal manifold-valued data. Using the tools of geometry allows us to derive
a method that makes little assumptions about the data and problem to deal with. Modeling choices
boil down to the definition of the metric on the manifold. This geometrical modeling also allows
us to introduce the concept of parallel curves on a manifold, which is key to uniquely decompose
differences seen in the data in a spatial and a temporal component. Because of the non-linearity
of the model, the estimation of the parameters should be based on an adequate maximization of the
observed likelihood. To address this issue, we propose to use a stochastic version of the ExpectationMaximization algorithm [5], namely the MCMC SAEM [2], for which theoretical results regarding
the convergence have been proved in [4], [2].
Experimental results on neuropsychological tests scores and estimates of scenarios of AD progression are given in section 4.

2
2.1

Spatiotemporal mixed-effects model for manifold-valued data
Riemannian geometry setting

The observed data consists in repeated multivariate measurements of p individuals. For a given
individual, the measurements are obtained at time points ti,1 < . . . < ti,ni . The j-th measurement
of the i-th individual is denoted by yi,j . We assume that each observation yi,j is a point on a
N -dimensional Riemannian manifold M embedded in RP (with P ≥ N ) and equipped with a
Riemannian metric g M . We denote ∇M the covariant derivative. We assume that the manifold is
geodesically complete, meaning that geodesics are defined for all time.
2

We recall that a geodesic is a curve drawn on the manifold γ : R → M, which has no acceleration:
M
∇M
γ̇ γ̇ = 0. For a point p ∈ M and a vector v ∈ Tp M, the mapping Expp (v) denotes the
Riemannian exponential, namely the point that is reached at time 1 by the geodesic starting at p
with velocity v. The parallel transport of a vector X0 ∈ Tγ(t0 ) M in the tangent space at point γ(t0 )
on a curve γ is a time-indexed family of vectors X(t) ∈ Tγ(t) M which satisfies ∇M
˙ X(t) = 0
γ(t)
and X(t0 ) = X0 . We denote Pγ,t0 ,t (X0 ) the isometry that maps X0 to X(t).
In order to describe our model, we need to introduce the notion of “parallel curves” on the manifold:
Definition 1. Let γ be a curve on M defined for all time, a time-point t0 ∈ R and a vector w ∈
Tγ(t0 ) M, w 6= 0. One defines the curve s → η w (γ, s), called parallel to the curve γ, as:

η w (γ, s) = ExpM
γ(s) Pγ,t0 ,s (w) , s ∈ R.
The idea is illustrated in Fig. 1. One uses the parallel transport to move the vector w from γ(t0 ) to
γ(s) along γ. At the point γ(s), a new point on M is obtained by taking the Riemannian exponential
of Pγ,t0 ,s (w). This new point is denoted by η w (γ, s). As s varies, one describes a curve η w (γ, ·)
on M, which can be understood as a “parallel” to the curve γ. It should be pointed out that, even
if γ is a geodesic, η w (γ, ·) is, in general, not a geodesic of M. In the Euclidean case (i.e. a flat
manifold), the curve η w (γ, ·) is the translation of the curve γ: η w (γ, s) = γ(s) + w.

Figure a)

Figure b)

Figure c)

Figure 1: Model description on a schematic manifold. Figure a) (left) : a non-zero vector wi is
choosen in Tγ(t0 ) M. Figure b) (middle) : the tangent vector wi is transported along the geodesic
γ and a point η wi (γ, s) is constructed at time s by use of the Riemannian exponential. Figure c)
(right) : The curve η wi (γ, ·) is the parallel resulting from the construction.
2.2

Generic spatiotemporal model for longitudinal data

Our model is built in a hierarchical manner: data points are seen as samples along individual trajectories, and these trajectories derive from a group-average trajectory. The model writes
yi,j = η wi (γ, ψi (ti,j )) + εi,j , where we assume the group-average trajectory to be a geodesic,
denoted γ from now on. Individual trajectories derive from the group average by spatiotemporal
transformations. They are defined as a time re-parameterization of a trajectory that is parallel to the
group-average: t → η wi (γ, ψi (t)). For the ith individual, wi denotes a non-zero tangent vector in
Tγ(t0 ) M, for some specific time point t0 that needs to be estimated, and which is orthogonal to the
M
tangent vector γ̇(t0 ) for the inner product given by the metric (h·, ·iγ(t0 ) = gγ(t
). The time-warp
0)
function ψi is defined as: ψi (t) = αi (t − t0 − τi ) + t0 . The parameter αi is an acceleration factor
which encodes whether the i-th individual is progressing faster or slower than the average, τi is a
time-shift which characterizes the advance or delay of the ith individual with respect to the average
and wi is a space-shift which encodes the variability in the measurements across individuals at the
same stage of progression.
The normal tubular neighborhood theorem ([11]) ensures that parallel shifting defines a spatiotemporal coordinate system as long as the vectors wi are choosen orthogonal and sufficently small.
The orthogonality condition on the tangent vectors wi is necessary to ensure the identifiability of
the model. Indeed, if a vector wi was not choosen orthogonal, its orthogonal projection would play
the same role as the acceleration factor.The spatial and temporal transformations commute, in the
sense that one may re-parameterize the average trajectory before building the parallel curve, or vice
versa. Mathematically, this writes η wi (γ ◦ ψi , s) = η wi (γ, ψi (s)). This relation also explains the
particular form of the affine time-warp ψi . The geodesic γ is characterized by the fact that it passes
3

at time-point t0 by point p0 = γ(t0 ) with velocity v0 = γ̇(t0 ). Then, γ ◦ ψi is the same trajectory,
except that it passes by point p0 at time t0 + τi with velocity αi v0 .
The fixed effects of the model are the parameters of the average geodesic: the point p0 on the
manifold, the time-point t0 and the velocity v0 . The random effects are the acceleration factors
αi , time-shifts τi and space-shifts wi . The first two random effects are scalars. One assumes the
acceleration factors to follow a log-normal distribution (they need to be positive in order not to
reverse time), and time-shifts to follow a zero-mean Gaussian distribution. Space-shifts are vectors
of dimension N − 1 in the hyperplane γ̇(t0 )⊥ in Tγ(t0 ) M. In the spirit of independent component
analysis [12], we assume that wi ’s result from the superposition of Ns < N statistically independent
components. This writes wi = Asi where A is a N × Ns matrix of rank Ns , si a vector of
Ns independent sources following a heavy tail Laplace distribution with fixed parameter, and each
column cj (A) (1 ≤ j ≤ Ns ) of A satisfies the orthogonality condition hcj (A), γ̇(t0 )iγ(t0 ) = 0.
For the dataset (ti,j , yi,j ) (1 ≤ i ≤ p, 1 ≤ j ≤ ni ), the model may be summarized as:
yi,j = η wi (γ, ψi (ti,j )) + εi,j .

(1)

with ψi (t) = αi (t − t0 − τi ) + t0 , αi = exp(ξi ), wi = Asi and
i.i.d.

i.i.d.

i.i.d.

i.i.d.

ξi ∼ N (0, ση2 ), τi ∼ N (0, στ2 ), εi,j ∼ N (0, σ 2 IN ), si,l ∼ Laplace(1/2).
Eventually, the parameters of the model one needs to estimate are the fixed effects and the variance
of the random effects, namely θ = (p0 , t0 , v0 , σξ , στ , σ, vec(A)).
2.3

Propagation model in a product manifold

We wish to use these developments to study the temporal progression of a family of biomarkers.
We assume that each component of yi,j is a scalar measurement of a given biomarker and belongs
to a geodesically complete one-dimensional manifold (M, g). Therefore, each measurement yi,j is
a point in the product manifold M = M N , which we assume to be equipped with the Riemannian
product metric g M = g + . . . + g. We denote γ 0 the geodesic of the one-dimensional manifold
M which goes through the point p0 ∈ M at time t0 with velocity v0 ∈ Tp0 M . In order to determine relative progression of the biomarkers among themselves,
 we consider a parametric family of
geodesics of M : γ δ (t) = γ0 (t), γ0 (t+δ1 ), . . . , γ0 (t+δN −1 ) . We assume here that all biomarkers
have on average the same dynamics but shifted in time. This hypothesis allows to model a temporal
succession of effects during the course of thedisease. The relative timing in biomarker changes is
measured by the vector δ = 0, δ1 , . . . , δN −1 , which becomes a fixed effect of the model.
In this setting, a curve that is parallel to a geodesic γ is given by the following lemma :
Lemma 1. Let γ be a geodesic of the product manifold M = M N and let t0 ∈ R. If
η w (γ, ·) denotes a parallel to the geodesic γ with w = (w1 , . . . , wN ∈Tγ(t0 ) M and γ(t) =
wN
w1
(γ1 (t), . . . , γN (t)), we have η w (γ, s) = γ1 γ̇(t
+ s , . . . , γN γ̇(t
+ s , s ∈ R.
0)
0)
As a consequence, a parallel to the average trajectory γ δ has the same form as the geodesic but with
randomly perturbed delays. The model (1) writes : for all k ∈ {1, . . . , N },


wk,i
yi,j,k = γ0
+ αi (ti,j − t0 − τi ) + t0 + δk−1 + εi,j,k .
(2)
γ˙0 (t0 + δk−1 )
where wk,i denotes the k-th component of the space-shift wi and yi,j,k , the measurement of the k-th
biomarker, at the j-th time point, for the i-th individual.
2.4

Multivariate logistic curves model

The propagation model given in (2) is now described for normalized biomarkers, such as scores of
neuropsychological tests. In this case, we assume the manifold to be M =]0, 1[ and equipped with
the Riemannian metric g given by : for p ∈]0, 1[, (u, v) ∈ Tp M × Tp M , gp (u, v) = uG(p)v with
G(p) = 1/(p2 (1 − p)2 ). The geodesics given by this metric in the one-dimensional Riemannian
−1
v0
(t − t0 )
manifold M are logistic curves of the form : γ0 (t) = 1 + ( p10 − 1) exp − p0 (1−p
0)
and leads to the multivariate logistic curves model in M. We can notice the quite unusual paramaterization of the logistic curve. This parametrization naturally arise because γ0 satisfies : γ0 (t0 ) = p0
and γ˙0 (t0 ) = v0 . In this case, the model (1) writes:
4

yi,j,k =

1

1+
− 1 exp
p0

−

i )k
v0 αi (ti,j − t0 − τi ) + v0 δk + v0 γ˙0(As
(t0 +δk )

p0 (1 − p0 )

!!−1
+ εi,j,k , (3)

where (Asi )k denotes the k-th component of the vector Asi . Note that (3) is not equivalent to a
linear model on the logit of the observations. The logit transform corresponds to the Riemannian
logarithm at p0 = 0.5. In our framework, p0 is not fixed, but estimated as a parameter of our
model. Even with a fixed p0 = 0.5, the model is still non-linear due to the multiplication between
random-effects αi and τi , and therefore does not boil down to the usual linear model [15].

3

Parameters estimation

In this section, we explain how to use a stochastic version of the Expectation-Maximization (EM)
algorithm [5] to produce estimates of the parameters θ = (p0 , t0 , v0 , δ, σξ , στ , σ, vec(A)) of the
model. The algorithm detailed in this section is essentially the same as in [2]. Its scope of application is not limited to statistical models on product manifolds and the MCMC-SAEM algorithm can
actually be used for the inference of a very large family of statistical models.
The random effects z = (ξi , τi , sj,i ) (1 ≤ i ≤ p and 1 ≤ j ≤ Ns ) are considered as hidden variables.
With the observed data y = (yi,j,k )i,j,k , (y, z) form the complete data of the model. In this context,
the Expectation-Maximization (EM) algorithm proposed in [5] is very efficient to compute the maximum likelihood estimate of θ. Due to the nonlinearity and complexity of the model, the E step is
intractable. As a consequence, we considered a stochastic version of the EM algorithm, namely the
Monte-Carlo Markov Chain Stochastic Approximation Expectation-Maximization (MCMC-SAEM)
algorithm [2], based on [4]. This algorithm is an EM-like algorithm which alternates between three
steps: simulation, stochastic approximation and maximization. If θ (t) denotes the current parameter
estimates of the algorithm, in the simulation step, a sample z(t) of the missing data is obtained from
the transition kernel of an ergodic Markov chain whose stationary distribution is the conditional
distribution of the missing data z knowing y and θ (t) , denoted by q(z | y, θ (t) ). This simulation
step is achieved using Hasting-Metropolis within Gibbs sampler. Note that the high complexity of
our model prevents us from resorting to sampling methods as in [10] as they would require heavy
computations, such as the Fisher information matrix. The stochastic approximation step consists in
a stochastic approximation on the complete log-likelihood log q(y, z | θ) summarized as follows :
Qt (θ) = Qt−1 (θ) + εt [log q(y, zP
| θ) − Qt−1 (θ)], where
P (εt )t is a decreasing sequence of positive
step-sizes in ]0, 1] which satisfies t εt = +∞ and t ε2t < +∞. Finally, the parameter estimates
are updated in the maximization step according to: θ (t+1) = argmaxθ∈Θ Qt (θ).
The theoretical convergence of the MCMC SAEM algorithm is proved only if the model belong to the curved exponential family. Or equivalently, if the complete log-likelihood of the
model may be written : log q(y, z | θ) = −φ(θ) + S(y, z)> ψ(θ), where S(y, z) is a sufficent
statistic of the model. In this case, the stochastic approximation on the complete log-likelihood
can be replaced with a stochastic approximation on the sufficent statistics of the model. Note
that the multivariate logistic curves model does not belong to the curved exponential family. A
usual workaround consists in regarding the parameters of the model as realizations of independents Gaussian random variables ([14]) : θ ∼ N (θ, D) where D is a diagonal matrix with
very small diagonal entries and the estimation now targets θ. This yields: p0 ∼ N (p0 , σp20 ),
t0 ∼ N (t0 , σt20 ), v0 ∼ N (v0 , σv20 ) and, for all k, δk ∼ N (δ k , σδ2 ). To ensure the orthogonality condition on the columns of A, we assumed that A follows a normal distribution on the
N s
space Σ = {A = (c1 (A), . . . , cNs (A)) ∈ Tγδ (t0 ) M
; ∀j, hcj (A), γ˙δ (t0 )iγδ (t0 ) = 0}.
P(N −1)Ns
Equivalently, we assume that the matrix A writes : A =
βk Bk where, for all k,
k=1
i.i.d.

βk ∼ N (β k , σβ2 ) and (B1 , . . . , B(N −1)Ns ) is an orthonormal basis of Σ obtained by application of the Gram-Schmidt process to a basis of Σ. The random variables β1 , . . . , β(N −1)Ns
are considered as new hidden variables of the model. The parameters of the model are θ =
(p0 , t0 , v0 , (δ k )1≤k≤N −1 , (β k )1≤k≤(N −1)Ns , σξ , στ , σ) whereas the hidden variables of the model
are z = (p0 , t0 , v0 , (δk )1≤k≤N −1 , (βk )1≤k≤(N −1)Ns , (ξi )1≤i≤p , (τi )1≤i≤p , (sj,i )1≤j≤Ns , 1≤i≤p ).
The algorithm (1) given below summarizes the SAEM algorithm for this model.
The MCMC-SAEM algorithm 1 was tested on synthetic data generated according to (3). The
MCMC-SAEM allowed to recover the parameters used to generate the synthetic dataset.
5

Algorithm 1 Overview of the MCMC SAEM algorithm for the multivariate logistic curves model.
(k) (k)
(k) 
If z(k) = p0 , t0 , . . . , (sj,i denotes the vector of hidden variables obtained in the simulation step of the k-th iteration of the MCMC SAEM, let fi,j = [fi,j,l ] ∈ RN and fi,j,l
(k)
(k)
(k)
(k) 
(k)
be the l-th component of ηw(k) (γ δ )(k) , exp(ξi )(ti,j − t0 − τi ) + t0
and wi
=
i
P(N −1)Ns (k)
βl Bl .
l=1
Initialization :
θ ← θ (0) ; z(0) ← random ; S ← 0 ; (εk )k≥0 .
repeat

(k) (k)
(k)
Simulation step : z(k) = p0 , t0 , . . . , (sj,i )j,i ← Gibbs Sampler(z(k−1) , y, θ (k−1) )




(k)
>
fi,j i,j ∈ RK ; S(k)
Compute the sufficent statistics : S1 ← yi,j
← kfi,j k2 i,j ∈ RK
2
i
h
Pp
(k)
(k)
(k) 2
∈ Rp ; S4 ←
with (1 ≤ i ≤ p ; 1 ≤ j ≤ ni ) and K =
n
;
S
=
(ξ
)
i
3
i=1
i
i
hi
i
h
(k)
(k)
(k)
(k)
(k)
(k)
(k)
(k)
(k)
∈ RN −1 ;
(τi )2 ∈ Rp ; S5 ← p0 ; S6 ← t0 ; S7 ← v0 ; S8 ← δj
j
hi i
(k)
S9 ← βj(k) ∈ R(N −1)Ns .
j

(k+1)

Stochastic approximation step : Sj

(k)

Maximization step : p0 (k+1) ← S5
(k+1)

(k)

← Sj

; t0

(k+1)

(k)

(k)

+ εk (S(y, z(k) ) − Sj ) for j ∈ {1, . . . , 9}.
(k)

← S6

(k)

; v0 (k+1) ← S7

(k+1)

; δj

(k+1)

(k)

← (S8 )j
(k)

← (S9 )j for all 1 ≤ j ≤ (N − 1)Ns ; σξ
← p1 (S3 )> 1p
1/2
P
(k) >
(k) >
(k+1)
(k)
2
← p1 (S4 )> 1p ; σ (k+1) ← √N1 K
.
; στ
i,j,k yi,j,k − 2(S1 ) 1K + (S2 ) 1K
until convergence.
return θ.
for all 1 ≤ j ≤ N − 1 ; β j

4
4.1

Experiments
Data

We use the neuropsychological assessment test “ADAS-Cog 13” from the ADNI1, ADNIGO or
ADNI2 cohorts of the Alzheimer’s Disease Neuroimaging Initiative (ADNI) [1]. The “ADAS-Cog
13” consists of 13 questions, which allow to test the impairment of several cognitive functions.
For the purpose of our analysis, these items are grouped into four categories: memory (5 items),
language (5 items), praxis (2 items) and concentration (1 item). Scores within each category are
added and normalized by the maximum possible score. Consequently, each data point consists in
four normalized scores, which can be seen as a point on the manifold M =]0, 1[4 .
We included 248 individuals in the study, who were diagnosed with mild cognitive impairment
(MCI) at their first visit and whose diagnosis changed to AD before their last visit. There is an average of 6 visits per subjects (min: 3, max: 11), with an average duration of 6 or 12 months between
consecutive visits. The multivariate logistic curves model was used to analyze this longitudinal data.
4.2

Experimental results

The model was applied with Ns = 1, 2 or 3 independent sources. In each experiment, the MCMC
SAEM was run five times with different initial parameter values. The experiment which returned
the smallest residual variance σ 2 was kept. The maximum number of iterations was arbitrarily set
to 5000 and the number of burn-in iterations was set to 3000 iterations. The limit of 5000 iterations
is enough to observe the convergence of the sequences of parameters estimates. As a result, two
and three sources allowed to decrease the residual variance better than one source (σ 2 = 0.012 for
one source, σ 2 = 0.08 for two sources and σ 2 = 0.084 for three sources). The residual variance
σ 2 = 0.012 (resp. σ 2 = 0.08, σ 2 = 0.084) mean that the model allowed to explain 79% (resp.
84%, 85%) of the total variance. We implemented our algorithm in MATLAB without any particular
optimization scheme. The 5000 iterations require approximately one day.
The number of parameters to be estimated is equal to 9 + 3Ns . Therefore, the number of sources
do not dramatically impact the runtime. Simulation is the most computationally expensive part of
6

our algorithm. For each run of the Hasting-Metropolis algorithm, the proposal distribution is the
prior distribution. As a consequence, the acceptation ratio simplifies [2] and one computation of
the acceptation ratio requires two computations of the likelihood of the observations, conditionally
on different vectors of latent variables and the vector of current parameters estimates. The runtime
could be improved by parallelizing the sampling per individuals.
For a matter of clarity and because the results obtained with three sources were similar to the results
with two sources, we report here the experimental results obtained with two independent sources.
The average model of disease progression γ δ is plotted in Fig. 2. The estimated fixed effects are
p0 = 0.3, t0 = 72 years, v0 = 0.04 unit per year, and δ = [0; −15; −13; −5] years. This means
that, on average, the memory score (first coordinate) reaches the value p0 = 0.3 at t0 = 72 years,
followed by concentration which reaches the same value at t0 + 5 = 77 years, and then by praxis
and language at age 85 and 87 years respectively.
Random effects show the variability of this average trajectory within the studied population. The
standard deviation of the time-shift equals στ = 7.5 years, meaning that the disease progression
model in Fig. 2 is shifted by ±7.5 years to account for the variability in the age of disease onset.
The effects of the variance of the acceleration factors, and the two independent components of the
space-shifts are illustrated in Fig. 4. The acceleration factors shows the variability in the pace of
disease progression, which ranges between 7 times faster and 7 times slower than the average. The
first independent component shows variability in the relative timing of the cognitive impairments:
in one direction, memory and concentration are impaired nearly at the same time, followed by
language and praxis; in the other direction, memory is followed by concentration and then language
and praxis are nearly superimposed. The second independent component keeps almost fixed the
timing of memory and concentration, and shows a great variability in the relative timing of praxis
and language impairment. It shows that the ordering of the last two may be inverted in different
individuals. Overall, these space-shift components show that the onset of cognitive impairment
tends to occur by pairs: memory & concentration followed by language & praxis.
Individual estimates of the random effects are obtained from the simulation step of the last iteration
of the algorithm and are plotted in Fig. 5. The figure shows that the estimated individual time-shifts
correspond well to the age at which individuals were diagnosed with AD. This means that the value
p0 estimated by the model is a good threshold to determine diagnosis (a fact that has occurred by
chance), and more importantly that the time-warp correctly register the dynamics of the individual
trajectories so that the normalized age correspond to the same stage of disease progression across
individuals. This fact is corroborated by Fig. 3 which shows that the normalized age of conversion
to AD is picked at 77 years old with a small variance compared to the real distribution of age of
conversion.

Figure 2: The four curves represent the estimated average trajectory. A vertical line is
drawn at t0 = 72 years old and an horizontal
line is drawn at p0 = 0.3.

Figure 3: In blue (resp. red) : histogram
of the ages of conversion to AD (tdiag
i )
(resp. normalized ages of conversion to AD
(ψi (tdiag
i ))), with ψi time-warp as in (1).
7

Acceleration factor 𝛼𝑖

Independent component 𝐴1

Independent component 𝐴2

-σ

+σ

Figure 4: Variability in disease progression superimposed with the average trajectory
γ δ (dotted

lines): effects of the acceleration factor with plots of γ δ exp(±σξ )(t − t0 ) + t0 (first column),
first and second independent component of space-shift with plots of η ±σsi ci (A) (γ δ , ·) for i = 1 or
2 (second and third column respectively).

Figure 5: Plots of individual random effects:
log-acceleration factor ξi = log(αi ) against
time-shifts t0 + τi . Color corresponds to the
age of conversion to AD.

4.3

Discussion and perspectives

We proposed a generic spatiotemporal model to analyze longitudinal manifold-valued measurements. The fixed effects define a group-average trajectory, which is a geodesic on the data manifold.
Random effects are subject-specific acceleration factor, time-shift and space-shift which provide insightful information about the variations in the direction of the individual trajectories and the relative
pace at which they are followed.
This model was used to estimate a normative scenario of Alzheimer’s disease progression from
neuropsychological tests. We validated the estimates of the spatiotemporal registration between
individual trajectories by the fact that they put into correspondence the same event on individual
trajectories, namely the age at diagnosis. Alternatives to estimate model of disease progression
include the event-based model [9], which estimates the ordering of categorical variables. Our model
may be seen as a generalization of this model for continuous variables, which do not only estimate
the ordering of the events but also the relative timing between them. Practical solutions to combine
spatial and temporal sources of variations in longitudinal data are given in [7]. Our goal was here to
propose theoretical and algorithmic foundations for the systematic treatment of such questions.
8

References
[1] The Alzheimer’s Disease Neuroimaging Initiative, https://ida.loni.usc.edu/
[2] Allassonnière, S., Kuhn, E., Trouvé, A.: Construction of bayesian deformable models via a stochastic
approximation algorithm: a convergence study. Bernoulli 16(3), 641–678 (2010)
[3] Braak, H., Braak, E.: Staging of alzheimer’s disease-related neurofibrillary changes. Neurobiology of
aging 16(3), 271–278 (1995)
[4] Delyon, B., Lavielle, M., Moulines, E.: Convergence of a stochastic approximation version of the em
algorithm. Annals of statistics pp. 94–128 (1999)
[5] Dempster, A.P., Laird, N.M., Rubin, D.B.: Maximum likelihood from incomplete data via the em algorithm. Journal of the royal statistical society. Series B (methodological) pp. 1–38 (1977)
[6] Diggle, P., Heagerty, P., Liang, K.Y., Zeger, S.: Analysis of longitudinal data. Oxford University Press
(2002)
[7] Donohue, M.C., Jacqmin-Gadda, H., Le Goff, M., Thomas, R.G., Raman, R., Gamst, A.C., Beckett, L.A.,
Jack, C.R., Weiner, M.W., Dartigues, J.F., Aisen, P.S., the Alzheimer’s Disease Neuroimaging Initiative:
Estimating long-term multivariate progression from short-term data. Alzheimer’s & Dementia 10(5), 400–
410 (2014)
[8] Durrleman, S., Pennec, X., Trouvé, A., Braga, J., Gerig, G., Ayache, N.: Toward a comprehensive framework for the spatiotemporal statistical analysis of longitudinal shape data. International Journal of Computer Vision 103(1), 22–59 (2013)
[9] Fonteijn, H.M., Modat, M., Clarkson, M.J., Barnes, J., Lehmann, M., Hobbs, N.Z., Scahill, R.I., Tabrizi,
S.J., Ourselin, S., Fox, N.C., et al.: An event-based model for disease progression and its application in
familial alzheimer’s disease and huntington’s disease. NeuroImage 60(3), 1880–1889 (2012)
[10] Girolami, M., Calderhead, B.: Riemann manifold langevin and hamiltonian monte carlo methods. Journal
of the Royal Statistical Society: Series B (Statistical Methodology) 73(2), 123–214 (2011)
[11] Hirsch, M.W.: Differential topology. Springer Science & Business Media (2012)
[12] Hyvärinen, A., Karhunen, J., Oja, E.: Independent component analysis, vol. 46. John Wiley & Sons
(2004)
[13] Jack, C.R., Knopman, D.S., Jagust, W.J., Shaw, L.M., Aisen, P.S., Weiner, M.W., Petersen, R.C., Trojanowski, J.Q.: Hypothetical model of dynamic biomarkers of the alzheimer’s pathological cascade. The
Lancet Neurology 9(1), 119–128 (2010)
[14] Kuhn, E., Lavielle, M.: Maximum likelihood estimation in nonlinear mixed effects models. Computational Statistics & Data Analysis 49(4), 1020–1038 (2005)
[15] Laird, N.M., Ware, J.H.: Random-effects models for longitudinal data. Biometrics pp. 963–974 (1982)
[16] Singer, J.D., Willett, J.B.: Applied longitudinal data analysis: Modeling change and event occurrence.
Oxford university press (2003)
[17] Singh, N., Hinkle, J., Joshi, S., Fletcher, P.T.: A hierarchical geodesic model for diffeomorphic longitudinal shape analysis. In: Information Processing in Medical Imaging. pp. 560–571. Springer (2013)
[18] Su, J., Kurtek, S., Klassen, E., Srivastava, A., et al.: Statistical analysis of trajectories on riemannian
manifolds: Bird migration, hurricane tracking and video surveillance. The Annals of Applied Statistics
8(1), 530–552 (2014)

9

