Online Rank Elicitation for Plackett-Luce:
A Dueling Bandits Approach
Balázs Szörényi
Technion, Haifa, Israel /
MTA-SZTE Research Group on
Artificial Intelligence, Hungary
szorenyibalazs@gmail.com

Róbert Busa-Fekete, Adil Paul, Eyke Hüllermeier
Department of Computer Science
University of Paderborn
Paderborn, Germany
{busarobi,adil.paul,eyke}@upb.de

Abstract
We study the problem of online rank elicitation, assuming that rankings of a set
of alternatives obey the Plackett-Luce distribution. Following the setting of the
dueling bandits problem, the learner is allowed to query pairwise comparisons
between alternatives, i.e., to sample pairwise marginals of the distribution in an
online fashion. Using this information, the learner seeks to reliably predict the
most probable ranking (or top-alternative). Our approach is based on constructing
a surrogate probability distribution over rankings based on a sorting procedure, for
which the pairwise marginals provably coincide with the marginals of the PlackettLuce distribution. In addition to a formal performance and complexity analysis,
we present first experimental studies.

1

Introduction

Several variants of learning-to-rank problems have recently been studied in an online setting, with
preferences over alternatives given in the form of stochastic pairwise comparisons [6]. Typically, the
learner is allowed to select (presumably most informative) alternatives in an active way—making a
connection to multi-armed bandits, where single alternatives are chosen instead of pairs, this is also
referred to as the dueling bandits problem [28].
Methods for online ranking can mainly be distinguished with regard to the assumptions they make
about the probabilities pi,j that, in a direct comparison between two alternatives i and j, the former
is preferred over the latter. If these probabilities are not constrained at all, a complexity that grows
quadratically in the number M of alternatives is essentially unavoidable [27, 8, 9]. Yet, by exploiting
(stochastic) transitivity properties, which are quite natural in a ranking context, it is possible to
devise algorithms with better performance guaranties, typically of the order M log M [29, 28, 7].
The idea of exploiting transitivity in preference-based online learning establishes a natural connection to sorting algorithms. Naively, for example, one could simply apply an efficient sorting
algorithm such as MergeSort as an active sampling scheme, thereby producing a random order of
the alternatives. What can we say about the optimality of such an order? The problem is that the
probability distribution (on rankings) induced by the sorting algorithm may not be well attuned with
the original preference relation (i.e., the probabilities pi,j ).
In this paper, we will therefore combine a sorting algorithm, namely QuickSort [15], and a stochastic preference model that harmonize well with each other—in a technical sense to be detailed later
on. This harmony was first presented in [1], and our main contribution is to show how it can be
exploited for online rank elicitation. More specifically, we assume that pairwise comparisons obey
the marginals of a Plackett-Luce model [24, 19], a widely used parametric distribution over rankings
(cf. Section 5). Despite the quadratic worst case complexity of QuickSort, we succeed in developing
its budgeted version (presented in Section 6) with a complexity of O(M log M ). While only returning partial orderings, this version allows us to devise PAC-style algorithms that find, respectively, a
close-to-optimal item (Section 7) and a close-to-optimal ranking of all items (Section 8), both with
high probability.
1

2

Related Work

Several studies have recently focused on preference-based versions of the multi-armed bandit setup,
also known as dueling bandits [28, 6, 30], where the online learner is only able to compare arms in
a pairwise manner. The outcome of the pairwise comparisons essentially informs the learner about
pairwise preferences, i.e., whether or not an option is preferred to another one. A first group of
papers, including [28, 29], assumes the probability distributions of pairwise comparisons to possess
certain regularity property, such as strong stochastic transitivity. A second group does not make
assumptions of that kind; instead, a target (“ground-truth”) ranking is derived from the pairwise
preferences, for example using the Copeland, Borda count and Random Walk procedures [9, 8, 27].
Our work is obviously closer to the first group of methods. In particular, the study presented in this
paper is related to [7] which investigates a similar setup for the Mallows model.
There are several approaches to estimating the parameters of the Plackett-Luce (PL) model, including standard statistical methods such as likelihood estimation [17] and Bayesian parameter estimation [14]. Pairwise marginals are also used in [26], in connection with the method-of-moments
approach; nevertheless, the authors assume that full rankings are observed from a PL model.
Algorithms for noisy sorting [2, 3, 12] assume a total order over the items, and that the comparisons
are representative of that order (if i precedes j, then the probability of option i being preferred to
j is bigger than some > 1/2). In [25], the data is assumed to consist of pairwise comparisons
generated by a Bradley-Terry model, however, comparisons are not chosen actively but according to
some fixed probability distribution.
Pure exploration algorithms for the stochastic multi-armed bandit problem sample the arms a certain
number of times (not necessarily known in advance), and then output a recommendation, such as the
best arm or the m best arms [4, 11, 5, 13]. While our algorithms can be viewed as pure exploration
strategies, too, we do not assume that numerical feedback can be generated for individual options;
instead, our feedback is qualitative and refers to pairs of options.

3

Notation

A set of alternatives/options/items to be ranked is denoted by I. To keep the presentation simple,
we assume that items are identified by natural numbers, so I = [M ] = {1, . . . , M }. A ranking is a
bijection r on I, which can also be represented as a vector r = (r1 , . . . , rM ) = (r(1), . . . , r(M )),
where rj = r(j) is the rank of the jth item. The set of rankings can be identified with the symmetric
group SM of order M . Each ranking r naturally defines an associated ordering o = (o1 , . . . , oM ) 2
SM of the items, namely the inverse o = r 1 defined by or(j) = j for all j 2 [M ].
For a permutation r, we write r(i, j) for the permutation in which ri and rj , the ranks of items i
and j, are replaced with each other. We denote by L(ri = j) = {r 2 SM | ri = j} the subset of
permutations for which the rank of item i is j, and by L(rj > ri ) = {r 2 SM | rj > ri } those for
which the rank of j is higher than the rank of i, that is, item i is preferred to j, written i j. We
write i r j to indicate that i is preferred to j with respect to ranking r.

We assume SM to be equipped with a probability distribution P : SM ! [0, 1]; thus, for each
ranking r, we denote by P(r) the probability to observe this ranking. Moreover, for each pair of
items i and j, we denote by
X
pi,j = P(i j) =
P(r)
(1)
r2L(rj >ri )

the probability that i is preferred to j (in a ranking randomly drawn according to P). These pairwise
probabilities are called the pairwise marginals of the ranking distribution P. We denote the matrix
composed of the values pi,j by P = [pi,j ]1i,jM .

4

Preference-based Approximations

Our learning problem essentially consists of making good predictions about properties of P. Concretely, we consider two different goals of the learner, depending on whether the application calls
for the prediction of a single item or a full ranking of items:
In the first problem, which we call PAC-Item or simply PACI, the goal is to find an item that is
almost as good as the optimal one, with optimality referring to the Condorcet winner. An item i⇤ is
2

a Condorcet winner if pi⇤ ,i > 1/2 for all i 6= i⇤ . Then, we call an item j a PAC-item, if it is beaten
by the Condorcet winner with at most an ✏-margin: |pi⇤ ,j 1/2| < ✏. This setting coincides with
those considered in [29, 28]. Obviously, it requires the existence of a Condorcet winner, which is
indeed guaranteed in our approach, thanks to the assumption of a Plackett-Luce model.
The second problem, called AMPR, is defined as finding the most probable ranking [7], that is,
r⇤ = argmaxr2SM P(r). This problem is especially challenging for ranking distributions for which
the order of two items is hard to elicit (because many entries of P are close to 1/2). Therefore, we
again relax the goal of the learner and only require it to find a ranking r with the following property:
There is no pair of items 1  i, j  M , such that ri⇤ < rj⇤ , ri > rj and pi,j > 1/2 + ✏. Put in
words, the ranking r is allowed to differ from r⇤ only for those items whose pairwise probabilities
are close to 1/2. Any ranking r satisfying this property is called an approximately most probable
ranking (AMPR).
Both goals are meant to be achieved with probability at least 1
, for some > 0. Our learner
operates in an online setting. In each iteration, it is allowed to gather information by asking for a
single pairwise comparison between two items—or, using the dueling bandits jargon, to pull two
arms. Thus, it selects two items i and j, and then observes either preference i
j or j
i; the
former occurs with probability pi,j as defined in (1), the latter with probability pj,i = 1 pi,j . Based
on this observation, the learner updates its estimates and decides either to continue the learning
process or to terminate and return its prediction. What we are mainly interested in is the sample
complexity of the learner, that is, the number of pairwise comparisons it queries prior to termination.
Before tackling the problems introduced above, we need some additional notation. The pair of items
chosen by the learner in the t-th comparison is denoted (it , j t ), where it < j t , and the feedback
received is defined as ot = 1 if it
j t and ot = 0 if j t
it . The set of steps among the
t
first t iterations in which the learner decides to compare items i and j is denoted by Ii,j
= {` 2
` `
t
t 1
[t] | (i , j ) = (i, j)}, and the size of this set by ni,j = #Ii,j . The proportion of “wins” of item
P
t
`
i against item j up to iteration t is then given by pbi,j
= n1t
`2I t o . Since our samples are
i,j

i,j

t
independent and identically distributed (i.i.d.), the relative frequency pbi,j
is a reasonable estimate of
the pairwise probability (1).

5

The Plackett-Luce Model

The Plackett-Luce (PL) model is a widely-used probability distribution on rankings [24, 19]. It is
parameterized by a “skill” vector v = (v1 , . . . , vM ) 2 RM
+ and mimics the successive construction
of a ranking by selecting items position by position, each time choosing one of the remaining items
i with a probability proportional to its skill vi . Thus, with o = r 1 , the probability of a ranking r is
P(r | v) =

M
Y

v oi
.
v + voi+1 + · · · + voM
i=1 oi

(2)

As an appealing property of the PL model, we note that the marginal probabilities (1) are very easy
to calculate [21], as they are simply given by
vi
pi,j =
.
(3)
vi + vj
Likewise, the most probable ranking r⇤ can be obtained quite easily, simply by sorting the items
according to their skill parameters, that is, ri⇤ < rj⇤ iff vi > vj . Moreover, the PL model satisfies
strong stochastic transitivity, i.e., pi,k max(pi,j , pj,k ) whenever pi,j 1/2 and pj,k 1/2 [18].

6

Ranking Distributions based on Sorting

In the classical sorting literature, the outcome of pairwise comparisons is deterministic and determined by an underlying total order of the items, namely the order the sorting algorithm seeks to find.
Now, if the pairwise comparisons are stochastic, the sorting algorithm can still be run, however, the
result it will return is a random ranking. Interestingly, this is another way to define a probability distribution over the rankings: P(r) = P(r | P) is the probability that r is returned by the algorithm if
1

We omit the index t if there is no danger of confusion.

3

stochastic comparisons are specified by P. Obviously, this view is closely connected to the problem
of noisy sorting (see the related work section).
In a recent work by Ailon [1], the well-known QuickSort algorithm is investigated in a stochastic
setting, where the pairwise comparisons are drawn from the pairwise marginals of the Plackett-Luce
model. Several interesting properties are shown about the ranking distribution based on QuickSort,
notably the property of pairwise stability. We denote the QuickSort-based ranking distribution by
PQS (· | P), where the matrix P contains the marginals (3) of the Plackett-Luce model. Then, it can
be shown that PQS (· | P) obeys the property of pairwise stability, which means that it preserves the
marginals, although the distributions themselves might not be identical, i.e., PQS (· | P) 6= P(· | v).
Theorem 1 (Theorem 4.1 in [1]). LetP
P be given by the pairwise marginals (3), i.e., pi,j = vi /(vi +
vj ). Then, pi,j = PQS (i j | P) = r2L(rj >ri ) PQS (r | P).

One drawback of the QuickSort algorithm is its complexity: To generate a random ranking, it compares O(M 2 ) items in the worst case. Next, we shall introduce a budgeted version of the QuickSort algorithm, which terminates if the algorithm compares too many pairs, namely, more than
O(M log M ). Upon termination, the modified Quicksort algorithm only returns a partial order.
Nevertheless, we will show that it still preserves the pairwise stability property.
6.1 The Budgeted QuickSort-based Algorithm
Algorithm 1 shows a budgeted version of the
QuickSort-based random ranking generation Algorithm 1 BQS(A, B)
process described in the previous section. It Require: A, the set to be sorted, and a budget B
works in a way quite similar to the standard Ensure: (r, B 00 ), where B 00 is the remaining budQuickSort-based algorithm, with the notable
get, and r is the (partial) order that was condifference of terminating as soon as the number
structed based on B B 00 samples
of pairwise comparisons exceeds the budget B, 1: Initialize r to be the empty partial order over A
which is a parameter assumed as an input. Ob- 2: if B  0 or |A|  1 then return (r, 0)
viously, the BQS algorithm run with A = [M ] 3: pick an element i 2 A uniformly at random
and B = 1 (or B > M 2 ) recovers the orig- 4: for all j 2 A \ {i} do
inal QuickSort-based sampling algorithm as a 5:
draw a random sample oij according to the
special case.
PL marginal (3)
update r accordingly
A run of BQS(A, 1) can be represented quite 6:
naturally as a random tree ⌧ : the root is labeled 7: A0 = {j 2 A | j 6= i & oi,j = 0}
[M ], end whenever a call to BQS(A, B) initi- 8: A1 = {j 2 A | j 6= i & oi,j = 1}
ates a recursive call BQS(A0 , B 0 ), a child node 9: (r0 , B 0 ) = BQS(A0 , B |A| + 1)
with label A0 is added to the node with label A. 10: (r00 , B 00 ) = BQS(A1 , B 0 )
Note that each such tree determines a ranking, 11: update r based on r0 and r00
12: return (r, B 00 )
which is denoted by r⌧ , in a natural way.
The random ranking generated by BQS(A, 1)
for some subset A ✓ [M ] was analyzed by Ailon [1], who showed that it gives back the same
marginals as the original Plackett-Luce model (as recalled in Theorem 1). Now, for B > 0, denote
by ⌧ B the tree the algorithm would have returned for the budget B instead of 1. 2 Additionally, let
B
T B denote the set of all possible outcomes of ⌧ B , and for two distinct indices i and j, let Ti,j
denote
B
the set of all trees T 2 T in which i and j are incomparable in the associated ranking (i.e., some
leaf of T is labelled by a superset of {i, j}).
The main result of this section is that BQS does not introduce any bias in the marginals (3), i.e.,
Theorem 1 also holds for the budgeted version of BQS.
Proposition 2. For any B > 0, any set A ✓ I and any indices i, j 2 A, the partial order r = r⌧ B
B
i
generated by BQS(A, B) satisfies P(i r j | ⌧ B 2 T B \ Ti,j
) = viv+v
.
j
That is, whenever two items i and j are comparable by the partial ranking r generated by BQS,
i
i r j with probability exactly viv+v
. The basic idea of the proof (deferred to the appendix) is to
j
show that, conditioned on the event that i and j are incomparable by r, i r j would have been
2
Put differently, ⌧ is obtained from ⌧ B by continuing the execution of BQS ignoring the stopping criterion
B  0.

4

i
obtained with probability viv+v
in case execution of BQS had been continued (see Claim 6). The
j
result then follows by combining this with Theorem 1.

7

The PAC-Item Problem and its Analysis

Our algorithm for finding the PAC item is
based on the sorting-based sampling tech- Algorithm 2 PLPAC( , ✏)
nique described in the previous section. The 1: for i, j = 1 ! M do
. Initialization
pseudocode of the algorithm, called PLPAC, 2:
b
pbi,j = 0
. P = [b
pi,j ]M ⇥M
is shown in Algorithm 2. In each iteration,
b
3:
n
=
0
.
N
=
[n
i,j
i,j ]M ⇥M
we generate a ranking, which is partial (line
6), and translate this ranking into pairwise 4: Set A = {1, . . . , M }
comparisons that are used to update the es- 5: repeat
r = BQS(A, a 1) where a = #A
.
timates of the pairwise marginals. Based on 6:
Sorting based random ranking
these estimates, we apply a simple eliminab and N correspondtion strategy, which consists of eliminating an 7:
update the entries of P
item i if it is significantly beaten by another
ing to A basedron r
item j, that is, pbi,j + ci,j < 1/2 (lines 9–
4M 2 n2i,j
set ci,j = 2n1i,j log
for all i 6= j
11). Finally, the algorithm terminates when 8:
it finds a PAC-item for which, by definition, 9:
for (i, j 2 A) ^ (i 6= j) do
|pi⇤ ,i 1/2| < ✏. To identify an item i as 10:
if pbi,j + ci,j < 1/2 then
a PAC-item, it is enough to guarantee that i 11:
A = A \ {i}
. Discard
is not beaten by any j 2 A with a margin
12:
C
=
{i
2
A
|
(8j
2
A
\
{i})
bigger than ✏, that is, pi,j > 1/2 ✏ for all
pbi,j ci,j > 1/2 ✏}
j 2 A. This sufficient condition is implemented in line 12. Since we only have empir- 13: until (#C 1)
ical estimates of the pi,j values, the test of the 14: return C
condition does of course also take the confidence intervals into account.
Note that vi = vj , i 6= j, implies pi,j = 1/2. In this case, it is not possible to decide whether pi,j
is above 1/2 or not on the basis of a finite number of pairwise comparisons. The ✏-relaxation of the
goal to be achieved provides a convenient way to circumvent this problem.
7.1

Sample Complexity Analysis of PLPAC

First, let rt denote the (partial) ordering produced by BQS in the t-th iteration. Note that each of
these (partial) orderings defines a bucket order: The indices are partitioned into different classes
(buckets) in such a way that none of the pairs are comparable within one class, but pairs from
different classes are; thus, if i and i0 belong to some class and j and j 0 belong to some other class,
then either i rt j and i0 rt j 0 , or j rt i and j 0 rt i0 . More specifically, the BQS algorithm
with budget a 1 (line 6) always results in a bucket order containing only two buckets since no
recursive call is carried out with this budget. Then one might show that the optimal arm i⇤ and
an arbitrary arm i(6= i⇤ ) fall into different buckets “often enough”. This observation allows us to
upper-bound the number of pairwise comparisons taken by PLPAC with high probability. The proof
of the next theorem is deferred to Appendix B.
vi⇤ v i
= (1/2) max{✏, pi⇤ ,i 1/2} = (1/2) max{✏, 2(v
} for each index i 6= i⇤ .
i⇤ +vi )
⇣
⌘
With probability at least 1
, after O maxi6=i⇤ 12 log Mi
calls for BQS with budget M
i
1, ⇣PLPAC terminates and ⌘outputs an ✏-optimal arm. Therefore, the total number of samples is
O M maxi6=i⇤ 12 log Mi .

Theorem 3. Set

i

i

In Theorem 3, the dependence on M is of order M log M . It is easy to show that ⌦(M log M ) is a
lower bound, therefore our result is optimal from this point of view.
Our model assumptions based on the PL model imply some regularity properties for the pairwise
marginals, such as strong stochastic transitivity and stochastic triangle inequality (see Appendix
A of [28] for the proof). Therefore, the I NTERLEAVED F ILTER [28] and B EAT T HE M EAN [29]
algorithms can be directly applied in our online framework. Both algorithms achieve a similar
sample complexity of order M log M . Yet, our experimental study in Section 9.1 clearly shows
that, provided our model assumptions on pairwise marginals are valid, PLPAC outperforms both
algorithms in terms of empirical sample complexity.
5

8

The AMPR Problem and its Analysis

For strictly more than two elements, the sorting-based surrogate distribution and the PL distribution
are in general not identical, although their mode rankings coincide [1]. The mode r⇤ of a PL model
is the ranking that sorts the items in decreasing order of their skill values: ri < rj iff vi > vj
for any i 6= j. Moreover, since vi > vj implies pi,j > 1/2, sorting based on the Copeland score
bi = #{1  j  M | (i 6= j) ^ (pi,j > 1/2)} yields a most probable ranking r⇤ .
Our algorithm is based on estimating the Copeland score of the items. Its pseudo-code is shown in
Algorithm 3 in Appendix C. As a first step, it generates rankings based on sorting, which is used to
b Then, it computes a lower and upper bound b and bi
update the pairwise probability estimates P.
i
for each of the scores bi . The lower bound is given as bi = #{j 2 [M ]\{i} | pbi,j c > 1/2}, which
is the number of items that are beaten by item i based on the current empirical estimates of pairwise
marginals. Similarly, the upper bound is given as bi = bi + si , where si = #{j 2 [M ] \ {i} | 1/2 2
[b
pi,j c, pbi,j + c]}. Obviously, si is the number of pairs for which, based on the current empirical
estimates, it cannot be decided whether pi,j is above or below 1/2.
As an important observation, note that there is no need to generate a full ranking based on sorting
in every case, because if [bi , bi ] \ [bj , bj ] = ;, then we already know the order of items i and j with
respect to r⇤ . Motivated by this observation, consider the interval graph G = ([M ], E) based on the
[bi , bi ], where E = {(i, j) 2 [M ]2 | [bi , bi ] \ [bj , bj ] 6= ;}. Denote the connected components of this
graph by C1 , . . . , Ck ✓ [M ]. Obviously, if two items belong to different components, then they do
not need to be compared anymore. Therefore, it is enough to call the sorting-based sampling with
the connected components.

Finally, the algorithm terminates if the goal is achieved (line 20). More specifically, it terminates if
there is no pair of items i and j, for which the ordering with respect to r⇤ is not elicited yet, i.e.,
[bi , bi ] \ [bj , bj ] 6= ;, and their pairwise probabilities is close to 1/2, i.e., |pi,j 1/2| < ✏.
8.1

Sample Complexity Analysis of PLPAC-AMPR

Denote by qM the expected number of comparisons of the (standard) QuickSort algorithm on M
elements, namely, qM = 2M log M + O(log M ) (see e.g., [22]). Thanks to the concentration
property of the performance of the QuickSort algorithm, there is no pair of items that falls into the
same bucket “too often” in bucket order which is output by BQS. This observation allows us to
upper-bound the number of pairwise comparisons taken by PLPAC-AMPR with high probability.
The proof of the next theorem is deferred to Appendix D.
Theorem 4. Set

v

v

(i)
= (1/2) max{✏, 2(v(i+1)
} for each 1  i  M , where v(i) denotes the i(i+1) +v(i) )
⇣
⌘
th largest skill parameter. With probability at least 1
, after O max1iM 1 ( 01 )2 log M
0

0
(i)

(i)

(i)

calls for BQS with budget 32 qM , the algorithm
arm.
⇣ PLPAC terminates and outputs an ✏-optimal
⌘
Therefore, the total number of samples is O (M log M ) max1iM 1 ( 01 )2 log M
.
0
(i)

(i)

Remark 5. The RankCentrality algorithm proposed in [23] converts the empirical pairwise
b into a row-stochastic matrix Q.
b Then, considering Q
b as a transition matrix of a
marginals P
Markov chain, it ranks the items based on its stationary distribution. In [25], the authors show that
if the pairwise marginals obey a PL distribution, this algorithm produces the mode of this distribution if the sample size is sufficiently large. In their setup, the learning algorithm has no influence on
the selection of pairs to be compared; instead, comparisons are sampled using a fixed underlying
distribution over the pairs. For any sampling distribution, their PAC bound is of order at least M 3 ,
whereas our sample complexity bound in Theorem 4 is of order M log2 M .

9

Experiments

Our approach strongly exploits the assumption of a data generating process that can be modeled by
means of a PL distribution. The experimental studies presented in this section are mainly aimed at
showing that it is doing so successfully, namely, that it has advantages compared to other approaches
in situations where this model assumption is indeed valid. To this end, we work with synthetic data.
6

Nevertheless, in order to get an idea of the robustness of our algorithm toward violation of the model
assumptions, some first experiments on real data are presented in Appendix I.3
9.1

The PAC-Item Problem

We compared our PLPAC algorithm with other preference-based algorithms applicable in our setting, namely I NTERLEAVED F ILTER (IF) [28], B EAT T HE M EAN (BTM) [29] and M ALLOWS MPI
[7]. While each of these algorithms follows a successive elimination strategy and discards items
one by one, they differ with regard to the sampling strategy they follow. Since the time horizon
must be given in advance for IF, we run it with T 2 {100, 1000, 10000}, subsequently referred
to as IF(T ). The BTM algorithm can be accommodated into our setup as is (see Algorithm 3 in
[29]). The M ALLOWS MPI algorithm assumes a Mallows model [20] instead of PL as an underlying
probability distribution over rankings, and it seeks to find the Condorcet winner—it can be applied
in our setting, too, since a Condorcet winner does exist for PL. Since the baseline methods are not
able to handle ✏-approximation except the BTM, we run our algorithm with ✏ = 0 (and made sure
that vi 6= vj for all 1  i 6= j  M ).

4

#10 4

7
PLPAC
IF(100)
IF(1000)
IF(10000)
BTM
MallowsMPI

6

3
2
1
0

5

#10 4

18
PLPAC
IF(100)
IF(1000)
IF(10000)
BTM
MallowsMPI

16

Sample complexity

5

Sample complexity

Sample complexity

6

4
3
2
1

5

10

15

0

14
12

#10 4
PLPAC
IF(100)
IF(1000)
IF(10000)
BTM
MallowsMPI

10
8
6
4
2

5

10

15

0

5

10

Number of arms

Number of arms

Number of arms

(a) c = 0

(b) c = 2

(c) c = 5

Figure 1: The sample complexity for M = {5, 10, 15},
over 100 repetitions.

15

= 0.1, ✏ = 0. The results are averaged

We tested the learning algorithm by setting the parameters of PL to vi = 1/(c + i) with c =
{0, 1, 2, 3, 5}. The parameter c controls the complexity of the rank elicitation task, since the gaps
between pairwise probabilities and 1/2 are of the form |pi,j 1/2| = | 12 1+1i+c |, which converges
j+c

to zero as c ! 1. We evaluated the algorithm on this test case with varying numbers of items
M = {5, 10, 15} and with various values of parameter c, and plotted the sample complexities, that
is, the number of pairwise comparisons taken by the algorithms prior to termination. The results
are shown in Figure 1 (only for c = {0, 2, 5}, the rest of the plots are deferred to Appendix E). As
can be seen, the PLPAC algorithm significantly outperforms the baseline methods if the pairwise
comparisons match with the model assumption, namely, they are drawn from the marginals of a PL
distribution. M ALLOWS MPI achieves a performance that is slightly worse than PLPAC for M = 5,
and its performance is among the worst ones for M = 15. This can be explained by the elimination
strategy of M ALLOWS MPI, which heavily relies on the existence of a gap mini6=j |pi,j 1/2| > 0
between all pairwise probabilities and 1/2; in our test case, the minimal gap pM,M 1 1/2 =
1
1/2 > 0 is getting smaller with increasing M and c . The poor performance of BTM
2 1/(c+M )
for large c and M can be explained by the same argument.
9.2

The AMPR Problem

Since the RankCentrality algorithm produces the most probable ranking if the pairwise marginals
obey a PL distribution and the sample size is sufficiently large (cf. Remark 5), it was taken as a baseline. Using the same test case as before, input data of various size was generated for RankCentrality
based on uniform sampling of pairs to be compared. Its performance is shown by the black lines in
Figure 2 (the results for c = {1, 3, 4} are again deferred to Appendix F). The accuracy in a single
run of the algorithm is 1 if the output of RankCentrality is identical with the most probable ranking,
and 0 otherwise; this accuracy was averaged over 100 runs.
3
In addition, we conducted some experiments to asses the impact of parameter ✏ and to test our algorithms
based on Clopper-Pearson confidence intervals. These experiments are deferred to Appendix H and G due to
lack of space.

7

0.8

0.6

0.4
RankCentrality (M=5)
RankCentrality (M=10)
RankCentrality (M=15)
PLPAC-AMPR (M=5)
PLPAC-AMPR (M=10)
PLPAC-AMPR (M=15)

0.2

0
10 2

10 4

10 6

1

0.8

0.6

0.4
RankCentrality (M=5)
RankCentrality (M=10)
RankCentrality (M=15)
PLPAC-AMPR (M=5)
PLPAC-AMPR (M=10)
PLPAC-AMPR (M=15)

0.2

0
10 2

10 4

10 6

Optimal recovery fraction

1

Optimal recovery fraction

Optimal recovery fraction

1

0.8

0.6

0.4
RankCentrality (M=5)
RankCentrality (M=10)
RankCentrality (M=15)
PLPAC-AMPR (M=5)
PLPAC-AMPR (M=10)
PLPAC-AMPR (M=15)

0.2

0
10 2

10 4

Sample size

Sample size

Sample size

(a) c = 0

(b) c = 2

(c) c = 5

10 6

Figure 2: Sample complexity for finding the approximately most probable ranking (AMPR) with
parameters M 2 {5, 10, 15}, = 0.05, ✏ = 0. The results are averaged over 100 repetitions.
We also run our PLPAC-AMPR algorithm and determined the number of pairwise comparisons it
takes prior to termination. The horizontal lines in Figure 2 show the empirical sample complexity
achieved by PLPAC-AMPR with ✏ = 0. In accordance with Theorem 4, the accuracy of PLPACAMPR was always significantly higher than 1
(actually equal to 1 in almost every case).
As can be seen, RankCentrality slightly outperforms PLPAC-AMPR in terms of sample complexity,
that is, it achieves an accuracy of 1 for a smaller number of pairwise comparisons. Keep in mind,
however, that PLPAC-AMPR only terminates when its output is correct with probability at least
1
. Moreover, it computes the confidence intervals for the statistics it uses based on the ChernoffHoeffding bound, which is known to be very conservative. As opposed to this, RankCentrality is
an offline algorithm without any performance guarantee if the sample size in not sufficiently large
(see Remark 5). Therefore, it is not surprising that, asymptotically, its empirical sample complexity
shows a better behavior than the complexity of our online learner.
As a final remark, ranking distributions can principally be defined based on any sorting algorithm,
for example MergeSort. However, to the best of our knowledge, pairwise stability has not yet
been shown for any sorting algorithm other than QuickSort. We empirically tested the MergeSort algorithm in our experimental study, simply by using it in place of budgeted QuickSort in the
PLPAC-AMPR algorithm. We found MergeSort inappropriate for the PL model, since the accuracy of PLPAC-AMPR, when being used with MergeSort instead of QuickSort, drastically drops
on complex tasks; for details, see Appendix J. The question of pairwise stability of different sorting
algorithms for various ranking distributions, such as the Mallows model, is an interesting research
avenue to be explored.

10

Conclusion and Future Work

In this paper, we studied different problems of online rank elicitation based on pairwise comparisons
under the assumption of a Plackett-Luce model. Taking advantage of this assumption, our idea is
to construct a surrogate probability distribution over rankings based on a sorting procedure, namely
QuickSort, for which the pairwise marginals provably coincide with the marginals of the PL distribution. In this way, we manage to exploit the (stochastic) transitivity properties of PL, which is at
the origin of the efficiency of our approach, together with the idea of replacing the original QuickSort with a budgeted version of this algorithm. In addition to a formal performance and complexity
analysis of our algorithms, we also presented first experimental studies showing the effectiveness of
our approach.
Needless to say, in addition to the problems studied in this paper, there are many other interesting
problems that can be tackled within the preference-based framework of online learning. For examb of the entire distriple, going beyond a single item or ranking, we may look for a good estimate P
⇣
⌘
b < ✏. With
bution P, for example, an estimate with small Kullback-Leibler divergence: KL P, P
regard to the use of sorting algorithms, another interesting open question is the following: Is there
any sorting algorithm with a worst case complexity of order M log M , which preserves the marginal
probabilities? This question might be difficult to answer since, as we conjecture, the MergeSort and
the InsertionSort algorithms, which are both well-known algorithms with an M log M complexity,
do not satisfy this property.
8

References
[1] Nir Ailon. Reconciling real scores with binary comparisons: A new logistic based model for ranking. In
Advances in Neural Information Processing Systems 21, pages 25–32, 2008.
[2] M. Braverman and E. Mossel. Noisy sorting without resampling. In Proceedings of the nineteenth annual
ACM-SIAM Symposium on Discrete algorithms, pages 268–276, 2008.
[3] M. Braverman and E. Mossel. Sorting from noisy information. CoRR, abs/0910.1191, 2009.
[4] S. Bubeck, R. Munos, and G. Stoltz. Pure exploration in multi-armed bandits problems. In Proceedings
of the 20th ALT, ALT’09, pages 23–37, Berlin, Heidelberg, 2009. Springer-Verlag.
[5] S. Bubeck, T. Wang, and N. Viswanathan. Multiple identifications in multi-armed bandits. In Proceedings
of The 30th ICML, pages 258–265, 2013.
[6] R. Busa-Fekete and E. Hüllermeier. A survey of preference-based online learning with bandit algorithms.
In Algorithmic Learning Theory (ALT), volume 8776, pages 18–39, 2014.
[7] R. Busa-Fekete, E. Hüllermeier, and B. Szörényi. Preference-based rank elicitation using statistical models: The case of Mallows. In (ICML), volume 32 (2), pages 1071–1079, 2014.
[8] R. Busa-Fekete, B. Szörényi, and E. Hüllermeier. Pac rank elicitation through adaptive sampling of
stochastic pairwise preferences. In AAAI, pages 1701–1707, 2014.
[9] R. Busa-Fekete, B. Szörényi, P. Weng, W. Cheng, and E. Hüllermeier. Top-k selection based on adaptive
sampling of noisy preferences. In Proceedings of the 30th ICML, JMLR W&CP, volume 28, 2013.
[10] C. J. Clopper and E. S. Pearson. The Use of Confidence or Fiducial Limits Illustrated in the Case of the
Binomial. Biometrika, 26(4):404–413, 1934.
[11] E. Even-Dar, S. Mannor, and Y. Mansour. PAC bounds for multi-armed bandit and markov decision
processes. In Proceedings of the 15th COLT, pages 255–270, 2002.
[12] Uriel Feige, Prabhakar Raghavan, David Peleg, and Eli Upfal. Computing with noisy information. SIAM
J. Comput., 23(5):1001–1018, October 1994.
[13] V. Gabillon, M. Ghavamzadeh, A. Lazaric, and S. Bubeck. Multi-bandit best arm identification. In NIPS
24, pages 2222–2230, 2011.
[14] J. Guiver and E. Snelson. Bayesian inference for plackett-luce ranking models. In Proceedings of the
26th ICML, pages 377–384, 2009.
[15] C. A. R. Hoare. Quicksort. Comput. J., 5(1):10–15, 1962.
[16] W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American
Statistical Association, 58:13–30, 1963.
[17] D.R. Hunter. MM algorithms for generalized bradley-terry models. The Annals of Statistics, 32(1):384–
406, 2004.
[18] R. Luce and P. Suppes. Handbook of Mathematical Psychology, chapter Preference, Utility and Subjective
Probability, pages 249–410. Wiley, 1965.
[19] R. D. Luce. Individual choice behavior: A theoretical analysis. Wiley, 1959.
[20] C. Mallows. Non-null ranking models. Biometrika, 44(1):114–130, 1957.
[21] John I. Marden. Analyzing and Modeling Rank Data. Chapman & Hall, 1995.
[22] C.J.H. McDiarmid and R.B. Hayward. Large deviations for quicksort. Journal of Algorithms, 21(3):476–
507, 1996.
[23] S. Negahban, S. Oh, and D. Shah. Iterative ranking from pairwise comparisons. In Advances in Neural
Information Processing Systems, pages 2483–2491, 2012.
[24] R. Plackett. The analysis of permutations. Applied Statistics, 24:193–202, 1975.
[25] Arun Rajkumar and Shivani Agarwal. A statistical convergence perspective of algorithms for rank aggregation from pairwise data. In ICML, pages 118–126, 2014.
[26] H. A. Soufiani, W. Z. Chen, D. C. Parkes, and L. Xia. Generalized method-of-moments for rank aggregation. In Advances in Neural Information Processing Systems (NIPS), pages 2706–2714, 2013.
[27] T. Urvoy, F. Clerot, R. Féraud, and S. Naamane. Generic exploration and k-armed voting bandits. In
Proceedings of the 30th ICML, JMLR W&CP, volume 28, pages 91–99, 2013.
[28] Y. Yue, J. Broder, R. Kleinberg, and T. Joachims. The k-armed dueling bandits problem. Journal of
Computer and System Sciences, 78(5):1538–1556, 2012.
[29] Y. Yue and T. Joachims. Beat the mean bandit. In Proceedings of the ICML, pages 241–248, 2011.
[30] M. Zoghi, S. Whiteson, R. Munos, and M. Rijke. Relative upper confidence bound for the k-armed
dueling bandit problem. In ICML, pages 10–18, 2014.

9

