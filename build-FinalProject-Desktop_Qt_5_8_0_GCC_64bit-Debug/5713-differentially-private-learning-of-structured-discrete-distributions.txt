Differentially Private Learning
of Structured Discrete Distributions
Ilias Diakonikolas‚àó
University of Edinburgh

Moritz Hardt
Google Research

Ludwig Schmidt
MIT

Abstract
We investigate the problem of learning an unknown probability distribution over
a discrete population from random samples. Our goal is to design efficient algorithms that simultaneously achieve low error in total variation norm while guaranteeing Differential Privacy to the individuals of the population.
We describe a general approach that yields near sample-optimal and computationally efficient differentially private estimators for a wide range of well-studied and
natural distribution families. Our theoretical results show that for a wide variety
of structured distributions there exist private estimation algorithms that are nearly
as efficient‚Äîboth in terms of sample size and running time‚Äîas their non-private
counterparts. We complement our theoretical guarantees with an experimental
evaluation. Our experiments illustrate the speed and accuracy of our private estimators on both synthetic mixture models and a large public data set.

1

Introduction

The majority of available data in modern machine learning applications come in a raw and unlabeled
form. An important class of unlabeled data is naturally modeled as samples from a probability
distribution over a very large discrete domain. Such data occurs in almost every setting imaginable‚Äî
financial transactions, seismic measurements, neurobiological data, sensor networks, and network
traffic records, to name a few. A classical problem in this context is that of density estimation or
distribution learning: Given a number of iid samples from an unknown target distribution, we want
to compute an accurate approximation of the distribution. Statistical and computational efficiency
are the primary performance criteria for a distribution learning algorithm. More specifically, we
would like to design an algorithm whose sample size requirements are information-theoretically
optimal, and whose running time is nearly linear in its sample size.
Beyond computational and statistical efficiency, however, data analysts typically have a variety
of additional criteria they must balance. In particular, data providers often need to maintain the
anonymity and privacy of those individuals whose information was collected. How can we reveal
useful statistics about a population, while still preserving the privacy of individuals? In this paper,
we study the problem of density estimation in the presence of privacy constraints, focusing on the
notion of differential privacy [1].
Our contributions. Our main findings suggest that the marginal cost of ensuring differential privacy in the context of distribution learning is only moderate. In particular, for a broad class of
shape-constrained density estimation problems, we give private estimation algorithms that are nearly
as efficient‚Äîboth in terms of sample size and running time‚Äîas a nearly optimal non-private baseline. As our learning algorithm approximates the underlying distribution up to small error in total
variation norm, all crucial properties of the underlying distribution are preserved. In particular, the
analyst is free to compose our learning algorithm with an arbitrary non-private analysis.
‚àó

The authors are listed in alphabetical order.

1

Our strong positive results apply to all distribution families that can be well-approximated by piecewise polynomial distributions, extending a recent line of work [2, 3, 4] to the differentially private
setting. This is a rich class of distributions including several natural mixture models, log-concave
distributions, and monotone distributions amongst many other examples. Our algorithm is agnostic so that even if the unknown distribution does not conform exactly to any of these distribution
families, it continues to find a good approximation.
These surprising positive results stand in sharp contrast with a long line of worst-case hardness
results and lower bounds in differential privacy, which show separations between private and nonprivate learning in various settings.
Complementing our theoretical guarantees, we present a novel heuristic method to achieve empirically strong performance. Our heuristic always guarantees privacy and typically converges rapidly.
We show on various data sets that our method scales easily to input sizes that were previously
prohibitive for any implemented differentially private algorithm. At the same time, the algorithm
approaches the estimation error of the best known non-private method for a sufficiently large number
of samples.

Technical overview. We briefly introduce a standard model of learning an unknown probability
distribution from samples (namely, that of [5]), which is essentially equivalent to the minimax rate
of convergence in `1 -distance [6]. A distribution learning problem is defined by a class C of distributions. The algorithm has access to independent samples from an unknown distribution p, and its
goal is to output a hypothesis distribution h that is ‚Äúclose‚Äù to p. We measure the closeness between
distributions in total variation distance, which is equivalent to the `1 -distance and sometimes also
called statistical distance. In the ‚Äúnoiseless‚Äù setting, we are promised that p ‚àà C, and the goal is
to construct a hypothesis h such that (with high probability) the total variation distance dTV (h, p)
between h and p is at most Œ±, where Œ± > 0 is the accuracy parameter.
The more challenging ‚Äúnoisy‚Äù or agnostic model captures the situation of having arbitrary (or even
adversarial) noise in the data. In this setting, we do not make any assumptions about the target distribution p and the goal is to find a hypothesis h that is almost as accurate as the ‚Äúbest‚Äù approximation
of p by any distribution in C. Formally, given sample access to a (potentially arbitrary) target distribution p and Œ± > 0, the goal of an agnostic learning algorithm for C is to compute a hypothesis
distribution h such that dTV (h, p) ‚â§ C ¬∑ optC (p) + Œ±, where optC (p) is the total variation distance
between p and the closest distribution to it in C, and C ‚â• 1 is a universal constant.
It is a folklore fact that learning an arbitrary discrete distribution over a domain of size N to constant
accuracy requires ‚Ñ¶(N ) samples and running time. The underlying algorithm is straightforward:
output the empirical distribution. For distributions over very large domains, a linear dependence
on N is of course impractical, and one might hope that drastically better results can be obtained
for most natural settings. Indeed, there are many natural and fundamental distribution estimation
problems where significant improvements are possible. Consider for example the class of all unimodal distributions over [N ]. In sharp contrast to the ‚Ñ¶(N ) lower bound for the unrestricted case,
an algorithm of Birg√© [7] is known to learn any unimodal distribution over [N ] with running time
and sample complexity of O(log(N )).
The starting point of our work is a recent technique [3, 8, 4] for learning univariate distributions
via piecewise polynomial approximation. Our first main contribution is a generalization of this
technique to the setting of approximate differential privacy. To achieve this result, we exploit a connection between structured distribution learning and private ‚ÄúKolmogorov approximations‚Äù. More
specifically, we show in Section 3 that, for the class of structured distributions we consider, a private algorithm that approximates an input histogram in the Kolmogorov distance combined with the
algorithmic framework of [4] yields sample and computationally efficient private learners under the
total variation distance.
Our approach crucially exploits the structure of the underlying distributions, as the Kolmogorov
distance is a much weaker metric than the total variation distance. Combined with a recent private
algorithm [9], we obtain differentially private learners for a wide range of structured distributions
over [N ]. The sample complexity of our algorithms matches their non-private analogues up to a
‚àó
standard dependence on the privacy parameters and a multiplicative factor of at most O(2log N ),
2

where log‚àó denotes the iterated logarithm function. The running time of our algorithm is nearlylinear in the sample size and logarithmic in the domain size.
Related Work. There is a long history of research in statistics on estimating structured families of
distributions going back to the 1950‚Äôs [10, 11, 12, 13], and it is still a very active research area [14,
15, 16]. Theoretical computer scientists have also studied these problems with an explicit focus on
the computational efficiency [5, 17, 18, 19, 3]. In statistics, the study of inference questions under
privacy constraints goes back to the classical work of Warner [20]. Recently, Duchi et al. [21, 22]
study the trade-off between statistical efficiency and privacy in a local model of privacy obtaining
sample complexity bounds for basic inference problems. We work in the non-local model and our
focus is on both statistical and computational efficiency.
There is a large literature on answering so-called ‚Äúrange queries‚Äù or ‚Äúthreshold queries‚Äù over an
ordered domain subject to differential privacy. See, for example, [23] as well as the recent work [24]
and many references therein. If the output of the algorithm represents a histogram over the domain
that is accurate on all such queries, then this task is equivalent to approximating a sample in Kolmogorov distance, which is the task we consider. Apart from the work of Beimel et al. [25] and Bun
et al. [9], to the best of our knowledge all algorithms in this literature (e.g., [23, 24]) have a running
time that depends polynomially on the domain size N . Moreover, except for the aforementioned
works, we know of no other algorithm that achieves a sub-logarithmic dependence on the domain
size in its approximation guarantee. Of all algorithms in this area, we believe that ours is the first
implemented algorithm that scales to very large domains with strong empirical performance as we
demonstrate in Section 5.

2

Preliminaries

Notation and basic definitions. For N ‚àà Z+ , we write [N ] to denote the set {1, . . . , N }. The
PN
`1 -norm of a vector v ‚àà RN (or equivalently, a function from [N ] to R) is kvk1 =
i=1 |vi |.
For a discrete probability distribution p : [N ] ‚Üí [0, 1], we write p(i) to denote the probability of element i ‚àà [N ] under p. For a subset of the domain S ‚äÜ [N ], we write p(S) to denote
P
def
i‚ààS p(i). The total variation distance between two distributions p and q over [N ] is dTV (p, q) =
maxS‚äÜ[N ] |p(S) ‚àí q(S)| = (1/2) ¬∑ kp ‚àí qk1 . The Kolmogorov distance between p and q is defined
Pj
Pj
def
as dK (p, q) = maxj‚àà[N ] | i=1 p(i) ‚àí i=1 q(i)|. Note that dK (p, q) ‚â§ dTV (p, q). Given a set
S of n independent samples s1 , . . . , sn drawn from a distribution p : [N ] ‚Üí [0, 1], the empirical
distribution pbn : [N ] ‚Üí [0, 1] is defined as follows: for all i ‚àà [N ], pbn (i) = |{j ‚àà [n] | sj = i}| /n.
Definition 1 (Distribution Learning). Let C be a family of distributions over a domain ‚Ñ¶. Given
sample access to an unknown distribution p over ‚Ñ¶ and 0 < Œ±, Œ≤ < 1, the goal of an (Œ±, Œ≤)-agnostic
learning algorithm for C is to compute a hypothesis distribution h such that with probability at least
1 ‚àí Œ≤ it holds dTV (h, p) ‚â§ C ¬∑ optC (p) + Œ± , where optC (p) := inf q‚ààC dTV (q, p) and C ‚â• 1 is a
universal constant.
Differential Privacy. A database D ‚àà [N ]n is an n-tuple of items from [N ]. Given a database
D = (d1 , . . . P
, dn ), we let hist(D) denote the normalized histogram corresponding to D. That is,
n
hist(D) = n1 i=1 edi , where ej denotes the j-th standard basis vector in RN .
Definition 2 (Differential Privacy). A randomized algorithm M : [N ]n ‚Üí R (where R is some
arbitrary range) is (, Œ¥)-differentially private if for all pairs of inputs D, D0 ‚àà [N ]n differing in
only one entry, we have that for all subsets of the range S ‚äÜ R, the algorithm satisfies:
Pr[M (D) ‚àà S] ‚â§ exp() Pr[M (D0 ) ‚àà S] + Œ¥.
In the context of private distribution learning, the database D is the sample set S from the unknown
target distribution p. In this case, the normalized histogram corresponding to D is the same as the
empirical distribution corresponding to S, i.e., hist(S) = pbn (S).
Basic tools from probability. We recall some probabilistic inequalities that will be crucial for our
analysis. Our first tool is the well-known VC inequality. Given a family of subsets A over [N ], define
kpkA = supA‚ààA |p(A)|. The VC‚Äìdimension of A is the maximum size of a subset X ‚äÜ [N ] that is
shattered by A (a set X is shattered by A if for every Y ‚äÜ X some A ‚àà A satisfies A ‚à© X = Y ).
3

Theorem 1 (VC inequality, [6, p. 31]). Let pbn be an empirical distribution
p of n samples from p. Let
A be a family of subsets of VC‚Äìdimension k. Then E [kp ‚àí pbn kA ] ‚â§ O( k/n).
We note that the RHS above is best possible (up to constant factors) and independent of the domain
size N . The Dvoretzky-Kiefer-Wolfowitz (DKW) inequality [26] can be obtained as a consequence
of the VC inequality by taking A to be the class of all intervals. The DKW inequality implies that
for n = ‚Ñ¶(1/2 ), with probability at least 9/10 (over the draw of n samples from p) the empirical
distribution pbn will be -close to p in Kolmogorov distance.
We will also use the following uniform convergence bound:
Theorem 2 ([6, p. 17]). Let A be a family of subsets over [N ], and pbn be an empirical distribution
of n samples from p. Let X be the random variable kp ‚àí pÃÇkA . Then we have Pr [X ‚àí E[X] > Œ∑] ‚â§
2
e‚àí2nŒ∑ .
Connection to Synthetic Data. Distribution learning is closely related to the problem of generating synthetic data. Any dataset D of size n over a universe X can be interpreted as a distribution
over the domain {1, . . . , |X|}. The weight of item x ‚àà X corresponds to the fraction of elements in
D that are equal to x. In fact, this histogram view is convenient in a number of algorithms in Differential Privacy. If we manage to learn this unknown distribution, then we can take n samples from it
obtain another synthetic dataset D0 . Hence, the quality of the distribution learner dictates the statistical properties of the synthetic dataset. Learning in total variation distance is particularly appealing
from this point of view. If two datasets represented as distributions p, q satisfy dTV (p, q) ‚â§ Œ±, then
for every test function f : X ‚Üí {0, 1} we must have that |Ex‚àºp f (x) ‚àí Ex‚àºq f (x)| ‚â§ Œ±. Put in different terminology, this means that the answer to any statistical query1 differs by at most Œ± between
the two distributions.

3

A Differentially Private Learning Framework

In this section, we describe our private distribution learning upper bounds. We start with the simple
case of privately learning an arbitrary discrete distribution over [N ]. We then extend this bound to
the case of privately and agnostically learning a histogram distribution over an arbitrary but known
partition of [N ]. Finally, we generalize the recent framework of [4] to obtain private agnostic learners for histogram distributions over an arbitrary unknown partition, and more generally piecewise
polynomial distributions.
Our first theorem gives a differentially private algorithm for arbitrary distributions over [N ] that essentially matches the best non-private algorithm. Let CN be the family of all probability distributions
over [N ]. We have the following:
Theorem 3. There is a computationally efficient (, 0)-differentially private (Œ±, Œ≤)-learning algorithm for CN that uses n = O((N + log(1/Œ≤))/Œ±2 + N log(1/Œ≤)/(Œ±)) samples.
The algorithm proceeds as follows: Given a dataset S of n samples from the unknown target distribution p over [N ], it outputs the hypothesis h = hist(S) + Œ∑ = pbn (S) + Œ∑, where Œ∑ ‚àà RN is
sampled from the N -dimensional Laplace distribution with standard deviation 1/(n). The simple
analysis is deferred to Appendix A.
A t-histogram over [N ] is a function h : [N ] ‚Üí R that is piecewise constant with at most t interval
pieces, i.e., there is a partition I of [N ] into intervals I1 , . . . , It such that h is constant on each
Ii . Let Ht (I) be the family of all t-histogram distributions over [N ] with respect to partition I =
{I1 , . . . , It }. Given sample access to a distribution p over [N ], our goal is to output a hypothesis
h : [N ] ‚Üí [0, 1] that satisfies dTV (h, p) ‚â§ C ¬∑ optt (p) + Œ±, where optt (p) = inf g‚ààHt (I) dTV (g, p).
We show the following:
Theorem 4. There is a computationally efficient (, 0)-differentially private (Œ±, Œ≤)-agnostic learning algorithm for Ht (I) that uses n = O((t + log(1/Œ≤))/Œ±2 + t log(1/Œ≤)/(Œ±)) samples.
The main idea of the proof is that the differentially private learning problem for Ht (I) can be
reduced to the same problem over distributions of support [t]. The theorem then follows by an
1

A statistical query asks for the average of a predicate over the dataset.

4

application of Theorem 3. See Appendix A for further details. Theorem 4 gives differentially private
learners for any family of distributions over [N ] that can be well-approximated by histograms over
a fixed partition, including monotone distributions and distributions with a known mode.
In the remainder of this section, we focus on approximate privacy, i.e., (, Œ¥)-differential privacy for
Œ¥ > 0, and show that for a wide range of natural and well-studied distribution families there exists a
computationally efficient and differentially private algorithm whose sample size is at most a factor
‚àó
of 2O(log N ) worse than its non-private counterpart. In particular, we give a differentially private
version of the algorithm in [4]. For a wide range of distributions, our algorithm has near-optimal
sample complexity and runs in time that is nearly-linear in the sample size and logarithmic in the
domain size.
We can view our overall private learning algorithm as a reduction. For the sake of concreteness,
we state our approach for the case of histograms, the generalization to piecewise polynomials being
essentially identical. Let Ht be the family of all t-histogram distributions over [N ] (with unknown
partition). In the non-private setting, a combination of Theorems 1 and 2 (see appendix) implies that
Ht is (Œ±, Œ≤)-agnostically learnable using n = Œò((t + log(1/Œ≤))/Œ±2 ) samples. The algorithm of [4]
starts with the empirical distribution pbn and post-processes it to obtain an (Œ±, Œ≤)-accurate hypothesis
h. Let Ak be the collection of subsets of [N ] that can be expressed as unions of at most k disjoint
intervals. The important property of the empirical distribution pbn is that with high probability, pbn is
Œ±-close to the target distribution p in Ak -distance for any k = O(t).
The crucial observation that enables our generalization is that the algorithm of [4] achieves the
same performance guarantees starting from any hypothesis q such that kp ‚àí qkAO(t) ‚â§ Œ±.2 This
observation motivates the following two-step differentially private algorithm: (1) Starting from the
empirical distribution pbn , efficiently construct an (, Œ¥)-differentially private hypothesis q such that
with probability at least 1 ‚àí Œ≤/2 it holds kq ‚àí pbn kAO(t) ‚â§ Œ±/2. (2) Pass q as input to the learning
algorithm of [4] with parameters (Œ±/2, Œ≤/2) and return its output hypothesis h.
We now proceed to sketch correctness. Since q is (, Œ¥)-differentially private and the algorithm of
Step (2) is only a function of q, the composition theorem implies that h is also (, Œ¥)-differentially
private. Recall that with probability at least 1 ‚àí Œ≤/2 we have kp ‚àí pbn kAO(t) ‚â§ Œ±/2. By the
properties of q in Step (1), a union bound and an application of the triangle inequality imply that
with probability at least 1 ‚àí Œ≤ we have kp ‚àí qkAO(t) ‚â§ Œ±. Hence, the output h of Step (2) is an
(Œ±, Œ≤)-accurate agnostic hypothesis.
We have thus sketched a proof of the following lemma:
Lemma 1. Suppose there is an (, Œ¥)-differentially private synthetic data algorithm under the
AO(t) ‚Äìdistance metric that is (Œ±/2, Œ≤/2)-accurate on databases of size n, where n = ‚Ñ¶((t +
log(1/Œ≤))/Œ±2 ). Then, there exists an (Œ±, Œ≤)-accurate agnostic learning algorithm for Ht with sample complexity n.
Recent work of Bun et al. [9] gives an efficient differentially private synthetic data algorithm under
the Kolmogorov distance metric:
Proposition 1. [9] There is an (, Œ¥)-differentially private (Œ±, Œ≤)-accurate synthetic data algorithm
‚àó
with respect to dK ‚Äìdistance on databases of size n over [N ], assuming n = ‚Ñ¶((1/(Œ±)) ¬∑ 2O(log N ) ¬∑
ln(1/Œ±Œ≤Œ¥)). The algorithm runs in time O(n ¬∑ log N ).
Note that the Kolmogorov distance is equivalent to the A2 -distance up to a factor of 2. Hence, by
applying the above proposition for Œ±0 = Œ±/t one obtains an (Œ±, Œ≤)-accurate synthetic data algorithm
with respect to the At -distance. Combining the above, we obtain the following:
Theorem 5. There is an (, Œ¥)-differentially private (Œ±, Œ≤)-agnostic learning algorithm for Ht that
‚àó
uses n = O((t/Œ±2 ) ¬∑ ln(1/Œ≤) + (t/(Œ±)) ¬∑ 2O(log N ) ¬∑ ln(1/Œ±Œ≤Œ¥)) samples and runs in time
e
O(n)
+ O(n ¬∑ log N ).
As an immediate corollary of Theorem 5, we obtain nearly-sample optimal and computationally
efficient differentially private estimators for all the structured discrete distribution families studied
2
We remark that a potential difference is in the running time of the algorithm, which depends on the support
and structure of the distribution q.

5

in [3, 4]. These include well-known classes of shape restricted densities including (mixtures of)
unimodal and multimodal densities (with unknown mode locations), monotone hazard rate (MHR)
and log-concave distributions, and others. Due to space constraints, we do not enumerate the full
descriptions of these classes or statements of these results here but instead refer the interested reader
to [3, 4].

4

Maximum Error Rule for Private Kolmogorov Distance Approximation

In this section, we describe a simple and fast algorithm for privately approximating an input histogram with respect to the Kolmogorov distance. Our private algorithm relies on a simple (nonprivate) iterative greedy algorithm to approximate a given histogram (empirical distribution) in Kolmogorov distance, which we term M AXIMUM E RROR RULE. This algorithm performs a set of basic
operations on the data and can be effectively implemented in the private setting.
To describe the non-private version of M AXIMUM E RROR RULE, we point out a connection of the
Kolmogorov distance approximation problem to the problem of approximating a monotone univariate function with by a piecewise linear function. Let pbn be the empirical probability distribution over
[N ], and let Pbn denote the corresponding empirical CDF. Note that Pbn : [N ] ‚Üí [0, 1] is monotone
non-decreasing and piecewise constant with at most n pieces. We would like to approximate pbn by
a piecewise uniform distribution with a corresponding a piecewise linear CDF. It is easy to see that
this is exactly the problem of approximating a monotone function by a piecewise linear function in
`‚àû -norm.
The M AXIMUM E RROR RULE works as follows: Starting with the trivial linear approximation that
interpolates between (0, 0) and (N, 1), the algorithm iteratively refines its approximation to the
target empirical CDF using a greedy criterion. In each iteration, it finds the point (x, y) of the
true curve (empirical CDF Pbn ) at which the current piecewise linear approximation disagrees most
strongly with the target CDF (in `‚àû -norm). It then refines the previous approximation by adding the
point (x, y) and interpolating linearly between the new point and the previous two adjacent points of
the approximation. See Figure 1 for a graphical illustration of our algorithm. The M AXIMUM E R ROR RULE is a popular method for monotone curve approximation whose convergence rate has been
analyzed under certain assumptions on the structure of the input curve. For example, if the monotone input curve satisfies a Lipschitz condition, it is known that the `‚àû -error after T iterations scales
as O(1/T 2 ) (see, e.g., [27] and references therein).
There are a number of challenges towards making this algorithm differentially private. The first is
that we cannot exactly select the maximum error point. Instead, we can only choose an approximate
maximizer using a differentially private sub-routine. The standard algorithm for choosing such
a point would be the exponential mechanism of McSherry and Talwar [28]. Unfortunately, this
algorithm falls short of our goals in two respects. First, it introduces a linear dependence on the
domain size in the running time making the algorithm prohibitively inefficient over large domains.
Second, it introduces a logarithmic dependence on the domain size in the error of our approximation.
In place of the exponential mechanism, we design a sub-routine using the ‚Äúchoosing mechanism‚Äù
of Beimel, Nissim, and Stemmer [25]. Our sub-routine runs in logarithmic time in the domain size
and achieves a doubly-logarithmic dependence in the error. See Figure 2 for a pseudocode of our
algorithm. In the description of the algorithm, we think of At as a CDF defined by a sequence of
points (0, 0), (x1 , y1 ), ..., (xk , yk ), (N, 1) specifying the value of the CDF at various discrete points
of the domain. We denote by weight(I, At ) ‚àà [0, 1] the weight of the interval I according to the
CDF At , where the value at missing points in the domain is achieved by linear interpolation. In other
words, At represents a piecewise-linear CDF (corresponding to a piecewise constant histogram).
Similarly, we let weight(I, S) ‚àà [0, 1] denote the weight of interval I according to the sample S,
that is, |S ‚à© I|/|S|.
We show that our algorithm satisfies (, Œ¥)-differential privacy (see Appendix B):
Lemma 2. For every  ‚àà (0, 2), Œ¥ > 0, MaximumErrorRule satisfies (, Œ¥)-differential privacy.
Next, we provide two performance guarantees for our algorithm. The first shows that the running
time per iteration is at most O(n log N ). The second shows that if at any step t there is a ‚Äúbad‚Äù
interval in I that has large error, then our algorithm finds such a bad interval where the quantitative
6

Figure 1: CDF approximation after T = 0, 1, 2, 3 iterations.
M AXIMUM E RROR RULE(S ‚àà [N ]n , privacy parameters , Œ¥)
For t = 1 to T :
1. I = F IND BAD I NTERVAL(At‚àí1 , S)
2. At = U PDATE(At‚àí1 , S, I)
F IND BAD I NTERVAL
1. Let I be the collection of all dyadic intervals of the domain.
2. For each J ‚àà I, let q(J; S) = |weight(J, At‚àí1 ) ‚àí weight(J, S)|.
3. Output an I ‚àà I sampled from the choosing mechanism with score function q over the
collection I with privacy parameters (/2T, Œ¥/T ).
U PDATE
1. Let I = (l, r) be the input interval.
Compute wl = weight([1, l], S) +
Laplace(0, 1/(2n)) and wr = weight([l + 1, r], S) + Laplace(0, 1/(2n)).
2. Output the CDF obtained from At‚àí1 by adding the points (l, wl ) and (r, wl + wr ) to the
graph of At‚àí1 .
Figure 2: Maximum Error Rule (MERR).

loss depends only doubly-logarithmically on the domain size (see Appendix B for the proof of the
following theorem).
Proposition 2. MERR runs in time O(T n log N ). Furthermore, for every step t, with probability
1 ‚àí Œ≤, we have that the interval I selected at step t satisfies



1
|weight(I, At‚àí1 ) ‚àí weight(I, S)| ‚â• OPT ‚àí O
¬∑ log n log N ¬∑ log(1/Œ≤Œ¥) .
n
Recall that OPT = maxJ‚ààI |weight(J, At‚àí1 ) ‚àí weight(J, S)|.

5

Experiments

In addition to our theoretical results from the previous sections, we also investigate the empirical
performance of our private distribution learning algorithm based on the maximum error rule. The
focus of our experiments is the learning error achieved by the private algorithm for various distributions. For this, we employ two types of data sets: multiple synthetic data sets derived from mixtures
of well-known distributions (see Appendix C), and a data set from Higgs experiments [29]. The
synthetic data sets allow us to vary a single parameter (in particular, the domain size) while keeping
the remaining problem parameters constant. We have chosen a distribution from the Higgs data set
because it gives rise to a large domain size. Our results show that the maximum error rule finds
a good approximation of the underlying distribution, matching the learning error of a non-private
baseline when the number of samples is sufficiently large. Moreover, our algorithm is very efficient
and runs in less than 5 seconds for n = 107 samples on a domain of size N = 1018 .
We implemented our algorithm in the Julia programming language (v0.3) and ran the experiments on
an Intel Core i5-4690K CPU (3.5 - 3.9 GHz, 6 MB cache). In all experiments involving our private
learning algorithm, we set the privacy parameters to  = 1 and Œ¥ = n1 . Since the noise magnitude
1
depends on n
, varying  has the same effect as varying the the sample size n. Similarly, changes in
Œ¥ are related to changes in n, and therefore we only consider this setting of privacy parameters.
7

Higgs data. In addition to the synthetic data mentioned above, we use the lepton pT (transverse
momentum) feature of the Higgs data set (see Figure 2e of [29]). The data set contains roughly
11 million samples, which we use as unknown distribution. Since the values are specified with 18
digits of accuracy, we interpret them as discrete values in [N ] for N = 1018 . We then generate a
sample from this data set by taking the first n samples and pass this subset as input to our private
distribution learning algorithm. This time, we measure the error as Kolmogorov distance between
the hypothesis returned by our algorithm and the cdf given by the full set of 11 million samples.
In this experiment (Figure 3), we again see that the maximum-error rule achieves a good learning
error. Moreover, we investigate the following two aspects of the algorithm: (i) The number of steps
taken by the maximum error rule influences the learning error. In particular, a smaller number of
steps leads to a better approximation for small values of n, while more samples allow us to achieve
a better error with a larger number of steps. (ii) Our algorithm is very efficient. Even for the largest
sample size n = 107 and the largest number of MERR steps, our algorithm runs in less than 5
seconds. Note that on the same machine, simply sorting n = 107 floating point numbers takes about
0.6 seconds. Since our algorithm involves a sorting step, this shows that the overhead added by
the maximum error rule is only about 7√ó compared to sorting. In particular, this implies that no
algorithm that relies on sorted samples can outperform our algorithm by a large margin.
Limitations and future work. As we previously saw, the performance of the algorithm varies
with the number of iterations. Currently this is a parameter that must be optimized over separately,
for example, by choosing the best run privately from the exponential mechanism. This is standard
practice in the privacy literature, but it would be more appealing to find an adaptive method of
choosing this parameter on the fly as the algorithm obtains more information about the data.
There remains a gap in sample complexity between the private and the non-private algorithm. One
reason for this are the relatively large constants in the privacy analysis of the choosing mechanism [9]. With a tighter privacy analysis, one could hope to reduce the sample size requirements of
our algorithm by up to an order of magnitude.
It is likely that our algorithm could also benefit from certain post-processing steps such as smoothing
the output histogram. We did not evaluate such techniques here for simplicity and clarity of the
experiments, but this is a promising direction.
Higgs data

Higgs data
Running time (seconds)

Kolmogorov-error

100
10‚àí1
10‚àí2

100

10‚àí1

‚àí3

10

103

104
105
106
Sample size n
m=4

103

107

m=8

m = 12

104
105
106
Sample size n

m = 16

107

m = 20

Figure 3: Evaluation of our private learning algorithm on the Higgs data set. The left plot shows the
Kolmogorov error achieved for various sample sizes n and number of steps taken by the maximum
error rule (m). The right plot displays the corresponding running times of our algorithm.

Acknowledgments
Ilias Diakonikolas was supported by EPSRC grant EP/L021749/1 and a Marie Curie Career Integration grant. Ludwig Schmidt was supported by MADALGO and a grant from the MIT-Shell
Initiative.
8

References
[1] C. Dwork. The differential privacy frontier (extended abstract). In TCC, pages 496‚Äì502, 2009.
[2] S. Chan, I. Diakonikolas, R. Servedio, and X. Sun. Learning mixtures of structured distributions over
discrete domains. In SODA, 2013.
[3] S. Chan, I. Diakonikolas, R. Servedio, and X. Sun. Efficient density estimation via piecewise polynomial
approximation. In STOC, pages 604‚Äì613, 2014.
[4] J. Acharya, I. Diakonikolas, J. Li, and L. Schmidt. Sample-Optimal Density Estimation in Nearly-Linear
Time. Available at http://arxiv.org/abs/1506.00671, 2015.
[5] M. Kearns, Y. Mansour, D. Ron, R. Rubinfeld, R. Schapire, and L. Sellie. On the learnability of discrete
distributions. In Proc. 26th STOC, pages 273‚Äì282, 1994.
[6] L. Devroye and G. Lugosi. Combinatorial methods in density estimation. Springer Series in Statistics,
Springer, 2001.
[7] L. Birg√©. Estimation of unimodal densities without smoothness assumptions. Annals of Statistics,
25(3):970‚Äì981, 1997.
[8] S. Chan, I. Diakonikolas, R. Servedio, and X. Sun. Near-optimal density estimation in near-linear time
using variable-width histograms. In NIPS, pages 1844‚Äì1852, 2014.
[9] M. Bun, K. Nissim, U. Stemmer, and S. P. Vadhan. Differentially private release and learning of threshold
functions. CoRR, abs/1504.07553, 2015.
[10] U. Grenander. On the theory of mortality measurement. Skand. Aktuarietidskr., 39:125‚Äì153, 1956.
[11] B.L.S. Prakasa Rao. Estimation of a unimodal density. Sankhya Ser. A, 31:23‚Äì36, 1969.
[12] P. Groeneboom. Estimating a monotone density. In Proc. of the Berkeley Conference in Honor of Jerzy
Neyman and Jack Kiefer, pages 539‚Äì555, 1985.
[13] L. Birg√©. Estimating a density under order restrictions: Nonasymptotic minimax risk. Ann. of Stat., pages
995‚Äì1012, 1987.
[14] F. Balabdaoui and J. A. Wellner. Estimation of a k-monotone density: Limit distribution theory and the
spline connection. The Annals of Statistics, 35(6):pp. 2536‚Äì2564, 2007.
[15] L. D umbgen and K. Rufibach. Maximum likelihood estimation of a log-concave density and its distribution function: Basic properties and uniform consistency. Bernoulli, 15(1):40‚Äì68, 2009.
[16] G. Walther. Inference and modeling with log-concave distributions. Stat. Science, 2009.
[17] Y. Freund and Y. Mansour. Estimating a mixture of two product distributions. In COLT, 1999.
[18] J. Feldman, R. O‚ÄôDonnell, and R. Servedio. Learning mixtures of product distributions over discrete
domains. In FOCS, pages 501‚Äì510, 2005.
[19] C. Daskalakis, I. Diakonikolas, and R.A. Servedio. Learning k-modal distributions via testing. In SODA,
pages 1371‚Äì1385, 2012.
[20] S. L. Warner. Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias. Journal
of the American Statistical Association, 60(309), 1965.
[21] J. C. Duchi, M. I. Jordan, and M. J. Wainwright. Local privacy and statistical minimax rates. In FOCS,
pages 429‚Äì438, 2013.
[22] J. C. Duchi, M. J. Wainwright, and M. I. Jordan. Local privacy and minimax bounds: Sharp rates for
probability estimation. In NIPS, pages 1529‚Äì1537, 2013.
[23] M. Hardt, K. Ligett, and F. McSherry. A simple and practical algorithm for differentially-private data
release. In NIPS, 2012.
[24] C. Li, M. Hay, G. Miklau, and Y. Wang. A data- and workload-aware query answering algorithm for
range queries under differential privacy. PVLDB, 7(5):341‚Äì352, 2014.
[25] A. Beimel, K. Nissim, and U. Stemmer. Private learning and sanitization: Pure vs. approximate differential privacy. In RANDOM, pages 363‚Äì378, 2013.
[26] A. Dvoretzky, J. Kiefer, and J. Wolfowitz. Asymptotic minimax character of the sample distribution
function and of the classical multinomial estimator. Ann. Mathematical Statistics, 27(3):642‚Äì669, 1956.
[27] G. Rote. The convergence rate of the sandwich algorithm for approximating convex functions. Computing,
48:337‚Äì361, 1992.
[28] F. McSherry and K. Talwar. Mechanism design via differential privacy. In FOCS, pages 94‚Äì103, 2007.
[29] Pierre Baldi, Peter Sadowski, and Daniel Whiteson. Searching for exotic particles in high-energy physics
with deep learning. Nature Communications, (5), 2014.
[30] C. Dwork, G. N. Rothblum, and S. Vadhan. Boosting and differential privacy. In FOCS, 2010.

9

