Predtron: A Family of Online Algorithms for General
Prediction Problems
Prateek Jain
Microsoft Research, INDIA
prajain@microsoft.com

Nagarajan Natarajan
University of Texas at Austin, USA
naga86@cs.utexas.edu

Ambuj Tewari
University of Michigan, Ann Arbor, USA
tewaria@umich.edu

Abstract
Modern prediction problems arising in multilabel learning and learning to rank
pose unique challenges to the classical theory of supervised learning. These problems have large prediction and label spaces of a combinatorial nature and involve
sophisticated loss functions. We offer a general framework to derive mistake
driven online algorithms and associated loss bounds. The key ingredients in our
framework are a general loss function, a general vector space representation of
predictions, and a notion of margin with respect to a general norm. Our general
algorithm, Predtron, yields the perceptron algorithm and its variants when instantiated on classic problems such as binary classification, multiclass classification,
ordinal regression, and multilabel classification. For multilabel ranking and subset ranking, we derive novel algorithms, notions of margins, and loss bounds. A
simulation study confirms the behavior predicted by our bounds and demonstrates
the flexibility of the design choices in our framework.

1

Introduction

Classical supervised learning problems, such as binary and multiclass classification, share a number
of characteristics. The prediction space (the space in which the learner makes predictions) is often
the same as the label space (the space from which the learner receives supervision). Because directly learning discrete valued prediction functions is hard, one learns real-valued or vector-valued
functions. These functions generate continuous predictions that are converted into discrete ones
via simple mappings, e.g., via the ‘sign’ function (binary classification) or the ‘argmax’ function
(multiclass classification). Also, the most commonly used loss function is simple, viz. the 0-1 loss.
In contrast, modern prediction problems, such as multilabel learning, multilabel ranking, and subset
ranking do not share these characteristics. In order to handle these problems, we need a more general
framework that offers more flexibility. First, it should allow for the possibility of having different
label space and prediction space. Second, it should allow practitioners to use creative, new ways
to map continuous, vector-valued predictions to discrete ones. Third, it should permit the use of
general loss functions.
Extensions of the theory of classical supervised learning to modern predictions problems have begun. For example, the work on calibration dimension [1] can be viewed as extending one aspect of
the theory, viz. that of calibrated surrogates and consistent algorithms based on convex optimization. This paper deals with the extension of another interesting part of classical supervised learning:
mistake driven algorithms such as perceptron (resp. winnow) and their analyses in terms of `2 (resp.
`1 ) margins [2, Section 7.3].
1

We make a number of contributions. First, we provide a general framework (Section 2) whose
ingredients include an arbitrary loss function and an arbitrary representation of discrete predictions in a continuous space. The framework is abstract enough to be of general applicability but
it offers enough mathematical structure so that we can derive a general online algorithm, Predtron
(Algorithm 1), along with an associated loss bound (Theorem 1) under an abstract margin condition (Section 2.2). Second, we show that our framework unifies several perception-like algorithms
for classical problems such as binary classification, multiclass classification, ordinal regression, and
multilabel classification (Section 3). Even for these classical problems, we get some new results, for
example, when the loss function treats labels asymmetrically or when there exists a ‘reject’ option
in classification. Third, we apply our framework to two modern prediction problems: subset ranking (Section 4) and multilabel ranking (Section 5). In both of these problems, the prediction space
(rankings) is different from the supervision space (set of labels or vector of relevance scores). For
these two problems, we propose interesting, novel notions of correct prediction with a margin and
derive mistake bounds under a loss derived from NDCG, a ranking measure that pays more attention
to the performance at the top of a ranked list. Fourth, our techniques based on online convex optimization (OCO) can effortlessly incorporate notions of margins w.r.t. non-Euclidean norms, such as
`1 norm, group norm, and trace norm. Such flexibility is important in modern prediction problems
where the learned parameter can be a high dimensional vector or a large matrix with low group or
trace norm. Finally, we test our theory in a simulation study (Section 6) dealing with the subset
ranking problem showing how our framework can be adapted to a specific prediction problem. We
investigate different margin notions as we vary two key design choices in our abstract framework:
the map used to convert continuous predictions into discrete ones, and the choice of the norm used
in the definition of margin.
Related Work. Our general algorithm is related to the perceptron and online gradient descent algorithms used in structured prediction [3, 4]. But, to the best of knowledge, our emphasis on keeping
label and prediction spaces possibly distinct, our use of a general representation of predictions, and
our investigation of generalized notions of margins are all novel. The use of simplex coding in multiclass problems [5] inspired the use of maximum similarity/minimum distance decoding to obtain
discrete predictions from continuous ones. Our proofs use results about Online Gradient Descent
and Online Mirror Descent from the Online Convex Optimization literature [6].

2

Framework and Main Result

The key ingredients in classic supervised learning are an input space, an output space and a loss
function. In this paper, the input space X 2 Rp will always be some subset of a finite dimensional
Euclidean space. Our algorithms maintain prediction functions as a linear combination of the seen
inputs. As a result, they easily kernelize and the theory extends, in a straightforward way to the case
when the input space is a, possibly infinite dimensional, reproducing kernel Hilbert space (RKHS).
2.1

Labels, Prediction, and Scores

We will distinguish between the label space and the prediction space. The former is the space where
the training labels come from whereas the latter is the space where the learning algorithm has to
make predictions in. Both spaces will be assumed to be finite. Therefore, without any loss of
generality, we can identify the label space with [`] = {1, . . . , `} and the prediction space with [k]
where `, k are positive, but perhaps very large, integers. A given loss function L : [k] ⇥ [`] ! R+
maps a prediction 2 [k] and a label y 2 [`] to a non-negative loss L( , y). The loss L can
equivalently be thought of as a k ⇥ ` matrix with loss values as entries. Define the set of correct
predictions for a label y as ⌃y = { y 2 [k] : L( y , y) = 0}. We assume that, for every label
y, the set ⌃y is non-empty. That is, every column of the loss matrix has a zero entry. Also, let
cL = minL( ,y)>0 L( , y) and CL = max ,y L( , y) be the minimum (non-zero) and maximum
entries in the loss matrix.
In an online setting, the learner will see a stream of examples (X⌧ , Y⌧ ) 2 X ⇥ [`]. Learner will
predict scores using a linear predictor W 2 Rd⇥p . However, the predicted scores W X⌧ will be
in Rd , not in the prediction space [k]. So, we need a function pred : Rd ! [k] to convert scores
into actual predictions. We will assume that there is a unique representation rep( ) 2 Rd of each
2

prediction such that k rep( )k2 = 1 for all . Given this, a natural transformation of scores into
prediction is given by the following maximum similarity decoding:
pred(t) 2 argmax hrep( ), ti ,

(1)

2[k]

where ties in the “argmax” can be broken arbitrarily. There are some nice consequences of the
definition of pred above. First, because k rep( )k2 = 1, maximum similarity decoding is equivalent
to nearest neighbor decoding: pred(t) 2 argmin k rep( ) tk2 . Second, we have a homogeneity
property: pred(ct) = pred(t) if c > 0. Third, rep serves as an “inverse” of pred in the following
sense. We have, pred(rep( )) = for all . Moreover, rep(pred(t)) is more similar to t than the
representation of any other prediction :
8t 2 Rd ,

2 [k], hrep(pred(t)), ti

hrep( ), ti .

In view of these facts, we will use pred 1 ( ) and rep( ) interchangeably. Using pred, the loss
function L can be extended to a function defined on Rd ⇥ [k] as:
L(t, y) = L(pred(t), y).
With a little abuse of notation, we will continue to denote this new function also by L.
2.2

Margins

We say that a score t is compatible with a label y if the set of
⌦ ’s that achieve
↵ the maximum in the
definition (1) of pred is exactly ⌃y . That is, argmax 2[k] pred 1 ( ), t = ⌃y . Hence, for any
⌦
↵
⌦
↵
2
/ ⌃y , we have pred 1 ( y ), t > pred 1 ( ), t . The notion of margin makes this
y 2 ⌃y ,
requirement stronger. We say that a score t has a margin > 0 on label y, iff t is compatible with
y and
⌦
↵ ⌦
↵
8 y 2 ⌃y , 2
/ ⌃y , pred 1 ( y ), t
pred 1 ( ), t +

Note that margin scales with t: if t has margin on y then ct has margin c on y for any positive c.
If we are using linear predictions t = W X, we say that W has margin on (X, y) iff t = W X has
margin on y. We say that W has margin on a dataset (X1 , y1 ), . . . , (Xn , yn ) iff W has margin
on (X⌧ , y⌧ ) for all ⌧ 2 [n]. Finally, a dataset (X1 , y1 ), . . . , (Xn , yn ) is said to be linearly separable
with margin if there is a unit norm1 W ? such that W ? has margin on (X1 , y1 ), . . . , (Xn , yn ).
2.3

Algorithm

Just like the classic perceptron algorithm, our generalized perceptron algorithm (Algorithm 1) is
mistake driven. That is, it only updates on round when a mistake, i.e., a non-zero loss, is incurred.
On a mistake round, it makes a rank-one update of the form W⌧ +1 = WP
g⌧ · X⌧> where g⌧ 2
⌧
>
Rd , X⌧ 2 Rp . Therefore, W⌧ always
has
a
representation
of
the
form
g
i i Xi . The prediction
P
on a fresh input X is given by i gi hXi , Xi which means the algorithm, just like the original
perceptron, can be kernelized.
We will give a loss bound for the algorithm using tools from Online Convex Optimization (OCO).
Define the function : Rd ⇥ [`] ! R as
⌦
↵
(t, y) = max L( , y)
pred 1 ( y ) pred 1 ( ), t
(2)
2[k]

where y 2 ⌃y is an arbitrary member of ⌃y . For any y, (·, y) is a point-wise maximum of linear
functions and hence convex. Also, is non-negative: choose = y to lower bound the maximum.
The inner product part vanishes and the loss L( y , y) vanishes too because y 2 ⌃y . Given the
definition of , Algorithm 1 can be described succinctly as follows. At round ⌧ , if L(W⌧ X⌧ , Y⌧ ) >
0, then W⌧ +1 = W⌧ ⌘rW (W X⌧ , Y⌧ ), otherwise W⌧ +1 = W⌧ .
1
Here, we mean that the Frobenius norm kW ? kF equals 1. Of course, the notion of margin can be generalized to any norm including the entry-based `1 norm kW k1 and the spectrum-based `1 norm kW kS(1) (also
called the nuclear or trace norm). See Appendix B.2.

3

Algorithm 1 Predtron: Extension of the Perceptron Algorithm to General Prediction Problems
1: W1
0
2: for ⌧ = 1, 2, . . . do
3:
Receive X⌧ 2 Rp
4:
Predict ⌧ = pred(W⌧ X⌧ ) 2 [k]
5:
Receive label y⌧ 2 [`]
6:
if L( ⌧ , y⌧ ) > 0 then
7:
(t, y) = (W⌧ X⌧ , y⌧ )
⌦
↵
8:
˜⌧ = argmax 2[k] L( , y)
pred 1 ( y ) pred 1 ( ), t 2 [k]
9:
r⌧ = (pred 1 (˜⌧ ) pred 1 ( y )) · X⌧> 2 Rd⇥p
10:
W⌧ +1 = W⌧ ⌘r⌧
11:
else
12:
W⌧ +1 = W⌧
13:
end if
14: end for
Theorem 1. Suppose the dataset (X1 , y1 ), . . . , (Xn , yn ) is linearly separable with margin . Then
the sequence W⌧ generated by Algorithm 1 with ⌘ = cL /(4R2 ) satisfies the loss bound,
n
X

⌧ =1

where kX⌧ k2  R for all ⌧ .

L(W⌧ X⌧ , y⌧ ) 

4R2 CL2
cL 2

Note that the bound above assumes perfect linear separability. However, just the classic perceptron,
the bound will degrade gracefully when the best linear predictor does not have enough margin on
the data set.
The Predtron algorithm has some interesting variants, two of which we consider in the appendix. A
loss driven version, Predtron.LD, enjoys a loss bound that gets rid of the CL /cL factor in the bound
above. A version, Predtron.Link, that uses link functions to deal with margins defined with respect
to non-Euclidean norms is also considered.

3

Relationship to Existing Results

It is useful to discuss a few concrete applications of the abstract framework introduced in the last
section. Several existing loss bounds can be readily derived by applying our bound for the generalized perceptron algorithm in Theorem 1. In some cases, our framework yields a different algorithm
than existing counterparts, yet admitting identical loss bounds, up to constants.
Binary Classification. We begin with the classical perceptron algorithm for binary classification
(i.e., ` = 2) [7]: L0-1 ( , y) = 1 if 6= y or 0 otherwise. Letting rep( ) be +1 for the positive
class and 1 for the negative class, predictor vector W⌧ 2 R1⇥p , and thus pred(t) = sign(t),
Algorithm 1 reduces to the original perceptron algorithm; Theorem 1 yields identical mistake bound
on a linearly separable dataset with margin (if the classical margin is , ours works out to be
Pn
R2
2 ), i.e.
2 . We can also easily incorporate asymmetric losses. Let
⌧ =1 L0-1 (W⌧ X⌧ , y⌧ ) 
L↵ ( , y) = ↵y , if 6= y and 0 otherwise. We then have the following result.
Corollary 2. Consider the perceptron with weighted loss L↵ . Assume ↵1
↵2 without loss of
generality. Then the sequence W⌧ generated by Algorithm 1 satisfies the weighted mistake bound,
n
X

⌧ =1

L↵ (W⌧ X⌧ , y⌧ ) 

4R2 ↵12
.
↵22 2

We are not aware of such results for weighted loss. Previous work [8] studies perceptrons
with
Pn uneven margins, and the loss bound there only implies a bound on the unweighted loss:
⌧ =1 L0-1 (t⌧ , y⌧ ). In a technical note, Rätsch and Kivinen [9] provide a mistake bound of the
4

Pn
form (without proof): ⌧ =1 L↵ (W⌧ X⌧ , y⌧ ) 
and ↵2 = (1 a)2 for any a 2 [0, 1].

R2
4 2,

but for the specific choice of weights ↵1 = a2

Another interesting extension is obtained by allowing the predictions to have a R EJECT option. Define LR EJ (R EJECT, y) = y and LR EJ ( , y) = L0-1 ( , y) otherwise. Assume 1
1
2 > 0 without loss of generality. Choosing the standardPbasis vectors in R2 to be rep(
)
for
the
positive
and the
Pn
negative classes, and rep(R EJECT) = p12
2{1,2} rep( ), we obtain
⌧ =1 LR EJ (W⌧ X⌧ , y⌧ ) 
4R2
2

2
1
2
2

(See Appendix C.1).

Multiclass Classification. Each instance is assigned exactly one of m classes (i.e., ` = m).
Extending binary classification, we choose the standard basis vectors in Rm to be rep( ) for
the m classes. The learner predicts score t 2 Rm using the predictor W 2 Rm⇥p . So,
pred(t) = argmaxi ti . Let wj denote the jth row of W (corresponding to label j). The definition of margin becomes:
hwy , Xi max hwj , Xi
j6=y

which is identical to the multiclass margin studied earlier [10]. For the multiclass 0-1 loss L0-1 , we
recover their bound, up to constants2 . Moreover, our surrogate for L0-1 :
(t, y) = max 0, 1 + max t
6=y

ty ,

matches the multiclass extension of the Hinge loss studied by [11]. Finally, note that it is straightforward to obtain loss bounds for multiclass perceptron with R EJECT option by naturally extending
the definitions of rep and LR EJ for the binary case.
Ordinal Regression. The goal is to assign ordinal classes (such as ratings) to a set of objects
{X1 , X2 , . . . } described by their features Xi 2 Rp . In many cases, precise rating information
may not be available, but only their relative ranks; i.e., the observations consist of object-rank pairs
(X⌧ , y⌧ ) where y⌧ 2 [`]. Y is totally-ordered with “>” relation, which in turn induces a partial
ordering on the objects (Xj is preferred to Xj 0 if yj > yj 0 , Xj and Xj 0 are not comparable if
yj = yP
y|, the PRank perceptron algorithm [12] enjoys the
j 0 ). For the ranking loss L( , y) = |
n
bound ⌧ =1 L(⌧⌧ , y⌧ )  (` 1)(R2 + 1)/˜ 2 , where ˜ is a certain rank margin. By a reduction
to multi-class classification with ` classes, Algorithm 1 achieves the loss bound 4(` 1)2 R2 / 2
(albeit, for a different margin ).
Multilabel Classification. This setting generalizes multiclass classification in that instances are
assigned subsets of m classes rather than unique classes, i.e., ` = 2m . The loss function L of
interest may dictate the choice of rep and in turn pred. For example, consider the following subset
losses that treat labels as well as predictions as subsets: (i) Subset 0-1 loss: LIsErr ( , y) = 1 if
= y or 0 otherwise; (ii) Hamming loss: LHam ( , y) = | [ y| | \ y|, and (ii) Error set
size: LErrSetSize ( , y) = {(r, s) 2 y ⇥ ([m] \ y) : r 62 , s 2 } . A natural choice of rep then
d
is the subset indicator
vector
expressed as
P
P in {+1, 1} , where d = m = log `, which can be
1
m
p
rep( ) = m
e
e
(where
e
’s
are
the
standard
basis
vectors
in
R
).
The learner
j
j
j
j2
j62
predicts score t 2 Rm using a matrix W 2 Rm⇥p . Note that pred(t) = sign(t), where sign is
applied component-wise. The number of predictions is 2m , but we show in Appendix C.2 that the
surrogate (2) and its gradient can be efficiently computed for all of the above losses.

4

Subset Ranking

In subset ranking [13], the task is to learn to rank a number of documents in order of their relevance to
a query. We will assume, for simplicity, that the number of documents per query is constant that we
denote by m. The input space is a subset of Rm⇥p0 that we can identify with Rp for p = mp0 . Each
row of an input matrix corresponds to a p0 -dimensional feature vector derived jointly using the query
2
Perceptron algorithm in [10] is based on a slightly different loss defined as LErrSet (t, y) = 1 if |{r 6= y :
tr
ty }| > 0 or 0 otherwise (where t = W X). This loss upper bounds L0-1 (because of the way ties are
handled, there can be rounds when L0-1 is 0, but LErrSet is 1).

5

and one of the documents associated with it. The predictions are all m! permutations of degree m.
The most natural (but by no means the only one) representation of permutations is to set rep( ) =
/Z where (i) is the position of the document i in the predicted ranking and the normalization
Z ensures that rep( ) is a unit vector. Note that the dimension d of this representation is equal to m.
The minus sign in this representation ensures that pred(t) outputs a permutation that corresponds to
sorting the entries of t in decreasing order, a common convention in existing work. A more general
representation is obtained by setting rep( ) = f ( )/Z where f : R ! R is
decreasing
paPstrictly
m
2 (i) ensures
real valued function that is applied entry-wise to . The normalization Z =
f
i=1
that k rep( )k2 = 1. To convert an input matrix X 2 Rp (p = mp0 ) into a score vector t 2 Rm ,
it seems that we need to learn a matrix W 2 Rm⇥mp0 . However, a natural permutation invariance
requirement (if the documents associated are presented in a permuted fashion, the output scores
should also get permuted in the same way) reduces the dimensionality of W to p0 (see, e.g., [14] for
more details). Thus, given a vector w 2 Rp0 we get the score vector as t = Xw. The label space
consists of relevance score vectors y 2 {0, 1, . . . , Ymax }m where Ymax is typically between 1 and
4 (yielding 2 to 5 grades of relevance). Note that the prediction space (of size k = m!) is different
from the label space (of size ` = (Ymax + 1)m ).
A variety of loss functions have been used in subset ranking. For multigraded relevance judgments,
Pm
2y(i) 1
a very popular choice is NDCG which is defined as N DCG( , y) =
i=1 log2 (1+ (i)) /Z(y)
where Z(y) is a normalization constant ensuring NDCG stays bounded by 1. To convert it into a
loss we define LNDCG = 1 N DCG. Note that any permutation that sorts y in decreasing order
gets zero LNDCG . One might worry that the computation of the surrogate defined in (2) and its
gradient might require an enumeration of m! permutations. The next lemma allays such a concern.
Lemma 3. When L = LNDCG and rep( ) is chosen as above, the computation of the surrogate (2),
as well as its gradient, can be reduced to solving a linear assignment problem and hence can be
done in O(m3 ) time.
We now give a result explaining what it means for a score vector t to have a margin on y when we
use a representation of the form described above. Without loss of generality, we may assume that y
is sorted in decreasing order of relevance judgements.
Lemma
pPm 4. Suppose rep( ) = f ( )/Z for a strictly decreasing function f : R ! R and Z =
2
i=1 f (i). Let y be a non-constant relevance judgement vector sorted in decreasing order.
Suppose i1 < i2 , . . . < iN , N
1 are the positions where the relevance drops by a grade or more
(i.e., y(ij ) < y(ij 1)). Then t has a margin on y iff t is compatible with y and, for j 2 [N ],
tij

1

t ij +

f (ij

Z
1) f (ij )

where we define i0 = 1, iN +1 = m + 1 to handle boundary cases.
1
Note that if we choose f (i) = i↵ , ↵ > 1 then f (ij 1) f (ij ) = O(i↵
) for large ij . In
j
that case, the margin condition above requires less separation between documents with different
relevance scores down the list (when viewed in decreasing order of relevance scores) than at the top
of the list. We end this section with a loss bound for LNDCG under a margin condition.
Corollary 5. Suppose L = LNDCG and rep( ) is as in Lemma 4. Then, assuming the dataset is
linearly separable with margin , the sequence generated by Algorithm 1 with line 9 replaced by

satisfies

r⌧ = X⌧> (pred
n
X

⌧ =1

where kX⌧ kop  R.

1

(˜⌧ )

LNDCG (X⌧ w⌧ , y⌧ ) 

pred

1

(

y ))

2 Rp0 ⇥1

2Ymax +3 · m2 log22 (2m) · R2
2

Note that the result above uses the standard `2 -norm based notion of margin. Imagine a subset
ranking problem, where only a small number of features are relevant. It is therefore natural to
consider a notion of margin where the weight vector that ranks everything perfectly has low group `1
norm, instead of low `2 norm. The `1 margin also appears in the analysis of AdaBoost [2, Definition
6

6.2]. We can use a special case of a more general algorithm given in the appendix (Appendix B.2,
Algorithm 3). Specifically, we replace line 10 with the step w⌧ +1 = (r ) 1 (r (w⌧ ) r⌧ )
where (w) = 12 kwk2r . We set r = log(p0 )/(log(p0 ) 1). The mapping r and its inverse can
both be easily computed (see, e.g., [6, p. 145]).
Corollary 6. Suppose L = LNDCG and rep( ) is as in Lemma 4. Then, assuming the dataset is
linearly separable with margin by a unit `1 norm w? (kw? k1 = 1), the sequence generated by
Algorithm 3 with chosen as above (and line 9 modified as in Corollary 5), satisfies
n
X

⌧ =1

LNDCG (X⌧ w⌧ , y⌧ ) 

9 · 2Ymax +3 · m2 log22 (2m) · R2 · log p0
2

where maxj=1,...,po kX⌧,j k2  R and X⌧,j denotes the jth column of X⌧ .

5

Multilabel Ranking

As discussed in Section 3, in multilabel classification, both prediction space and label space are
{0, 1}m with sizes k = ` = 2m . In multilabel ranking, however, the learner has to output rankings
as predictions. So, as in the previous section, we have k = m! since the prediction can be any
one of m! permutations of the labels. As before, we choose rep( ) = f ( )/Z and hence d = m.
However, unlike the previous section, the input is no longer a matrix but a vector X 2 Rp . A
prediction t 2 Rd is obtained as W X where W 2 Rm⇥p . Note the contrast with the last section:
there, inputs are matrices and a weight vector is learned; here, inputs are vectors and a weight matrix
is learned. Since we output rankings, it is reasonable to use a loss that takes positions of labels into
account. We can use L = LNDCG . Algorithm 1 now immediately applies. Lemma 3 already showed
that is efficiently implementable. We have the following straightforward corollary.
Corollary 7. Suppose L = LNDCG and rep( ) is as in Lemma 4. Then, assuming the dataset is
linearly separable with margin , the sequence generated by Algorithm 1 satisfies
n
X

⌧ =1

LNDCG (X⌧ w⌧ , y⌧ ) 

2Ymax +3 · m2 log22 (2m) · R2
2

where kX⌧ k2  R.
The bound above matches the corresponding bound, up to loss specific constants, for the multiclass
multilabel perceptron (MMP) algorithm studied by [15]. The definition of margin by [15] for MMP
is different from ours since their algorithms are designed specifically for multilabel ranking. Just like
them, we can also consider other losses, e.g., precision at top K positions. Another perceptron style
algorithm for multilabel ranking adopts a pairwise approach of comparing two labels at a time [16].
However, no loss bounds are derived.
The result above uses the standard Frobenius norm based margin. Imagine a multilabel problem,
where only a small number of features are relevant across all labels. Then, it is natural to consider a
notion of margin where the matrix that ranksP
everything perfectly has low group (2, 1) norm, instead
p
of low Frobenius norm, where kW k2,1 = j=1 kWj k2 (Wj denotes a column of W ). We again
use a special case of Algorithm 3 (Appendix B.2). Specifically, we replace line 10 with the step
W⌧ +1 = (r ) 1 (r (W⌧ ) r⌧ ) where (W ) = 12 kW k22,r . Recall that the group (2, r)-norm is
the `r norm of the `2 norm of the columns of W . We set r = log(p)/(log(p) 1). The mapping
r and its inverse can both be easily computed (see, e.g., [17, Eq. (2)]).
Corollary 8. Suppose L = LNDCG and rep( ) is as in Lemma 4. Then, assuming the dataset is
linearly separable with margin by a unit group norm W ? (kW ? k2,1 = 1), the sequence generated
by Algorithm 3 with chosen as above, satisfies
n
X

⌧ =1

LNDCG (X⌧ w⌧ , y⌧ ) 

9 · 2Ymax +3 · m2 log22 (2m) · R2 · log p
2

where kX⌧ k1  R.
7

pred−1(σ(i))=1/i
pred−1(σ(i))=−i1.1
−10

10

pred−1(σ(i))=−i2
20

40
60
80
No. of Training Points (n)

(a)

100

Subset Ranking (n=30, p0=30)

0

10

pred−1(σ(i))=1/i
pred−1(σ(i))=−i1.1

−5

10

pred−1(σ(i))=−i2

−10

10

15

20
No. of documents in each instance (m)

25

Loss on Test Points (1−NDCG)

−5

10

Loss on Test Points (1−NDCG)

Loss on Test Points (1−NDCG)

Subset Ranking (m=20, p0=30)

0

10

0.4
0.3

L1 vs L2 (s=50, n=50, m=20)
Predtron−L2
Predtron−L1

0.2
0.1
0

(b)

500

1000
1500
2000
Data dimensionality (p0)

2500

(c)
1

Figure 1: Subset Ranking: NDCG loss for different pred choices with varying n (Plot (a)) and m
(Plot (b)). As predicted by Lemmas 4 and 5, pred 1 ( i ) = i1.1 is more accurate than 1/i. (c):
L1 vs L2 margin. LNDCG for two different Predtron algorithms based on L1 and L2 margin. Data
is generated using L1 margin notion but with varying sparsity of the optimal scoring function w⇤ .

6

Experiments

We now present simulation results to demonstrate the application of our proposed Predtron framework to subset ranking. We also demonstrate that empirical results match the trend predicted by
our error bounds, hence hinting at tightness of our (upper) bounds. Due to lack of space, we focus
only on the subset ranking problem. Also, we would like to stress that we do not claim that the
basic version of Predtron itself (with ⌘ = 1) provides a state-of-the-art ranker. Instead, we wish to
demonstrate the applicability and flexibility of our framework in a controlled setting.
We generated n data points X⌧ 2 Rm⇥p0 using a Gaussian distribution with independent rows. The
ith row of X⌧ represents a document and is sampled from a spherical Gaussian centered at µi . We
selected a w⇤ 2 Rp0 and also a set of thresholds [⇣1 , . . . , ⇣m+1 ] to generate relevance scores; we
set ⇣j = 1j , 82  j  m and ⇣1 = +1 and ⇣m+1 = 1. We set relevance score y⌧ (i) of the
ith document in the ⌧ th document-set as: y⌧ (i) = m j iff ⇣j+1  hX⌧ (i), w⇤ i  ⇣j . That is,
y⌧ (i) 2 [m 1].
We measure performance of a given method using the NDCG loss LNDCG defined in Section 4.
Note that LNDCG is less sensitive to errors in predictions for the less relevant documents in the list.
On the other hand, our selection of thresholds ⇣i ’s implies that the gap between scores of lowerranked documents is very small compared to the higher-ranked ones, and hence chances of making
mistakes lower down the list is higher.
Figure 1 (a) shows LNDCG (on a test set) for our Predtron algorithm (see Section 4) but with different
pred 1 functions. For pred 1 ( (i)) = f2 ( ) = i1.1 , f2 (i 1) f2 (i) is monotonically increasing
with i. On the other hand, for pred 1 ( (i)) = f1 ( ) = 1/i, f1 (i 1) f1 (i) is monotonically
decreasing with i. Lemma 4 shows that the mistake bound (in terms of LNDCG ) of Predtron is better
when pred 1 function is selected to be f2 ( (i)) = i1.1 (as well as for f3 ( (i)) = i2 ) instead of
f1 ( (i)) = 1/i. Clearly, Figure 1 (a) empirically validates this mistake bound with LNDCG going
to almost 0 for f2 and f3 with just 60 training points, while f1 based Predtron has large loss even
with n = 100 training points.
Next, we fix the number of training instances to be n = 30 and vary the number of documents m.
As the gap between ⇣i ’s decreases for larger i, increasing m implies reducing the margin. Naturally,
Predtron with the above mentioned inverse functions has monotonically increasing loss (see Figure 1
(b)). However, f2 and f3 provide zero-loss solutions for larger m when compared to f1 .
Finally, we conduct an experiment to show that by selecting appropriate notion of margin, Predtron
can obtain more accurate solutions. To this end, we generate data from [ 1, 1]p0pand select a sparse
w⇤ . Now, Predtron with `2 -margin notion, i.e., standard gradient descent has p0 dependency in
the error bounds while the `1 -margin (see Corollary 6) has only s log(p0 ) dependence. This error
dependency is also revealed by Figure 1 (c), where increasing p0 with fixed s leads to minor increase
in the loss for `1 -based Predtron but leads to significantly higher loss for `2 -based Predtron.
Acknowledgments
A. Tewari acknowledges the support of NSF under grant IIS-1319810.
8

References
[1] Harish G. Ramaswamy and Shivani Agarwal. Classification calibration dimension for general multiclass
losses. In Advances in Neural Information Processing Systems, pages 2078–2086, 2012.
[2] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of machine learning. MIT
press, 2012.
[3] Michael Collins. Discriminative training methods for hidden Markov models: Theory and experiments
with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural
language processing-Volume 10, pages 1–8, 2002.
[4] Nathan D. Ratliff, J Andrew Bagnell, and Martin Zinkevich. (Approximate) subgradient methods for
structured prediction. In International Conference on Artificial Intelligence and Statistics, pages 380–
387, 2007.
[5] Youssef Mroueh, Tomaso Poggio, Lorenzo Rosasco, and Jean-Jeacques Slotine. Multiclass learning with
simplex coding. In Advances in Neural Information Processing Systems, pages 2789–2797, 2012.
[6] Shai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends in Machine Learning, 4(2):107–194, 2011.
[7] Albert B.J. Novikoff. On convergence proofs on perceptrons. In Proceedings of the Symposium on the
Mathematical Theory of Automata, volume 12, pages 615–622, 1962.
[8] Yaoyong Li, Hugo Zaragoza, Ralf Herbrich, John Shawe-Taylor, and Jaz S. Kandola. The perceptron
algorithm with uneven margins. In Proceedings of the Nineteenth International Conference on Machine
Learning, pages 379–386, 2002.
[9] Gunnar Ratsch and Jyrki Kivinen. Extended classification with modified Perceptron, 2002. Presented
at the NIPS 2002 Workshop: Beyond Classification and Regression: Learning Rankings, Preferences,
Equality Predicates, and Other Structures; abstract available at http://www.cs.cornell.edu/
people/tj/ranklearn/raetsch_kivinen.pdf.
[10] Koby Crammer and Yoram Singer. Ultraconservative online algorithms for multiclass problems. The
Journal of Machine Learning Research, 3:951–991, 2003.
[11] Koby Crammer and Yoram Singer. On the algorithmic implementation of multiclass kernel-based vector
machines. The Journal of Machine Learning Research, 2:265–292, 2002.
[12] Koby Crammer and Yoram Singer. Pranking with ranking. Advances in Neural Information Procession
Systems, 14:641–647, 2002.
[13] David Cossock and Tong Zhang. Statistical analysis of bayes optimal subset ranking. IEEE Transactions
on Information Theory, 54(11):5140–5154, 2008.
[14] Ambuj Tewari and Sougata Chaudhuri. Generalization error bounds for learning to rank: Does the length
of document lists matter? In Proceedings of the 32nd International Conference on Machine Learning,
volume 37 of JMLR Workshop and Conference Proceedings, 2015.
[15] Koby Crammer and Yoram Singer. A family of additive online algorithms for category ranking. The
Journal of Machine Learning Research, 3:1025–1058, 2003.
[16] Eneldo Loza Mencı́a and Johannes Furnkranz. Pairwise learning of multilabel classifications with perceptrons. In IEEE International Joint Conference on Neural Networks, pages 2899–2906, 2008.
[17] Sham M. Kakade, Shai Shalev-Shwartz, and Ambuj Tewari. Regularization techniques for learning with
matrices. Journal of Machine Learning Research, 13:1865–1890, 2012.

9

