Accelerated Mirror Descent
in Continuous and Discrete Time
Walid Krichene
UC Berkeley

Alexandre M. Bayen
UC Berkeley

Peter L. Bartlett
UC Berkeley and QUT

walid@eecs.berkeley.edu

bayen@berkeley.edu

bartlett@berkeley.edu

Abstract
We study accelerated mirror descent dynamics in continuous and discrete time.
Combining the original continuous-time motivation of mirror descent with a recent ODE interpretation of Nesterovâ€™s accelerated method, we propose a family of
continuous-time descent dynamics for convex functions with Lipschitz gradients,
such that the solution trajectories converge to the optimum at a O(1/t2 ) rate. We
then show that a large family of first-order accelerated methods can be obtained as
a discretization of the ODE, and these methods converge at a O(1/k 2 ) rate. This
connection between accelerated mirror descent and the ODE provides an intuitive
approach to the design and analysis of accelerated first-order algorithms.

1

Introduction

We consider a convex optimization problem, minimizexâˆˆX f (x), where X âŠ† Rn is convex and
closed, f is a C 1 convex function, and âˆ‡f is assumed to be Lf -Lipschitz. Let f ? be the minimum
of f on X . Many convex optimization methods can be interpreted as the discretization of an ordinary
differential equation, the solutions of which are guaranteed to converge to the set of minimizers. Perhaps the simplest such method is gradient descent, given by the iteration x(k+1) = x(k) âˆ’sâˆ‡f (x(k) )
for some step size s, which can be interpreted as the discretization of the ODE XÌ‡(t) = âˆ’âˆ‡f (X(t)),
with discretization step s. The well-established theory of ordinary differential equations can provide
guidance in the design and analysis of optimization algorithms, and has been used for unconstrained
optimization [8, 7, 13], constrained optimization [27] and stochastic optimization [25]. In particular,
proving convergence of the solution trajectories of an ODE can often be achieved using simple and
elegant Lyapunov arguments. The ODE can then be carefully discretized to obtain an optimization algorithm for which the convergence rate can be analyzed by using an analogous Lyapunov
argument in discrete time.
In this article, we focus on two families of first-order methods: Nesterovâ€™s accelerated method [22],
and Nemirovskiâ€™s mirror descent method [19]. First-order methods have become increasingly important for large-scale optimization problems that arise in machine learning applications. Nesterovâ€™s
accelerated method [22] has been applied to many problems and extended in a number of ways, see
for example [23, 20, 21, 4]. The mirror descent method also provides an important generalization of the gradient descent method to non-Euclidean geometries, as discussed in [19, 3], and has
many applications in convex optimization [6, 5, 12, 15], as well as online learning [9, 11]. An intuitive understanding of these methods is of particular importance for the design and analysis of
new algorithms. Although Nesterovâ€™s method has been notoriously hard to explain intuitively [14],
progress has been made recently: in [28], Su et al. give an ODE interpretation of Nesterovâ€™s method.
However, this interpretation is restricted to the original method [22], and does not apply to its extensions to non-Euclidean geometries. In [1], Allen-Zhu and Orecchia give another interpretation
of Nesterovâ€™s method, as performing, at each iteration, a convex combination of a mirror step and a
gradient step. Although it covers a broader family of algorithms (including non-Euclidean geometries), this interpretation still requires an involved analysis, and lacks the simplicity and elegance of
1

ODEs. We provide a new interpretation which has the benefits of both approaches: we show that a
broad family of accelerated methods (which includes those studied in [28] and [1]) can be obtained
as a discretization of a simple ODE, which converges at a O(1/t2 ) rate. This provides a unified
interpretation, which could potentially simplify the design and analysis of first-order accelerated
methods.
The continuous-time interpretation [28] of Nesterovâ€™s method and the continuous-time motivation
of mirror descent [19] both rely on a Lyapunov argument. They are reviewed in Section 2. By
combining these ideas, we propose, in Section 3, a candidate Lyapunov function V (X(t), Z(t), t)
that depends on two state variables: X(t), which evolves in the primal space E = Rn , and Z(t),
which evolves in the dual space E âˆ— , and we design coupled dynamics of (X, Z) to guarantee that
d
dt V (X(t), Z(t), t) â‰¤ 0. Such a function is said to be a Lyapunov function, in reference to [18];
see also [16]. This leads to a new family of ODE systems, given in Equation (5). We prove the
existence and uniqueness of the solution to (5) in Theorem 1. Then we prove in Thereom 2, using
the Lyapunov function V , that the solution trajectories are such that f (X(t)) âˆ’ f ? = O(1/t2 ). In
Section 4, we give a discretization of these continuous-time dynamics, and obtain a family of accelerated mirror descent methods, for which we prove the same O(1/k 2 ) convergence rate (Theorem 3)
using a Lyapunov argument analogous to (though more involved than) the continuous-time case. We
give, as an example, a new accelerated method on the simplex, which can be viewed as performing,
at each step, a convex combination of two entropic projections with different step sizes. This ODE
interpretation of accelerated mirror descent gives new insights and allows us to extend recent results
such as the adaptive restarting heuristics proposed by Oâ€™Donoghue and CandeÌ€s in [24], which are
known to empirically improve the convergence rate. We test these methods on numerical examples
in Section 5 and comment on their performance.

2

ODE interpretations of Nemirovskiâ€™s mirror descent method and
Nesterovâ€™s accelerated method

Proving convergence of the solution trajectories of an ODE often involves a Lyapunov argument. For
example, to prove convergence of the solutions to the gradient descent ODE XÌ‡(t) = âˆ’âˆ‡f (X(t)),
consider the Lyapunov function V (X(t)) = 21 kX(t) âˆ’ x? k2 for some minimizer x? . Then the time
derivative of V (X(t)) is given by
D
E
d
V (X(t)) = XÌ‡(t), X(t) âˆ’ x? = hâˆ’âˆ‡f (X(t)), X(t) âˆ’ x? i â‰¤ âˆ’(f (X(t)) âˆ’ f ? ),
dt

where the last inequality is by convexity of f .Integrating, we
âˆ’ V (x0 ) â‰¤ tf ? âˆ’
 have V (X(t))
Rt
R
R
t
t
f (X(Ï„ ))dÏ„ , thus by Jensenâ€™s inequality, f 1t 0 X(Ï„ )dÏ„ âˆ’ f ? â‰¤ 1t 0 f (X(Ï„ ))dÏ„ âˆ’ f ? â‰¤
0
 R

V (x0 )
1 t
?
t , which proves that f t 0 X(Ï„ )dÏ„ converges to f at a O(1/t) rate.
2.1

Mirror descent ODE

The previous argument was extended by Nemirovski and Yudin in [19] to a family of methods
called mirror descent. The idea is to start from a non-negative function V , then to design dynamics
for which V is a Lyapunov function. Nemirovski and Yudin argue that one can replace the Lyapunov
function V (X(t)) = 21 kX(t) âˆ’ x? k2 by a function on the dual space, V (Z(t)) = DÏˆâˆ— (Z(t), z ? ),
where Z(t) âˆˆ E âˆ— is a dual variable for which we will design the dynamics (z ? is the value of Z at
equilibrium), and the corresponding trajectory in the primal space is X(t) = âˆ‡Ïˆ âˆ— (Z(t)). Here Ïˆ âˆ— is
a convex function defined on E âˆ— , such that âˆ‡Ïˆ âˆ— maps E âˆ— to X , and DÏˆâˆ— (Z(t), z ? ) is the Bregman
divergence associated with Ïˆ âˆ— , defined as DÏˆâˆ— (z, y) = Ïˆ âˆ— (z) âˆ’ Ïˆ âˆ— (y) âˆ’ hâˆ‡Ïˆ âˆ— (y), z âˆ’ yi. The
âˆ—
function Ïˆ âˆ— is said to be `-strongly convex w.r.t. a reference norm k Â· kâˆ— if DÏˆ
(z, y) â‰¥ 2` kz âˆ’ yk2âˆ—
L
for all y, z, and it is said to be L-smooth w.r.t. k Â· kâˆ— if DÏˆâˆ— (z, y) â‰¤ 2 kz âˆ’ yk2âˆ— . For a review of
properties of Bregman divergences, see Chapter 11.2 in [11], or Appendix A in [2].
By definition of the Bregman divergence, we have
d
d
d
V (Z(t)) = DÏˆâˆ— (Z(t), z ? ) =
(Ïˆ âˆ— (Z(t)) âˆ’ Ïˆ âˆ— (z ? ) âˆ’ hâˆ‡Ïˆ âˆ— (z âˆ— ), Z(t) âˆ’ z ? i)
dt
dt
dt
D
E D
E
= âˆ‡Ïˆ âˆ— (Z(t)) âˆ’ âˆ‡Ïˆ âˆ— (z ? ), ZÌ‡(t) = X(t) âˆ’ x? , ZÌ‡(t) .

2

Therefore, if the dual variable Z obeys the dynamics ZÌ‡ = âˆ’âˆ‡f (X), then

d
V (Z(t)) = âˆ’ hâˆ‡f (X(t)), X(t) âˆ’ x? i â‰¤ âˆ’(f (X(t)) âˆ’ f ? )
dt

and
the same
 by
 argument as in the gradient descent ODE, V is a Lyapunov function and
R
1 t
f t 0 X(Ï„ )dÏ„ âˆ’ f ? converges to 0 at a O(1/t) rate. The mirror descent ODE system can be
summarized by
ï£±
âˆ—
ï£´
ï£² X = âˆ‡Ïˆ (Z)
ZÌ‡ = âˆ’âˆ‡f (X)
ï£´
ï£³ X(0) = x , Z(0) = z with âˆ‡Ïˆ âˆ— (z ) = x
0
0
0
0

(1)

Note that since âˆ‡Ïˆ âˆ— maps into X , X(t) = âˆ‡Ïˆ âˆ— (Z(t)) remains in X . Finally, the unconstrained
gradient descent ODE can be obtained as a special case of the mirror descent ODE (1) by taking
Ïˆ âˆ— (z) = 12 kzk2 , for which âˆ‡Ïˆ âˆ— is the identity, in which case X and Z coincide.
2.2

ODE interpretation of Nesterovâ€™s accelerated method

In [28], Su et al. show that Nesterovâ€™s accelerated method [22] can be interpreted as a discretization
of a second-order differential equation, given by
(

XÌˆ + r+1
XÌ‡ + âˆ‡f (X) = 0
t
X(0) = x0 , XÌ‡(0) = 0

(2)
2

The argument uses the following Lyapunov function (up to reparameterization), E(t) = tr (f (X) âˆ’
f ? ) + 2r kX + rt XÌ‡ âˆ’ x? k2 , which is proved to be a Lyapunov function for the ODE (2) whenever
r â‰¥ 2. Since E is decreasing along trajectories of the system, it follows that for all t > 0, E(t) â‰¤
? 2
2
k
E(0) = 2r kx0 âˆ’ x? k2 , therefore f (X(t)) âˆ’ f ? â‰¤ tr2 E(t) â‰¤ tr2 E(0) â‰¤ rt2 kx0 âˆ’x
, which proves
2
that f (X(t)) converges to f ? at a O(1/t2 ) rate. One should note in particular that the squared
Euclidean norm is used in the definition of E(t) and, as a consequence, discretizing the ODE (2)
leads to a family of unconstrained, Euclidean accelerated methods. In the next section, we show
that by combining this argument with Nemirovskiâ€™s idea of using a general Bregman divergence
as a Lyapunov function, we can construct a much more general family of ODE systems which
have the same O(1/t2 ) convergence guarantee. And by discretizing the resulting dynamics, we
obtain a general family of accelerated methods that are not restricted to the unconstrained Euclidean
geometry.

3
3.1

Continuous-time Accelerated Mirror Descent
Derivation of the accelerated mirror descent ODE

We consider a pair of dual convex functions, Ïˆ defined on X and Ïˆ âˆ— defined on E âˆ— , such that
âˆ‡Ïˆ âˆ— : E âˆ— â†’ X . We assume that Ïˆ âˆ— is LÏˆâˆ— -smooth with respect to k Â· kâˆ— , a reference norm on the
dual space. Consider the function
V (X(t), Z(t), t) =

t2
(f (X(t)) âˆ’ f ? ) + rDÏˆâˆ— (Z(t), z ? )
r

(3)

?

where Z is a dual variable for which we will design the dynamics, and z is its value at equilibrium.
Taking the time-derivative of V , we have
E
D
E
d
2t
t2 D
V (X(t), Z(t), t) = (f (X) âˆ’ f ? ) +
âˆ‡f (X), XÌ‡ + r ZÌ‡, âˆ‡Ïˆ âˆ— (Z) âˆ’ âˆ‡Ïˆ âˆ— (z ? ) .
dt
r
r

Assume that ZÌ‡ = âˆ’ rt âˆ‡f (X). Then, the time-derivative of V becomes



d
2t
t
?
âˆ—
âˆ— ?
V (X(t), Z(t), t) = (f (X) âˆ’ f ) âˆ’ t âˆ‡f (X), âˆ’ XÌ‡ + âˆ‡Ïˆ (Z) âˆ’ âˆ‡Ïˆ (z ) .
dt
r
r

Therefore, if Z is such that âˆ‡Ïˆ âˆ— (Z) = X + rt XÌ‡, and âˆ‡Ïˆ âˆ— (z ? ) = x? , then,

d
2t
2t
V (X(t), Z(t), t) = (f (X) âˆ’ f ? ) âˆ’ t hâˆ‡f (X), X âˆ’ x? i â‰¤ (f (X) âˆ’ f ? ) âˆ’ t(f (X) âˆ’ f ? )
dt
r
r
râˆ’2
â‰¤ âˆ’t
(f (X) âˆ’ f ? )
(4)
r

3

and it follows that V is a Lyapunov function whenever r â‰¥ 2. The proposed ODE system is then
ï£±
âˆ—
r
ï£´
ï£² XÌ‡ = t (âˆ‡Ïˆ (Z) âˆ’ X),
t
ZÌ‡ = âˆ’ r âˆ‡f (X),
ï£´
ï£³ X(0) = x , Z(0) = z , with âˆ‡Ïˆ âˆ— (z ) = x .
0
0
0
0

(5)

1
2
âˆ—
In the unconstrained Euclidean case, taking Ïˆ âˆ— (z)
 = 2 kzk
 , we have âˆ‡Ïˆ (z) = z, thus Z =
t
t
d
t
X + r XÌ‡, and the ODE system is equivalent to dt X + r XÌ‡ = âˆ’ r âˆ‡f (X), which is equivalent to
the ODE (2) studied in [28], which we recover as a special case.

We also give another interpretation of ODE (5): theR first equation is equivalent to tr XÌ‡ + rtrâˆ’1 X =
t
rtrâˆ’1 âˆ‡Ïˆ âˆ— (Z), or, in integral form, tr X(t) = r 0 Ï„ râˆ’1 âˆ‡Ïˆ âˆ— (Z(Ï„ ))dÏ„ , which can be written as
X(t) =

Rt
0

w(Ï„ )âˆ‡Ïˆ âˆ— (Z(Ï„ ))dÏ„
Rt
,
w(Ï„ )dÏ„
0

with w(Ï„ ) = Ï„ râˆ’1 . Therefore the coupled dynamics of (X, Z) can

be interpreted as follows: the dual variable Z accumulates gradients with a rt rate, while the primal
variable X is a weighted average of âˆ‡Ïˆ âˆ— (Z(Ï„ )) (the â€œmirroredâ€ dual trajectory), with weights
proportional to Ï„ râˆ’1 . This also gives an interpretation of r as a parameter controlling the weight
distribution. It is also interesting to observe that the weights are increasing if and only if r â‰¥ 2.
Finally, with this averaging interpretation, it becomes clear that the primal trajectory X(t) remains
in X , since âˆ‡Ïˆ âˆ— maps into X and X is convex.
3.2

Solution of the proposed dynamics

First, we prove existence and uniqueness of a solution to the ODE system (5), defined for all t >
0. By assumption, Ïˆ âˆ— is LÏˆâˆ— -smooth w.r.t. k Â· kâˆ— , which is equivalent (see e.g. [26]) to âˆ‡Ïˆ âˆ— is
LÏˆâˆ— -Lipschitz. Unfortunately, due to the rt term in the expression of XÌ‡, the function (X, Z, t) 7â†’
(XÌ‡, ZÌ‡) is not Lipschitz at t = 0, and we cannot directly apply the Cauchy-Lipschitz existence and
uniqueness theorem. However, one can work around it by considering a sequence of approximating
ODEs, similarly to the argument used in [28].
Theorem 1. Suppose f is C 1 , and that âˆ‡f is Lf -Lipschitz, and let (x0 , z0 ) âˆˆ X Ã— E âˆ— such that
âˆ‡Ïˆ âˆ— (z0 ) = x0 . Then the accelerated mirror descent ODE system (5) with initial condition (x0 , z0 )
has a unique solution (X, Z), in C 1 ([0, âˆž), Rn ).
We will show existence of a solution on any given interval [0, T ] (uniqueness is proved in the supplementary material). Let Î´ > 0, and consider the smoothed ODE system
ï£±
âˆ—
r
ï£´
ï£² XÌ‡ = max(t,Î´) (âˆ‡Ïˆ (Z) âˆ’ X),
t
ZÌ‡ = âˆ’ r âˆ‡f (X),
ï£´
ï£³ X(0) = x , Z(0) = z with âˆ‡Ïˆ âˆ— (z ) = x .
0
0
0
0

(6)

r
Since the functions (X, Z) 7â†’ âˆ’ rt âˆ‡f (X) and (X, Z) 7â†’ max(t,Î´)
(âˆ‡Ïˆ âˆ— (Z) âˆ’ X) are Lipschitz for
all t âˆˆ [0, T ], by the Cauchy-Lipschitz theorem (Theorem 2.5 in [29]), the system (6) has a unique
solution (XÎ´ , ZÎ´ ) in C 1 ([0, T ]). In order to show the existence of a solution to the original ODE,
we use the following Lemma (proved in the supplementary material).

Lemma 1. Let t0 = âˆš 2
. Then the family of solutions (XÎ´ , ZÎ´ )|[0,t0 ] Î´â‰¤t is equi-LipschitzLf LÏˆâˆ—

0

continuous and uniformly bounded.

Proof of existence. Consider the family of solutions (XÎ´i , ZÎ´i ), Î´i = t0 2âˆ’i iâˆˆN restricted to [0, t0 ].
By Lemma 1, this family is equi-Lipschitz-continuous and uniformly bounded, thus by the ArzelaÌ€Ascoli theorem, there exists a subsequence ((XÎ´i , ZÎ´i ))iâˆˆI that converges uniformly on [0, t0 ]
(where I âŠ‚ N is an infinite set of indices). Let (XÌ„, ZÌ„) be its limit. Then we prove that (XÌ„, ZÌ„)
is a solution to the original ODE (5) on [0, t0 ].
First, since for all i âˆˆ I, XÎ´i (0) = x0 and ZÎ´i (0) = z0 , it follows that XÌ„(0) =
limiâ†’âˆž,iâˆˆI XÎ´i (0) = x0 and ZÌ„(0) = limiâ†’âˆž,iâˆˆI ZÎ´i (0) = z0 , thus (XÌ„, ZÌ„) satisfies the initial
conditions. Next, let t1 âˆˆ (0, t0 ), and let (XÌƒ, ZÌƒ) be the solution of the ODE (5) on t â‰¥ t1 , with
initial condition (XÌ„(t1 ), ZÌ„(t1 )). Since (XÎ´i (t1 ), ZÎ´i (t1 ))iâˆˆI â†’ (XÌ„(t1 ), ZÌ„(t1 )) as i â†’ âˆž, then by
4

continuity of the solution w.r.t. initial conditions (Theorem 2.8 in [29]), we have that for some  > 0,
XÎ´i â†’ XÌƒ uniformly on [t1 , t1 + ). But we also have XÎ´i â†’ XÌ„ uniformly on [0, t0 ], therefore XÌ„
and XÌƒ coincide on [t1 , t1 + ), therefore XÌ„ satisfies the ODE on [t1 , t1 + ). And since t1 is arbitrary
in (0, t0 ), this concludes the proof of existence.
3.3

Convergence rate

It is now straightforward to establish the convergence rate of the solution.
Theorem 2. Suppose that f has Lipschitz gradient, and that Ïˆ âˆ— is a smooth distance generating
function. Let (X(t), Z(t)) be the solution to the accelerated mirror descent ODE (5) with r â‰¥ 2.
Then for all t > 0, f (X(t)) âˆ’ f ? â‰¤

r 2 DÏˆâˆ— (z0 ,z ? )
.
t2

2

Proof. By construction of the ODE, V (X(t), Z(t), t) = tr (f (X(t)) âˆ’ f ? ) + rDÏˆâˆ— (Z(t), z ? ) is
2
a Lyapunov function. It follows that for all t > 0, tr (f (X(t)) âˆ’ f ? ) â‰¤ V (X(t), Z(t), t) â‰¤
V (x0 , z0 , 0) = rDÏˆâˆ— (z0 , z ? ).

4

Discretization

Next, we show that with a careful discretization of this continuous-time dynamics, we can obtain a
general family of accelerated mirror descent methods for constrained optimization. Using a mixed
forward/backward
(5)
âˆš system
âˆšEuler scheme (see e.g. Chapter 2 in [10]), we can discretize the ODE
(k)
of
the
ODE
(5),
let
t
=
k
s,
and
x
=
using a step size s as follows. Given a solution (X, Z)
k
âˆš
âˆš
k)
X(tk ) = X(k s). Approximating XÌ‡(tk ) with X(tk + âˆšs)âˆ’X(t
,
we
propose
the
discretization
s
(

(k)
x(k+1)
âˆšâˆ’x
s
(k)
z (k+1)
âˆšâˆ’z
s

=
+

r
âˆš
âˆ‡Ïˆ âˆ— (z (k) ) âˆ’ x(k+1)
kâˆš s
k s
(k+1)
) = 0.
r âˆ‡f (x



,

(7)



The first equation can be rewritten as x(k+1) = x(k) + kr âˆ‡Ïˆ âˆ— (z (k) ) / 1 + kr (note the independence on s, due to the time-scale invariance of the first ODE). In other words, x(k+1) is a convex
r
k
combination of âˆ‡Ïˆ âˆ— (z (k) ) and x(k) with coefficients Î»k = r+k
and 1 âˆ’ Î»k = r+k
. To summarize,
our first discrete scheme can be written as
(
r
x(k+1) = Î»k âˆ‡Ïˆ âˆ— (z (k) ) + (1 âˆ’ Î»k )x(k) , Î»k = r+k
,
(8)
ks
(k+1)
(k+1)
(k)
).
z
= z âˆ’ r âˆ‡f (x
Since âˆ‡Ïˆ âˆ— maps into the feasible set X , starting from x(0) âˆˆ X guarantees that x(k) remains in X
for all k (by convexity of X ). Note that by duality, we have âˆ‡Ïˆ âˆ— (xâˆ— ) = arg maxxâˆˆX hx, xâˆ— iâˆ’Ïˆ(x),
and if we additionally assume that Ïˆ is differentiable on the image of âˆ‡Ïˆ âˆ— , then âˆ‡Ïˆ = (âˆ‡Ïˆ âˆ— )âˆ’1
(Theorem 23.5 in [26]), thus if we write zÌƒ (k) = âˆ‡Ïˆ âˆ— (z (k) ), the second equation can be written as


ks
ks
âˆ‡f (x(k+1) )) = arg min Ïˆ(x) âˆ’ âˆ‡Ïˆ(zÌƒ (k) ) âˆ’
âˆ‡f (x(k+1) ), x
r
r
xâˆˆX
D
E
ks
= arg min
âˆ‡f (x(k+1) ), x + DÏˆ (x, zÌƒ (k) ).
r
xâˆˆX

zÌƒ (k+1) = âˆ‡Ïˆ âˆ— (âˆ‡Ïˆ(zÌƒ (k) ) âˆ’

We will eventually modify this scheme in order to be able to prove the desired O(1/k 2 ) convergence
rate. However, we start by analyzing this version.âˆš Motivated by the continuous-time Lyapunov
function (3), and using the correspondence t â‰ˆ k s, we consider the potential function E (k) =
âˆš
2
V (x(k) , z (k) , k s) = kr s (f (x(k) ) âˆ’ f ? ) + rDÏˆâˆ— (z (k) , z ? ). Then we have
(k + 1)2 s
k2 s
(f (x(k+1) ) âˆ’ f ? ) âˆ’
(f (x(k) ) âˆ’ f ? ) + r(DÏˆâˆ— (z (k+1) , z ? ) âˆ’ DÏˆâˆ— (z (k) , z ? ))
r
r
s(1 + 2k)
k2 s
=
(f (x(k+1) ) âˆ’ f (x(k) )) +
(f (x(k+1) ) âˆ’ f ? ) + r(DÏˆâˆ— (z (k+1) , z ? ) âˆ’ DÏˆâˆ— (z (k) , z ? )).
r
r

E (k+1) âˆ’ E (k) =

5

And through simple algebraic manipulation, the last term can be bounded as follows
DÏˆâˆ— (z (k+1) , z ? ) âˆ’ DÏˆâˆ— (z (k) , z ? )
D
E
= DÏˆâˆ— (z (k+1) , z (k) ) + âˆ‡Ïˆ âˆ— (z (k) ) âˆ’ âˆ‡Ïˆ âˆ— (z ? ), z (k+1) âˆ’ z (k)
by definition of the Bregman divergence


k (k+1)
ks
= DÏˆâˆ— (z (k+1) , z (k) ) +
(x
âˆ’ x(k) ) + x(k+1) âˆ’ x? , âˆ’ âˆ‡f (x(k+1) )
by the discretization (8)
r
r
â‰¤ DÏˆâˆ— (z (k+1) , z (k) ) +

k2 s
ks ?
(f (x(k) ) âˆ’ f (x(k+1) )) +
(f âˆ’ f (x(k+1) )).
r2
r

by convexity of f

Therefore we have E (k+1) âˆ’ E (k) â‰¤ âˆ’ s[(râˆ’2)kâˆ’1]
(f (x(k+1) ) âˆ’ f ? ) + rDÏˆâˆ— (z (k+1) , z (k) ). Comr
d
V (X(t), Z(t), t) in the continuous-time case,
paring this expression with the expression (4) of dt
we see that we obtain an analogous expression, except for the additional Bregman divergence term
rDÏˆâˆ— (z (k+1) , z (k) ), and we cannot immediately conclude that V is a Lyapunov function. This can
be remedied by the following modification of the discretization scheme.
4.1

A family of discrete-time accelerated mirror descent methods

In the expression (8) of x(k+1) = Î»k zÌƒ (k) + (1 âˆ’ Î»k )x(k) , we propose to
x(k) with xÌƒ(k) , ob
 replace
(k)
(k)
tained as a solution to a minimization problem xÌƒ = arg minxâˆˆX Î³s âˆ‡f (x ), x + R(x, x(k) ),
where R is regularization function that satisfies the following assumptions: there exist 0 < `R â‰¤ LR
such that for all x, x0 âˆˆ X , `2R kx âˆ’ x0 k2 â‰¤ R(x, x0 ) â‰¤ L2R kx âˆ’ x0 k2 .
0 2

k
In the Euclidean case, one can take R(x, x0 ) = kxâˆ’x
, in which case `R = LR = 1 and the
2
xÌƒ update becomes a prox-update. In the general case, one can take R(x, x0 ) = DÏ† (x, x0 ) for
some distance generating function Ï† which is `R -strongly convex and LR -smooth, in which case
the xÌƒ update becomes a mirror update. The resulting method is summarized in Algorithm 1. This
algorithm is a generalization of Allen-Zhu and Orecchiaâ€™s interpretation of Nesterovâ€™s method in [1],
where x(k+1) is a convex combination of a mirror descent update and a gradient descent update.

Algorithm 1 Accelerated mirror descent with distance generating function Ïˆ âˆ— , regularizer R, step
size s, and parameter r â‰¥ 3

1: Initialize xÌƒ(0) = x0 , zÌƒ (0) = x0 , or z (0) âˆˆ (âˆ‡Ïˆ)âˆ’1 (x0 ) .
2: for k âˆˆ N do
r
3:
x(k+1) = Î»k zÌƒ (k) + (1 âˆ’ Î»k )xÌƒ(k) , with Î»k = r+k
.
D
E
(k+1)
(k+1)
ks
), zÌƒ + DÏˆ (zÌƒ, zÌƒ (k) ).
4:
zÌƒ
= arg minzÌƒâˆˆX r âˆ‡f (x

5:

4.2

âˆ‡f (x(k+1) ) and zÌƒ (k+1) = âˆ‡Ïˆ âˆ— (z (k+1) ).
If Ïˆ is non-differentiable, z (k+1) = z (k) âˆ’ kr
D
E s
(k+1)
(k+1)
xÌƒ
= arg minxÌƒâˆˆX Î³s âˆ‡f (x
), xÌƒ + R(xÌƒ, x(k+1) )



Consistency of the modified scheme

One can show that given our assumptions on R, xÌƒ(k) = x(k) + O(s). Indeed, we have
D
E
`R (k)
kxÌƒ âˆ’ x(k) k2 â‰¤ R(xÌƒ(k) , x(k) ) â‰¤ R(x(k) , x(k) ) + Î³s âˆ‡f (x(k) ), x(k) âˆ’ xÌƒ(k)
2
â‰¤ Î³skâˆ‡f (x(k) )kâˆ— kxÌƒ(k) âˆ’ x(k) k
(k)

)kâˆ—
therefore kxÌƒ(k) âˆ’ x(k) k â‰¤ s 2Î³kâˆ‡f`(x
, which proves the claim. Using this observation, we
R
can show that the modified discretization scheme is consistent with the original ODE (5), that is,
the difference equations defining x(k) and z (k) converge, as s tends to 0, to the ordinary differential
equations of the continuous-time system (5). The difference equations of Algorithm 1 are equivalent
to (7) in which x(k) is replaced by xÌƒ(k) , i.e.
(
(k)
x(k+1)
r
âˆšâˆ’xÌƒ
= kâˆš
(âˆ‡Ïˆ âˆ— (z (k) ) âˆ’ x(k+1) )
s
s
(k)
z (k+1)
âˆšâˆ’z
s

âˆš

= âˆ’ k r s âˆ‡f (x(k+1) )
6

Now suppose there exist C 1 functions (X, Z), defined on R+ , such that X(tk ) â‰ˆ x(k) and
âˆš
Z(tk ) â‰ˆ z (k) for tk = k s. Then, usingâˆš the fact that xÌƒ(k) = x(k) + O(s), we have
âˆš
âˆš
(k+1)
(k)
(k+1)
(k)
x
k)
âˆšâˆ’xÌƒ
= x âˆšâˆ’x
+ O( s) â‰ˆ X(tk + âˆšs)âˆ’X(t
+ O( s) = XÌ‡(tk ) + o(1), and simis
s
s
larly,

(k)
z (k+1)
âˆšâˆ’z
s

â‰ˆ ZÌ‡(tk ) + o(1), therefore the difference equation system can be written as
(
âˆš
XÌ‡(tk ) + o(1) = trk (âˆ‡Ïˆ âˆ— (Z(tk )) âˆ’ X(tk + s))
âˆš
ZÌ‡(tk ) + o(1) = âˆ’ trk âˆ‡f (X(tk + s))

which converges to the ODE (5) as s â†’ 0.
4.3

Convergence rate

To prove convergence of the algorithm, consider the modified potential function
âˆš
2
EÌƒ (k) = V (xÌƒ(k) , z (k) , k s) = kr s (f (xÌƒ(k) ) âˆ’ f ? ) + rDÏˆâˆ— (z (k) , z ? ).
Lemma 2. If Î³ â‰¥ LR LÏˆâˆ— and s â‰¤

`R
2Lf Î³ ,

EÌƒ (k+1) âˆ’ EÌƒ (k) â‰¤

then for all k â‰¥ 0,

(2k + 1 âˆ’ kr)s
(f (xÌƒ(k+1) ) âˆ’ f ? ).
r

As a consequence, if r â‰¥ 3, EÌƒ is a Lyapunov function for k â‰¥ 1.
This lemma is proved in the supplementary material.
Theorem 3. The discrete-time accelerated mirror descent Algorithm 1 with parameter r â‰¥ 3 and
step sizes Î³ â‰¥ LR LÏˆâˆ— , s â‰¤ 2L`Rf Î³ , guarantees that for all k > 0,
r2 DÏˆâˆ— (z0 , z ? ) f (x0 ) âˆ’ f ?
r (1)
EÌƒ
â‰¤
+
.
sk 2
sk 2
k2
Proof. The first inequality follows immediately from Lemma 2. The second inequality follows from
a simple bound on EÌƒ (1) , proved in the supplementary material.
f (xÌƒ(k)) ) âˆ’ f ? â‰¤

4.4

Example: accelerated entropic descent

We give an P
instance of Algorithm 1 for simplex-constrained problems. Suppose that X = âˆ†n =
n
n
{x âˆˆ R+ : i=1 xi = 1} is the n-simplex. Taking Ïˆ to be the negative entropy on âˆ†, we have for
x âˆˆ X , z âˆˆ Eâˆ—,
!
Ïˆ(x) =

n
X

xi ln xi +Î´(x|âˆ†), Ïˆ âˆ— (z) = ln

i=1

n
X

ezi

ezi
, âˆ‚Ïˆ(x) = (1 + ln xi )i +Ru, âˆ‡Ïˆ âˆ— (z)i = Pn
j=1

i=1

ezj

.

where Î´(Â·|âˆ†) is the indicator function of the simplex (Î´(x|âˆ†) = 0 if x âˆˆ âˆ† and +âˆž otherwise),
and u âˆˆ Rn is a normal vector to the affine hull of the simplex. The resulting mirror descent
update is a simple entropy projection and can be computed exactly in O(n) operations, and Ïˆ âˆ—
can be shown to be 1-smooth w.r.t. k Â· kâˆž , see for example [3, 6]. For the second update, we
take R(x, y) = DÏ† (x, y) where
Pn Ï† is a smoothed negative entropy function defined as follows:
let  > 0, and let Ï†(x) =  i=1 (xi + ) ln(xi + ) + Î´(x|âˆ†). Although no simple, closed-form
expression is known for âˆ‡Ï†âˆ— , it can be computed efficiently, in O(n log n) time using a deterministic
algorithm, or O(n) expected time using a randomized algorithm, see [17]. Additionally, Ï† satisfies

our assumptions: it is 1+n
-strongly convex and 1-smooth w.r.t. k Â· kâˆž . The resulting accelerated
mirror descent method on the simplex can then be implemented efficiently, and by Theorem 3 it is

guaranteed to converge in O(1/k 2 ) whenever Î³ â‰¥ 1 and s â‰¤ 2(1+n)L
.
fÎ³

5

Numerical Experiments

We test the accelerated mirror descent method in Algorithm 1, on simplex-constrained problems in Rn , n = 100, with two different objective functions: a simple quadratic f (x) =
hx âˆ’ x? , Q(x âˆ’ x? )i, for a random positive semi-definite matrix Q, and a log-sum-exp function
7

10âˆ’1

f (x(k) ) âˆ’ f ?

f (x(k) ) âˆ’ f ?

10âˆ’9

10

âˆ’17

Mirror descent
Accelerated mirror descent
Speed restart
Gradient restart
100

200

300

400

10âˆ’5

10âˆ’8

10âˆ’11

500

600

700

f (x(k) ) âˆ’ f ?

10âˆ’5

10âˆ’5

10âˆ’13

r
r
r
r

10âˆ’2

10âˆ’2

10

âˆ’14

10âˆ’8

10âˆ’11

Mirror descent
Accelerated mirror descent
Speed restart
Gradient restart
100

200

300
k

k

(a) Weakly convex quadratic, rank 10

=3
= 10
= 30
= 90

10âˆ’14

400

500

(b) Log-sum-exp

600

10âˆ’17

100

200

300

400
k

500

600

700

800

(c) Effect of the parameter r.

Figure 1: Evolution of f (x(k) ) âˆ’ f ? on simplex-constrained problems, using different accelerated
mirror descent methods with entropy distance generating functions.
Algorithm 2 Accelerated mirror descent with restart
1: Initialize l = 0, xÌƒ(0) = zÌƒ (0) = x0 .
2: for k âˆˆ N do
r
3:
x(k+1) = Î»l zÌƒ (k) + (1 âˆ’ Î»l )xÌƒ(k) , with Î»l = r+l
D
E
(k+1)
(k+1)
ks
4:
zÌƒ
= arg minzÌƒâˆˆX r âˆ‡f (x
), zÌƒ + DÏˆ (zÌƒ, zÌƒ (k) )
D
E
5:
xÌƒ(k+1) = arg minxÌƒâˆˆX Î³s âˆ‡f (x(k+1) ), xÌƒ + R(xÌƒ, x(k+1) )
6:
l â†l+1
7:
if Restart condition then
8:
zÌƒ (k+1) â† x(k+1) , l â† 0

P

I
n
given by f (x) = ln
i=1 hai , xi + bi , where each entry in ai âˆˆ R and bi âˆˆ R is iid normal. We implement the accelerated entropic descent algorithm proposed in Section 4.4, and include the (non-accelerated) entropic descent for reference. We also adapt the gradient restarting
heuristic proposed by Oâ€™Donoghue and CandeÌ€s in [24], as well as the speed restart heuristic proposed by Su et al. in [28]. The generic restart
2. The restart condi
 method is given in Algorithm

tions are the following: (i) gradient restart: x(k+1) âˆ’ x(k) , âˆ‡f (x(k) ) > 0, and (ii) speed restart:
kx(k+1) âˆ’ x(k) k < kx(k) âˆ’ x(kâˆ’1) k.
The results are given in Figure 1. The accelerated mirror descent method exhibits a polynomial
convergence rate, which is empirically faster than the O(1/k 2 ) rate predicted by Theorem 3. The
method also exhibits oscillations around the set of minimizers, and increasing the parameter r seems
to reduce the period of the oscillations, and results in a trajectory that is initially slower, but faster
for large k, see Figure 1-c. The restarting heuristics alleviate the oscillation and empirically speed
up the convergence. We also visualized, for each experiment, the trajectory of the iterates x(k) for
each method, projected on a 2-dimensional hyperplane. The corresponding videos are included in
the supplementary material.

6

Conclusion

By combining the Lyapunov argument that motivated mirror descent, and the recent ODE interpretation [28] of Nesterovâ€™s method, we proposed a family of ODE systems for minimizing convex
functions with a Lipschitz gradient, which are guaranteed to converge at a O(1/t2 ) rate, and proved
existence and uniqueness of a solution. Then by discretizing the ODE, we proposed a family of
accelerated mirror descent methods for constrained optimization and proved an analogous O(1/k 2 )
rate when the step size is small enough. The connection with the continuous-time dynamics motivates a more detailed study of the ODE (5), such as studying the oscillatory behavior of its solution
trajectories, its convergence rates under additional assumptions such as strong convexity, and a rigorous study of the restart heuristics.
Acknowledgments
We gratefully acknowledge the NSF (CCF-1115788, CNS-1238959, CNS-1238962, CNS-1239054,
CNS-1239166), the ARC (FL110100281 and ACEMS), and the Simons Institute Fall 2014 Algorithmic Spectral Graph Theory Program.
8

References
[1] Zeyuan Allen-Zhu and Lorenzo Orecchia. Linear coupling: An ultimate unification of gradient and mirror
descent. In ArXiv, 2014.
[2] Arindam Banerjee, Srujana Merugu, Inderjit S. Dhillon, and Joydeep Ghosh. Clustering with Bregman
divergences. J. Mach. Learn. Res., 6:1705â€“1749, December 2005.
[3] Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods for convex
optimization. Oper. Res. Lett., 31(3):167â€“175, May 2003.
[4] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences, 2(1):183â€“202, 2009.
[5] A. Ben-Tal and A. Nemirovski. Lectures on Modern Convex Optimization. SIAM, 2001.
[6] Aharon Ben-Tal, Tamar Margalit, and Arkadi Nemirovski. The ordered subsets mirror descent optimization method with applications to tomography. SIAM J. on Optimization, 12(1):79â€“108, January 2001.
[7] Anthony Bloch, editor. Hamiltonian and gradient flows, algorithms, and control. American Mathematical
Society, 1994.
[8] A. A. Brown and M. C. Bartholomew-Biggs. Some effective methods for unconstrained optimization
based on the solution of systems of ordinary differential equations. Journal of Optimization Theory and
Applications, 62(2):211â€“224, 1989.
[9] SeÌbastien Bubeck and NicoloÌ€ Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed
bandit problems. Foundations and Trends in Machine Learning, 5(1):1â€“122, 2012.
[10] J. C. Butcher. Numerical Methods for Ordinary Differential Equations. John Wiley & Sons, Ltd, 2008.
[11] NicoloÌ€ Cesa-Bianchi and GaÌbor Lugosi. Prediction, Learning, and Games. Cambridge, 2006.
[12] Ofer Dekel, Ran Gilad-Bachrach, Ohad Shamir, and Lin Xiao. Optimal distributed online prediction. In
Proceedings of the 28th International Conference on Machine Learning (ICML), June 2011.
[13] U. Helmke and J.B. Moore. Optimization and dynamical systems. Communications and control engineering series. Springer-Verlag, 1994.
[14] Anatoli Juditsky. Convex Optimization II: Algorithms, Lecture Notes. 2013.
[15] Anatoli Juditsky, Arkadi Nemirovski, and Claire Tauvel. Solving variational inequalities with stochastic
mirror-prox algorithm. Stoch. Syst., 1(1):17â€“58, 2011.
[16] H.K. Khalil. Nonlinear systems. Macmillan Pub. Co., 1992.
[17] Walid Krichene, Syrine Krichene, and Alexandre Bayen. Efficient Bregman projections onto the simplex.
In 54th IEEE Conference on Decision and Control, 2015.
[18] A.M. Lyapunov. General Problem of the Stability Of Motion. Control Theory and Applications Series.
Taylor & Francis, 1992.
[19] A. S. Nemirovsky and D. B. Yudin. Problem Complexity and Method Efficiency in Optimization. WileyInterscience series in discrete mathematics. Wiley, 1983.
[20] Yu. Nesterov. Smooth minimization of non-smooth functions. Mathematical Programming, 103(1):127â€“
152, 2005.
[21] Yu. Nesterov. Gradient methods for minimizing composite functions. Mathematical Programming,
140(1):125â€“161, 2013.
[22] Yurii Nesterov. A method of solving a convex programming problem with convergence rate o(1/k2).
Soviet Mathematics Doklady, 27(2):372â€“376, 1983.
[23] Yurii Nesterov. Introductory Lectures on Convex Optimization, volume 87. Springer Science & Business
Media, 2004.
[24] Brendan Oâ€™Donoghue and Emmanuel CandeÌ€s. Adaptive restart for accelerated gradient schemes. Foundations of Computational Mathematics, 15(3):715â€“732, 2015.
[25] M. Raginsky and J. Bouvrie. Continuous-time stochastic mirror descent on a network: Variance reduction,
consensus, convergence. In CDC 2012, pages 6793â€“6800, 2012.
[26] R.T. Rockafellar. Convex Analysis. Princeton University Press, 1970.
[27] J. Schropp and I. Singer. A dynamical systems approach to constrained minimization. Numerical Functional Analysis and Optimization, 21(3-4):537â€“551, 2000.
[28] Weijie Su, Stephen Boyd, and Emmanuel CandeÌ€s. A differential equation for modeling Nesterovâ€™s accelerated gradient method: Theory and insights. In NIPS, 2014.
[29] Gerald Teschl. Ordinary differential equations and dynamical systems, volume 140. American Mathematical Soc., 2012.

9

