A Universal Primal-Dual Convex Optimization Framework

Alp Yurtsever:
:

Quoc Tran-Dinh;

Volkan Cevher:

Laboratory for Information and Inference Systems, EPFL, Switzerland
{alp.yurtsever, volkan.cevher}@epfl.ch
;
Department of Statistics and Operations Research, UNC, USA
quoctd@email.unc.edu

Abstract
We propose a new primal-dual algorithmic framework for a prototypical constrained convex optimization template. The algorithmic instances of our framework are universal since they can automatically adapt to the unknown HoÌˆlder
continuity degree and constant within the dual formulation. They are also guaranteed to have optimal convergence rates in the objective residual and the feasibility
gap for each HoÌˆlder smoothness degree. In contrast to existing primal-dual algorithms, our framework avoids the proximity operator of the objective function. We
instead leverage computationally cheaper, Fenchel-type operators, which are the
main workhorses of the generalized conditional gradient (GCG)-type methods. In
contrast to the GCG-type methods, our framework does not require the objective
function to be differentiable, and can also process additional general linear inclusion constraints, while guarantees the convergence rate on the primal problem.

1

Introduction

This paper constructs an algorithmic framework for the following convex optimization template:
f â€¹ :â€œ min tf pxq : Ax Â´ b P Ku ,
xPX

(1)

where f : Rp Ã‘ R Y t`8u is a convex function, A P RnË†p , b P Rn , and X and K are nonempty,
closed and convex sets in Rp and Rn respectively. The constrained optimization formulation (1) is
quite flexible, capturing many important learning problems in a unified fashion, including matrix
completion, sparse regularization, support vector machines, and submodular optimization [1â€“3].
Processing the inclusion Ax Â´ b P K in (1) requires a significant computational effort in the largescale setting [4]. Hence, the majority of the scalable numerical solution methods for (1) are of
the primal-dual-type, including decomposition, augmented Lagrangian, and alternating direction
methods: cf., [4â€“9]. The efficiency guarantees of these methods mainly depend on three properties
of f : Lipschitz gradient, strong convexity, and the tractability of its proximal operator.
For instance,
(
the proximal operator of f , i.e., proxf pxq :â€œ arg minz f pzq ` p1{2q}z Â´ x}2 , is key in handling
non-smooth f while obtaining the convergence rates as if it had Lipschitz gradient.
When the set AxÂ´b P K is absent in (1), other methods can be preferable to primal-dual algorithms.
For instance, if f has Lipschitz gradient, then we can use the accelerated proximal gradient methods
by applying the proximal operator for the indicator function of the set X [10, 11]. However, as the
problem dimensions become increasingly larger, the proximal tractability assumption can be restrictive. This fact increased the popularity of the generalized conditional gradient (GCG) methods (or
Frank-Wolfe-type algorithms), which instead leverage the following Fenchel-type oracles [1, 12, 13]
rxs7X ,g :â€œ arg max txx, sy Â´ gpsqu ,
sPX

(2)

where g is a convex function. When g â€œ 0, we obtain the so-called linear minimization oracle [12].
When X â€ Rp , then the (sub)gradient of the Fenchel conjugate of g, âˆ‡g Ëš , is in the set rxs7g .
1

The sharp-operator in (2) is often much cheaper to process as compared to the prox operator [1,
12]. While the GCG-type algorithms require O p1{q-iterations to guarantee an  -primal objective
residual/duality gap, they cannot converge when their objective is nonsmooth [14].
To this end, we propose a new primal-dual algorithmic framework that can exploit the sharp-operator
of f in lieu of its proximal operator. Our aim is to combine the flexibility of proximal primal-dual
methods in addressing the general template (1) while leveraging the computational advantages of
the GCG-type methods. As a result, we trade off the computational difficulty per iteration with the
overall rate of convergence. While`we obtain
optimal rates based on the sharp-operator oracles,
Ë˜
we note that the rates reduce to O 1{2 with the sharp operator vs. O p1{q with the proximal
operator when f is completely non-smooth (cf. Definition 1.1). Intriguingly, the convergence rates
are the same when f is strongly convex. Unlike GCG-type methods, our approach can now handle
nonsmooth objectives in addition to complex constraint structures as in (1).
Our primal-dual framework is universal in the sense the convergence of our algorithms can optimally
adapt to the HoÌˆlder continuity of the dual objective g (cf., (6) in Section 3) without having to know
its parameters. By HoÌˆlder continuity, we mean the (sub)gradient âˆ‡g of a convex function g satisfies
}âˆ‡gpÎ»q Â´ âˆ‡gpÎ»Ìƒq} Ä MÎ½ }Î» Â´ Î»Ìƒ}Î½ with parameters MÎ½ Äƒ 8 and Î½ P r0, 1s for all Î», Î»Ìƒ P Rn .
The case Î½ â€œ 0 models the bounded subgradient, whereas Î½ â€œ 1 captures the Lipschitz gradient.
The HoÌˆlder continuity has recently resurfaced in unconstrained optimization by [15] with universal
gradient methods that obtain optimal rates without having to know MÎ½ and Î½. Unfortunately, these
methods cannot directly handle the general constrained template (1). After our initial draft appeared,
[14] presented new GCG-type methods for composite minimization, i.e., minxPRp f pxq ` Ïˆpxq,
relying on HoÌˆlder smoothness of f (i.e., Î½ P p0, 1s) and the sharp-operator of Ïˆ. The methods
in [14] do not apply when f is non-smooth. In addition, they cannot process the additional inclusion
Ax Â´ b P K in (1), which is a major drawback for machine learning applications.
Our algorithmic framework features a gradient method and its accelerated variant that operates on
the dual formulation of (1). For the accelerated variant, we study an alternative to the universal
accelerated method of [15] based on FISTA [10] since it requires less proximal operators in the
dual. While the FISTA scheme is classical, our analysis of it with the HoÌˆlder continuous assumption
is new. Given the dual iterates, we then use a new averaging scheme to construct the primal-iterates
for the constrained template (1). In contrast to the non-adaptive weighting schemes of GCG-type
algorithms, our weights explicitly depend on the local estimates of the HoÌˆlder constants MÎ½ at each
iteration. Finally, we derive the worst-case complexity results. Our results are optimal since they
match the computational lowerbounds in the sense of first-order black-box methods [16].
Paper organization: Section 2 briefly recalls primal-dual formulation of problem (1) with some
standard assumptions. Section 3 defines the universal gradient mapping and its properties. Section 4
presents the primal-dual universal gradient methods (both the standard and accelerated variants), and
analyzes their convergence. Section 5 provides numerical illustrations, followed by our conclusions.
The supplementary material includes the technical proofs and additional implementation details.
Notation and terminology: For notational simplicity, we work on the Rp {Rn spaces with the
Euclidean norms. We denote the Euclidean distance of the vector u to a closed convex set X by
dist pu, X q. Throughout the paper, } Â¨ } represents the Euclidean norm for vectors and the spectral
norm for the matrices. For a convex function f , we use âˆ‡f both for its subgradient and gradient, and
f Ëš for its Fenchelâ€™s conjugate. Our goal is to approximately solve (1) to obtain x in the following
sense:
Definition 1.1. Given an accuracy level  Ä… 0, a point x P X is said to be an -solution of (1) if
|f px q Â´ f â€¹ | Ä , and dist pAx Â´ b, Kq Ä .
Here, we call |f px q Â´ f â€¹ | the primal objective residual and dist pAx Â´ b, Kq the feasibility gap.

2

Primal-dual preliminaries

In this section, we briefly summarize the primal-dual formulation with some standard assumptions.
For the ease of presentation, we reformulate (1) by introducing a slack variable r as follows:
fâ€¹ â€œ

min tf pxq : Ax Â´ r â€œ bu , pxâ€¹ : f pxâ€¹ q â€œ f â€¹ q.

xPX ,rPK

(3)

Let z :â€œ rx, rs and Z :â€œ X Ë†K. Then, we have D :â€œ tz P Z : AxÂ´r â€œ bu as the feasible set of (3).
2

The dual problem: The Lagrange function associated with the linear constraint Ax Â´ r â€œ b is
defined as Lpx, r, Î»q :â€œ f pxq ` xÎ», Ax Â´ r Â´ by, and the dual function d of (3) can be defined and
decomposed as follows:
dpÎ»q :â€œ min tf pxq ` xÎ», Ax Â´ r Â´ byu â€œ min tf pxq ` xÎ», Ax Â´ byu ` min xÎ», Â´ry,
xPX
xPX
rPK
loooooooooooooooomoooooooooooooooon
loooooomoooooon
rPK
dx pÎ»q

dr pÎ»q

n

where Î» P R is the dual variable. Then, we define the dual problem of (3) as follows:
!
)
dâ€¹ :â€œ maxn dpÎ»q â€œ maxn dx pÎ»q ` dr pÎ»q .
Î»PR

Î»PR

(4)

Fundamental assumptions: To characterize the primal-dual relation between (1) and (4), we require the following assumptions [17]:
Assumption A. 1. The function f is proper, closed, and convex, but not necessarily smooth. The
constraint sets X and K are nonempty, closed, and convex. The solution set X â€¹ of (1) is nonempty.
Either Z is polyhedral or the Slaterâ€™s condition holds. By the Slaterâ€™s condition, we mean ripZq X
tpx, rq : Ax Â´ r â€œ bu â€° H, where ripZq stands for the relative interior of Z.
Strong duality: Under Assumption A.1, the solution set Î›â€¹ of the dual problem (4) is also
nonempty and bounded. Moreover, the strong duality holds, i.e., f â€¹ â€œ dâ€¹ .

3

Universal gradient mappings

This section defines the universal gradient mapping and its properties.
3.1

Dual reformulation

We first adopt the composite convex minimization formulation of (4) for better interpretability as
Gâ€¹ :â€œ minn tGpÎ»q :â€œ gpÎ»q ` hpÎ»qu ,
Î»PR

(5)

where Gâ€¹ â€œ Â´dâ€¹ , and the correspondence between pg, hq and pdx , dr q is as follows:
#
gpÎ»q :â€œ max txÎ», b Â´ Axy Â´ f pxqu â€œ Â´dx pÎ»q,
xPX

hpÎ»q :â€œ max xÎ», ry â€œ Â´dr pÎ»q.

(6)

rPK

Since g and h are generally non-smooth, FISTA and its proximal-based analysis [10] are not directly
applicable. Recall the sharp operator defined in (2), then g can be expressed as
(
gpÎ»q â€œ max xÂ´AT Î», xy Â´ f pxq ` xÎ», by,
xPX

and we define the optimal solution to the g subproblem above as follows:
(
xËš pÎ»q P arg max xÂ´AT Î», xy Â´ f pxq â€ rÂ´AT Î»s7X ,f .
xPX

(7)

The second term, h, depends on the structure of K. We consider three special cases:
paq Sparsity/low-rankness: If K :â€œ tr P Rn : }r} Ä Îºu for a given Îº Ä› 0 and a given norm } Â¨ },
then hpÎ»q â€œ Îº}Î»}Ëš , the scaled dual norm of } Â¨ }. For instance, if K :â€œ tr P Rn : }r}1 Ä Îºu,
then hpÎ»q â€œ Îº}Î»}8 . While the `1 -norm induces the sparsity of x, computing h requires the max
absolute elements of Î». If K :â€œ tr P Rq1 Ë†q2 : }r}Ëš Ä Îºu (the nuclear norm), then hpÎ»q â€œ Îº}Î»},
the spectral norm. The nuclear norm induces the low-rankness of x. Computing h in this case leads
to finding the top-eigenvalue of Î», which is efficient.
pbq Cone constraints: If K is a cone, then h becomes the indicator function Î´KËš of its dual cone
KËš . Hence, we can handle the inequality constraints and positive semidefinite constraints in (1). For
instance, if K â€ Rn` , then hpÎ»q â€œ Î´RnÂ´ pÎ»q, the indicator function of RnÂ´ :â€œ tÎ» P Rn : Î» Ä 0u. If
p
K â€ S`
, then hpÎ»q :â€œ Î´SÂ´p pÎ»q, the indicator function of the negative semidefinite matrix cone.
Å›p
Å™p
pcq Separable structures: If X and f are separable, i.e., X :â€œ iâ€œ1 Xi and f pxq :â€œ iâ€œ1 fi pxi q,
then the evaluation of g and its derivatives can be decomposed into p subproblems.
3

3.2

HoÌˆlder continuity of the dual universal gradient

Let âˆ‡gpÂ¨q be a subgradient of g, which can be computed as âˆ‡gpÎ»q â€œ b Â´ AxËš pÎ»q. Next, we define
#
+
}âˆ‡gpÎ»qÂ´âˆ‡gpÎ»Ìƒq}
MÎ½ â€œ MÎ½ pgq :â€œ sup
,
(8)
}Î» Â´ Î»Ìƒ}Î½
Î»,Î»ÌƒPRn ,Î»â€°Î»Ìƒ
where Î½ Ä› 0 is the HoÌˆlder smoothness order. Note that the parameter MÎ½ explicitly depends on
Î½ [15]. We are interested in the case Î½ P r0, 1s, and especially the two extremal cases, where
we either have the Lipschitz gradient that corresponds to Î½ â€œ 1, or the bounded subgradient that
corresponds to Î½ â€œ 0.
We require the following condition in the sequel:
Assumption A. 2. MÌ‚ pgq :â€œ inf MÎ½ pgq Äƒ `8.
0ÄÎ½Ä1

Assumption A.2 is reasonable. We explain this claim with the following two examples. First, if g is
subdifferentiable and X is bounded, then âˆ‡gpÂ¨q is also bounded. Indeed, we have
A
}âˆ‡gpÎ»q} â€œ }b Â´ AxËš pÎ»q} Ä DX
:â€œ supt}b Â´ Ax} : x P X u.
A
Äƒ 8.
Hence, we can choose Î½ â€œ 0 and MÌ‚Î½ pgq â€œ 2DX

Second, if f is uniformly convex with the convexity parameter Âµf Ä… 0 and the degree q Ä› 2, i.e.,
xâˆ‡f pxq Â´ âˆ‡f pxÌƒq, x Â´ xÌƒy Ä› Âµf }x Â´ xÌƒ}q for all x, xÌƒ P Rp , then g defined by (6) satisfies (8) with
`
Ë˜ 1
1
2 qÂ´1
Î½ â€œ qÂ´1
and MÌ‚Î½ pgq â€œ ÂµÂ´1
Äƒ `8, as shown in [15]. In particular, if q â€œ 2, i.e., f
f }A}
2
is Âµf -strongly convex, then Î½ â€œ 1 and MÎ½ pgq â€œ ÂµÂ´1
f }A} , which is the Lipschitz constant of the
gradient âˆ‡g.
3.3

The proximal-gradient step for the dual problem

Given Î»Ì‚k P Rn and Mk Ä… 0, we define
Mk
}Î» Â´ Î»Ì‚k }2
2
as an approximate quadratic surrogate of g. Then, we consider the following update rule:
Â´
Â¯
(
Î»k`1 :â€œ arg minn QMk pÎ»; Î»Ì‚k q ` hpÎ»q â€ proxM Â´1 h Î»Ì‚k Â´ MkÂ´1 âˆ‡gpÎ»Ì‚k q .
QMk pÎ»; Î»Ì‚k q :â€œ gpÎ»Ì‚k q ` xâˆ‡gpÎ»Ì‚k q, Î» Â´ Î»Ì‚k y `

Î»PR

k

(9)

For a given accuracy  Ä… 0, we define
ïš¾ 1Â´Î½
â€
2
1 Â´ Î½ 1 1`Î½
Ä
MÎ½1`Î½ .
M :â€œ
1`Î½ 

(10)

We need to choose the parameter Mk Ä… 0 such that QMk is an approximate upper surrogate of g,
i.e., gpÎ»q Ä QMk pÎ»; Î»k q ` Î´k for some Î» P Rn and Î´k Ä› 0. If Î½ and MÎ½ are known, then we can
Ä defined by (10). In this case, QM
set Mk â€œ M
Ä is an upper surrogate of g. In general, we do not
know Î½ and MÎ½ . Hence, Mk can be determined via a backtracking line-search procedure.

4

Universal primal-dual gradient methods

We apply the universal gradient mappings to the dual problem (5), and propose an averaging scheme
to construct txÌ„k u for approximating xâ€¹ . Then, we develop an accelerated variant based on the FISTA
Â¯ k u for approximating xâ€¹ .
scheme [10], and construct another primal sequence txÌ„
4.1

Universal primal-dual gradient algorithm

Our algorithm is shown in Algorithm 1. The dual steps are simply the universal gradient method
in [15], while the new primal step allows to approximate the solution of (1).
Complexity-per-iteration: First, computing xËš pÎ»k q at Step 1 requires the solution xËš pÎ»k q P
rÂ´AT Î»k s7X ,f . For many X and f , we can compute xËš pÎ»k q efficiently and often in a closed form.
4

Algorithm 1 (Universal Primal-Dual Gradient Method pUniPDGradq)
Initialization: Choose an initial point Î»0 P Rn and a desired accuracy level  Ä… 0.
Ä . Set SÂ´1 â€œ 0 and xÌ„Â´1 â€œ 0p .
Estimate a value MÂ´1 such that 0 Äƒ MÂ´1 Ä M
for k â€œ 0 to kmax
1. Compute a primal solution xËš pÎ»k q P rÂ´AT Î»k s7X ,f .
2. Form âˆ‡gpÎ»k q â€œ b Â´ AxËš pÎ»k q.
3. Line-search: Set Mk,0 â€œ 0.5MkÂ´1 . For i â€œ Â´0 to imax , perform the
Â¯ following steps:
Â´1
3.a. Compute the trial point Î»k,i â€œ proxM Â´1 h Î»k Â´ Mk,i
âˆ‡gpÎ»k q .
k,i
3.b. If the following line-search condition holds:

gpÎ»k,i q Ä QMk,i pÎ»k,i ; Î»k q ` {2,
then set ik â€œ i and terminate the line-search loop. Otherwise, set Mk,i`1 â€œ 2Mk,i .
End of line-search
k
4. Set Î»k`1 â€œ Î»k,ik and Mk â€œ Mk,ik . Compute wk â€œ M1k , Sk â€œ SkÂ´1 `wk , and Î³k â€œ w
Sk .
Ëš
5. Compute xÌ„k â€œ p1 Â´ Î³k qxÌ„kÂ´1 ` Î³k x pÎ»k q.
end for
Output: Return the primal approximation xÌ„k for xâ€¹ .

Second, in the line-search procedure, we require the solution Î»k,i at Step 3.a, and the evaluation of
gpÎ»k,i q. The total computational cost depends on the proximal operator of h and the evaluations of
g. We prove below that our algorithm requires two oracle queries of g on average.
Theorem 4.1. The primal sequence txÌ„k u generated by the Algorithm 1 satisfies
Â´}Î»â€¹ }dist pAxÌ„k Â´ b, Kq Ä f pxÌ„k q Â´ f â€¹ Ä

Ä }Î»0 }2
M

` ,
k`1
2

(11)
d

dist pAxÌ„k Â´ b, Kq Ä

Ä
4M
}Î»0 Â´ Î»â€¹ } `
k`1

Ä 
2M
,
k`1

(12)

Ä is defined by (10), Î»â€¹ P Î›â€¹ is an arbitrary dual solution, and  is the desired accuracy.
where M
The worst-case analytical complexity: We establish the total number of iterations kmax to achieve
an -solution xÌ„k of (1). The supplementary material proves that
â€”Â»
ffi
fi2
â€”
ffi
?
2
Ë†
Ë™ 1`Î½
â€”
ffi
â€¹
M
4 2}Î» }
â€”â€“
ffi
Î½
fl inf
b
kmax â€œ â€“
(13)
fl ,
}Î»â€¹ }
0ÄÎ½Ä1

Â´1 ` 1 ` 8 â€¹
}Î» }r1s

â€¹

â€¹

where }Î» }r1s â€œ max t}Î» }, 1u. This complexity is optimal for Î½ â€œ 0, but not for Î½ Ä… 0 [16].
At each iteration k, the linesearch procedure at Step 3 requires the evaluations of g. The supplementary material bounds the total number N1 pkq of oracle queries, including the function G and its
gradient evaluations, up to the kth iteration as follows:
Ë†
Ë™
*
"
p1Â´Î½q
2
1Â´Î½
N1 pkq Ä 2pk ` 1q ` 1 Â´ log2 pMÂ´1 q` inf
log2
`
log2 MÎ½ . (14)
0ÄÎ½Ä1 1`Î½
p1`Î½q
1`Î½
Hence, we have N1 pkq Â« 2pk`1q, i.e., we require approximately two oracle queries at each iteration
on the average.
4.2

Accelerated universal primal-dual gradient method

We now develop an accelerated scheme for solving (5). Our scheme is different from [15] in two
key aspects. First, we adopt the FISTA [10] scheme to obtain the dual sequence since it requires
less prox operators compared to the fast scheme in [15]. Second, we perform the line-search after
computing âˆ‡gpÎ»Ì‚k q, which can reduce the number of the sharp-operator computations of f and X .
Note that the application of FISTA to the dual function is not novel per se. However, we claim that
our theoretical characterization of this classical scheme based on the HoÌˆlder continuity assumption
in the composite minimization setting is new.
5

Algorithm 2 (Accelerated Universal Primal-Dual Gradient Method pAccUniPDGradq)
Initialization: Choose an initial point Î»0 â€œ Î»Ì‚0 P Rn and an accuracy level  Ä… 0.
Ä . Set SÌ‚Â´1 â€œ 0, t0 â€œ 1 and xÌ„
Â¯ Â´1 â€œ 0p .
Estimate a value MÂ´1 such that 0 Äƒ MÂ´1 Ä M
for k â€œ 0 to kmax
1. Compute a primal solution xËš pÎ»Ì‚k q P rÂ´AT Î»Ì‚s7X ,f .
2. Form âˆ‡gpÎ»Ì‚k q â€œ b Â´ AxËš pÎ»Ì‚k q.
3. Line-search: Set Mk,0 â€œ MkÂ´1 . For i â€œ 0 to imax , perform the following steps:
`
Ë˜
Â´1
3.a. Compute the trial point Î»k,i â€œ proxM Â´1 h Î»Ì‚k Â´ Mk,i
âˆ‡gpÎ»Ì‚k q .
k,i
3.b. If the following line-search condition holds:
gpÎ»k,i q Ä QMk,i pÎ»k,i ; Î»Ì‚k q ` {p2tk q,
then ik â€œ i, and terminate the line-search loop. Otherwise, set Mk,i`1 â€œ 2Mk,i .
End of line-search
tk
4. Set Î»k`1 â€œ Î»k,ik and Mk â€œ Mk,ik . Compute wk â€œ M
, SÌ‚k â€œ SÌ‚kÂ´1 `wk , and Î³k â€œ wk {SÌ‚k .
k
a
â€œ
`
Ë˜
â€°
Â´1
2
5. Compute tk`1 â€œ 0.5 1 ` 1 ` 4tk and update Î»Ì‚k`1 â€œ Î»k`1 ` ttkk`1
Î»k`1 Â´ Î»k .
Â¯ k â€œ p1 Â´ Î³k qxÌ„
Â¯ kÂ´1 ` Î³k xËš pÎ»Ì‚k q.
6. Compute xÌ„
end for
Â¯ k for xâ€¹ .
Output: Return the primal approximation xÌ„

Complexity per-iteration: The per-iteration complexity of Algorithm 2 remains essentially the same
as that of Algorithm 1.
Â¯ k u generated by the Algorithm 2 satisfies
Theorem 4.2. The primal sequence txÌ„
Ä }Î»0 }2 ,
4M

`
2 pk`2q 1`3Î½
1`Î½
d
Ä
Ä 
16M
8M
â€¹
Â¯ k Â´b, Kq Ä
dist pAxÌ„
1`3Î½ }Î»0 Â´Î» } `
1`3Î½ ,
pk`2q 1`Î½
pk`2q 1`Î½

Â¯ kÂ´b, Kq Ä f pxÌ„
Â¯ k qÂ´f â€¹ Ä
Â´}Î»â€¹ }dist pAxÌ„

(15)
(16)

Ä is defined by (10), Î»â€¹ P Î›â€¹ is an arbitrary dual solution, and  is the desired accuracy.
where M
The worst-case analytical complexity: The supplementary material proves the following worst-case
Â¯k:
complexity of Algorithm 2 to achieve an -solution xÌ„
ffi
â€”Â»
fi 2`2Î½
ffi
â€”
1`3Î½
?
2
Ë†
Ë™ 1`3Î½
â€”
ffi
â€¹
M
8 2}Î» }
ffi
â€”â€“
Î½
fl
b
(17)
inf
kmax â€œ â€“
fl .
}Î»}
0ÄÎ½Ä1

Â´1 ` 1 ` 8 }Î»}r1s
This worst-case complexity is optimal in the sense of first-order black box models [16].
The line-search procedure at Step 3 of Algorithm 2 also terminates after a finite number of iterations.
Similar to Algorithm 1, Algorithm 2 requires 1 gradient query and ik function evaluations of g at
each iteration. The supplementary material proves that the number of oracle queries in Algorithm 2
is upperbounded as follows:
N2 pkq Ä 2pk ` 1q ` 1 `

1Â´Î½
2
rlog2 pk ` 1q Â´ log2 pqs `
log2 pMÎ½ q Â´ log2 pMÂ´1 q. (18)
1`Î½
1`Î½

Roughly speaking, Algorithm 2 requires approximately two oracle query per iteration on average.

5

Numerical experiments

This section illustrates the scalability and the flexibility of our primal-dual framework using some
applications in the quantum tomography (QT) and the matrix completion (MC).
6

5.1

Quantum tomography with Pauli operators

We consider the QT problem which aims to extract information from a physical quantum system. A
q-qubit quantum system is mathematically characterized by its density matrix, which is a complex
p
p Ë† p positive semidefinite Hermitian matrix X6 P S`
, where p â€œ 2q . Surprisingly, we can provably
deduce the state from performing compressive linear measurements b â€œ ApXq P C n based on Pauli
operators A [18]. While the size of the density matrix grows exponentially in q, a significantly fewer
compressive measurements (i.e., n â€œ Opp log pq) suffices to recover a pure state q-qubit density
matrix as a result of the following convex optimization problem:
"
*
1
Ï•â€¹ â€œ minp Ï•pXq :â€œ }ApXqÂ´b}22 : trpXq â€œ 1 , pXâ€¹ : Ï•pXâ€¹ q â€œ Ï•â€¹ q,
(19)
2
XPS`
where the constraint ensures that Xâ€¹ is a density matrix. The recovery is also robust to noise [18].
Since the objective function has Lipschitz gradient and the constraint (i.e., the Spectrahedron) is
tuning-free, the QT problem provides an ideal scalability test for both our framework and GCG-type
algorithms. To verify the performance of the algorithms with respect to the optimal solution in largescale, we remain within the noiseless setting. However, the timing and the convergence behavior of
the algorithms remain qualitatively the same under polarization and additive Gaussian noise.
âˆ¥Xk âˆ’Xâ‹† âˆ¥F
âˆ¥Xâ‹† âˆ¥F

10 0

10 0

10

-1

Relative solution error:

10

10

0

-1

10 -2

10 -2

10 -3

10 -3

10 -4

10 -4
10 0

10 1

# iteration

10 2

10 0

âˆ¥Xk âˆ’Xâ‹† âˆ¥F
âˆ¥Xâ‹† âˆ¥F

10 1

10 1

Relative solution error:

UniPDGrad
AccUniPDGrad
FrankWolfe

Objective residual: |Ï•(Xk ) âˆ’ Ï•â‹† |

Objective residual: |Ï•(Xk ) âˆ’ Ï•â‹† |

10 2

10

2

10

3

10

4

10 -1

10 -2

10

computational time (s)

0

10

1

# iteration

10

2

10 -1

10

-2

10 2

10 3

10 4

computational time (s)

Figure 1: The convergence behavior of algorithms for the q â€œ 14 qubits QT problem. The solid lines
correspond to the theoretical weighting scheme, and the dashed lines correspond to the line-search
(in the weighting step) variants.
To this end, we generate a random pure quantum state (e.g., rank-1 X6 ), and we take n â€œ 2p log p
random Pauli measurements. For q â€œ 14 qubits system, this corresponds to a 2681 4351 456 dimensional problem with n â€œ 3171 983 measurements. We recast (19) into (1) by introducing the slack
variable r â€œ ApXq Â´ b.
We compare our algorithms vs. the Frank-Wolfe method, which has optimal convergence rate guarantees for this problem, and its line-search variant. Computing the sharp-operator rxs7 requires a
top-eigenvector e1 of AËš pÎ»q, while evaluating g corresponds to just computing the top-eigenvalue
Ïƒ1 of AËš pÎ»q via a power method. All methods use the same subroutine to compute the sharpoperator, which is based on MATLABâ€™s eigs function. We set  â€œ 2 Ë† 10Â´4 for our methods and
have a wall-time 2 Ë† 104 s in order to stop the algorithms. However, our algorithms seems insensitive
to the choice of  for the QT problem.
Figure 1 illustrates the iteration and the timing complexities of the algorithms. UniPDGrad algorithm, with an average of 1.978 line-search steps per iteration, has similar iteration and timing
performance as compared to the standard Frank-Wolfe scheme with step-size Î³k â€œ 2{pk ` 2q. The
line-search variant of Frank-Wolfe improves over the standard one; however, our accelerated variant,
with an average of 1.057 line-search steps, is the clear winner in terms of both iterations and time.
We can empirically improve the performance of our algorithms even further by adapting a similar
line-search strategy in the weighting step as Frank-Wolfe, i.e., by choosing the weights wk in a
greedy fashion to minimize the objective function. The practical improvements due to line-search
appear quite significant.
5.2

Matrix completion with MovieLens dataset

To demonstrate the flexibility of our framework, we consider the popular matrix completion (MC)
application. In MC, we seek to estimate a low-rank matrix X P RpË†l from its subsampled entries
b P Rn , where ApÂ¨q is the sampling operator, i.e., ApXq â€œ b.
7

10 0

10 -1

10 -2
10 0

UniPDGrad
AccUniPDGrad
FrankWolfe
10 1

10 2

# iteration

10 3

10 0

1.13

1.13

1.11

1.11

RMSE

10 1

10 1

RMSE

(RMSE - RMSEâ‹† ) / RMSEâ‹†

(Ï•(X) âˆ’ Ï•â‹† )/Ï•â‹†

10 2

1.09

10 -1

1.07

1.07

10 -2
10 0

1.05

1.05
10 1

10 2

10 3

# iteration

1.09

0

1000 2000 3000 4000 5000

# iteration

0

1

2

3

4

5

computational time (min)

Figure 2: The performance of the algorithms for the MC problems. The dashed lines correspond to
the line-search (in the weighting step) variants, and the empty and the filled markers correspond to
the formulation (20) and (21), respectively.
Convex formulations involving the nuclear norm have been shown to be quite effective in estimating
low-rank matrices from limited number of measurements [19]. For instance, we can solve
"
*
1
2
min Ï•pXq â€œ }ApXq Â´ b} : }X}Ëš Ä Îº ,
(20)
n
XPRpË†l
with Frank-Wolfe-type methods, where Îº is a tuning parameter, which may not be available a priori.
We can also solve the following parameter-free version
"
*
1
min ÏˆpXq â€œ }X}2Ëš : ApXq â€œ b .
(21)
n
XPRpË†l
While the nonsmooth objective of (21) prevents the tuning parameter, it clearly burdens the computational efficiency of the convex optimization algorithms.
We apply our algorithms to (20) and (21) using the MovieLens 100K dataset. Frank-Wolfe algorithms cannot handle (21) and only solve (20). For this experiment, we did not pre-process the data
and took the default ub test and training data partition. We start out algorithms form Î»0 â€œ 0n , we
set the target accuracy  â€œ 10Â´3 , and we choose the tuning parameter Îº â€œ 9975{2 as in [20]. We
use lansvd function (MATLAB version) from PROPACK [21] to compute the top singular vectors,
and a simple implementation of the power method to find the top singular value in the line-search,
both with 10Â´5 relative error tolerance.
The first two plots in Figure 2 show the performance of the algorithms for (20). Our metrics are
the normalized objective residual and the root mean squared error (RMSE) calculated for the test
data. Since we do not have access to the optimal solutions, we approximated the optimal values,
Ï•â€¹ and RMSEâ€¹ , by 5000 iterations of AccUniPDGrad. Other two plots in Figure 2 compare the
performance of the formulations (20) and (21) which are represented by the empty and the filled
markers, respectively. Note that, the dashed line for AccUniPDGrad corresponds to the line-search
variant, where the weights wk are chosen to minimize the feasibility gap. Additional details about
the numerical experiments can be found in the supplementary material.

6

Conclusions

This paper proposes a new primal-dual algorithmic framework that combines the flexibility of proximal primal-dual methods in addressing the general template (1) while leveraging the computational
advantages of the GCG-type methods. The algorithmic instances of our framework are universal
since they can automatically adapt to the unknown HoÌˆlder continuity properties implied by the template. Our analysis technique unifies Nesterovâ€™s universal gradient methods and GCG-type methods
to address the more broadly applicable primal-dual setting. The hallmarks of our approach includes
the optimal worst-case complexity and its flexibility to handle nonsmooth objectives and complex
constraints, compared to existing primal-dual algorithm as well as GCG-type algorithms, while essentially preserving their low cost iteration complexity.
Acknowledgments
This work was supported in part by ERC Future Proof, SNF 200021-146750 and SNF CRSII2147633. We would like to thank Dr. Stephen Becker of University of Colorado at Boulder for his
support in preparing the numerical experiments.
8

References
[1] M. Jaggi, Revisiting Frank-Wolfe: Projection-free sparse convex optimization. J. Mach. Learn.
Res. Workshop & Conf. Proc., vol. 28, pp. 427â€“435, 2013.
[2] V. Cevher, S. Becker, and M. Schmidt.
Convex optimization for big data: Scalable, randomized, and parallel algorithms for big data analytics. IEEE Signal Process.
Mag., vol. 31, pp. 32â€“43, Sept. 2014.
[3] M. J. Wainwright, Structured regularizers for high-dimensional problems: Statistical and
computational issues. Annu. Review Stat. and Applicat., vol. 1, pp. 233â€“253, Jan. 2014.
[4] G. Lan and R. D. C. Monteiro, Iteration-complexity of first-order augmented Lagrangian
methods for convex programming. Math. Program., pp. 1â€“37, Jan. 2015, doi:10.1007/s10107015-0861-x.
[5] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, Distributed optimization and statistical
learning via the alternating direction method of multipliers. Found. and Trends in Machine
Learning, vol. 3, pp. 1â€“122, Jan. 2011.
[6] P. L. Combettes and J.-C. Pesquet, A proximal decomposition method for solving convex variational inverse problems. Inverse Problems, vol. 24, Nov. 2008, doi:10.1088/02665611/24/6/065014.
[7] T. Goldstein, E. Esser, and R. Baraniuk, Adaptive primal-dual hybrid gradient methods for
saddle point problems. 2013, http://arxiv.org/pdf/1305.0546.
[8] R. Shefi and M. Teboulle, Rate of convergence analysis of decomposition methods based on
the proximal method of multipliers for convex minimization. SIAM J. Optim., vol. 24, pp. 269â€“
297, Feb. 2014.
[9] Q. Tran-Dinh and V. Cevher, Constrained convex minimization via model-based excessive gap.
In Advances Neural Inform. Process. Syst. 27 (NIPS2014), Montreal, Canada, 2014.
[10] A. Beck and M. Teboulle, A fast iterative shrinkage-thresholding algorithm for linear inverse
problems. SIAM J. Imaging Sci., vol. 2, pp. 183â€“202, Mar. 2009.
[11] Y. Nesterov, Smooth minimization of non-smooth functions. Math. Program., vol. 103, pp. 127â€“
152, May 2005.
[12] A. Juditsky and A. Nemirovski, Solving variational inequalities with monotone operators
on domains given by Linear Minimization Oracles. Math. Program., pp. 1â€“36, Mar. 2015,
doi:10.1007/s10107-015-0876-3.
[13] Y. Yu, Fast gradient algorithms for structured sparsity. PhD dissertation, Univ. Alberta,
Edmonton, Canada, 2014.
[14] Y. Nesterov, Complexity bounds for primal-dual methods minimizing the model of objective
function. CORE, Univ. Catholique Louvain, Belgium, Tech. Rep., 2015.
[15] Y. Nesterov, Universal gradient methods for convex optimization problems. Math. Program.,
vol. 152, pp. 381â€“404, Aug. 2015.
[16] A. Nemirovskii and D. Yudin, Problem complexity and method efficiency in optimization.
Hoboken, NJ: Wiley Interscience, 1983.
[17] R. T. Rockafellar, Convex analysis (Princeton Math. Series), Princeton, NJ: Princeton Univ.
Press, 1970.
[18] D. Gross, Y.-K. Liu, S. T. Flammia, S. Becker, and J. Eisert,
Quantum state
tomography via compressed sensing.
Phys. Rev. Lett., vol. 105, pp. Oct. 2010,
doi:10.1103/PhysRevLett.105.150401.
[19] E. CandeÌ€s and B. Recht, Exact matrix completion via convex optimization. Commun. ACM,
vol. 55, pp. 111â€“119, June 2012.
[20] M. Jaggi and M. SulovskyÌ, A simple algorithm for nuclear norm regularized problems. In
Proc. 27th Int. Conf. Machine Learning (ICML2010), Haifa, Israel, 2010, pp. 471â€“478.
[21] R. M. Larsen, PROPACK - Software for large and sparse SVD calculations. Available: http:
//sun.stanford.edu/â€rmunk/PROPACK/.

9

